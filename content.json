{"meta":{"title":"Continuous Learning","subtitle":"浮云一别后，流水十年间","description":null,"author":"CodeJuan","url":"http://blog.decbug.com"},"pages":[{"title":"","date":"2016-10-10T13:05:25.396Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"404.html","permalink":"http://blog.decbug.com/404.html","excerpt":"","text":""},{"title":"碎碎念","date":"2015-12-30T15:30:09.000Z","updated":"2016-10-10T13:05:25.416Z","comments":true,"path":"twitter/index.html","permalink":"http://blog.decbug.com/twitter/index.html","excerpt":"","text":"碎碎念，记录一些感悟，吐槽。利用disqus，可以免去部署之繁琐。 感谢@技术小黑屋给我的启发。 以游客身份回复的方法: 输入你的昵称及邮箱 选中I’d rather post as a guest 再点击回复按钮即可"},{"title":"","date":"2016-10-10T13:05:25.416Z","updated":"2016-10-10T13:05:25.416Z","comments":true,"path":"test/index.html","permalink":"http://blog.decbug.com/test/index.html","excerpt":"","text":"test测试页面，还没写好"},{"title":"tags","date":"2015-10-11T05:59:02.000Z","updated":"2016-10-10T13:05:25.416Z","comments":true,"path":"tags/index.html","permalink":"http://blog.decbug.com/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2013-12-22T04:39:04.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"categories/index.html","permalink":"http://blog.decbug.com/categories/index.html","excerpt":"","text":""},{"title":"book","date":"2013-12-24T15:30:09.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"book/index.html","permalink":"http://blog.decbug.com/book/index.html","excerpt":"","text":"读书计划2016 书名 状态 备注 微服务设计与实现 完成 一般 图解TCP/IP 完成 通俗科普 容器与容器云 完成 不错 kubernetes权威指南 90% 不错不错，值得一看，但是书里讲的k8s版本有点旧 分布式服务框架原理与实践 完成 docker进阶与实战 完成 一般 wireshark网络分析的艺术 完成 不可多得的好书，由实战例子引入分析方法 wireshark网络分析就这么简单 完成 通过简单例子讲解了TCPIP，对协议有了更深刻理解 JAVA性能优化权威指南 30% 复习了GC，常用profiler mesos大数据资源调度 完成 一般 恰如其分的软件架构 5% 微服务设计 完成 还可以吧 2015 书名 状态 备注 持续交付 完成 构建之法 完成 还欠了作者一篇书评 程序员职业规划书 完成 UNIX编程艺术 完成 Linux内核设计与实现 完成 虽然看完了，但是还是有很多不懂，有时间还需要再看 Linux命令行与shell编程大全 完成 收获很大，入门必看 谷歌软件测试之道 完成 深入浅出nodejs 完成 很好玩啊 TCPIP卷1 30% 断断续续看的，看了30%，很头疼，等状态好的时候啃完 大型分布式网站架构设计与实现 完成 大部分内容都是开源项目的readme helloworld，适合初学者 大规模分布式系统架构与设计实战 30% 作者竟然是我司的，然而搜了一下，貌似离职了，sigh 图解http 完成 基本概念都有讲到，状态码，报文结构，首部等都有涉及，可惜对keepalive描述不太深入，总体来说，是入门利器 Docker技术入门与实战 完成 带我入门 精通nginx 完成 基本的用法都讲到了，接下来就是要深入实践 性能之巅 完成 讲了底层知识，以及常用优化套路，可以作为工具书 openstack设计与实现 完成 曾经看过的书 书名 状态 备注 Effective C++ 完成 More Effective C++ 完成 Essential C++ 完成 HeadFirst设计模式 完成 编程珠玑 完成 编程之美 完成 windows核心编程 完成 代码大全 完成 软件调试 完成 深入理解计算机操作系统 勉强看完 30天制作操作系统 实践了一番 深入理解linux内核 懂了些概念 算法导论 头大 编译原理 打算再看一遍英文版 程序员修炼之道 完成 半途而废的书，早晚得看完 书名 状态 备注 C++ primer 深度探索C++模型 重构 计算机程序构造与解释 修改代码的艺术 代码整洁之道 未完成 写出可读代码 未完成 计划要看的书 书名 状态 备注 UNIX环境高级编程 UNIX网络编程 大型分布式存储系统 年少时看过的书 -_-! 书名 状态 备注 程序员面试宝典 程序员面试笔试宝典 剑指offer 程序员求职宝典"},{"title":"about me","date":"2013-12-24T15:30:09.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"about/index.html","permalink":"http://blog.decbug.com/about/index.html","excerpt":"","text":"个人信息 不算简历，只能算简介 我看过的书 github stackoverflow xh@decbug.com license除特别注明之外，本博按署名-非商用-相同方式共享 4.0进行发布,转载请保留原文链接及作者"}],"posts":[{"title":"APM厂商分析","slug":"APM","date":"2016-10-09T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2016/10/10/APM/","link":"","permalink":"http://blog.decbug.com/2016/10/10/APM/","excerpt":"在微服务大行其道的今天，系统的实例越来越多，出现性能问题时要调试就很困难。于是乎，就出现了许多APM厂商，只需要装一个agent，就能通过监控系统调用，网络传输，性能指标，辅助调试定位性能问题。 在公司分析了很多，也抓包了，详细内容带不出来。就简单记个笔记，供以后回忆","text":"在微服务大行其道的今天，系统的实例越来越多，出现性能问题时要调试就很困难。于是乎，就出现了许多APM厂商，只需要装一个agent，就能通过监控系统调用，网络传输，性能指标，辅助调试定位性能问题。 在公司分析了很多，也抓包了，详细内容带不出来。就简单记个笔记，供以后回忆 sysdig分为开源版sysdig.org和商业版sysdig cloud 开源原理：抓内核级别的调用，比如read，write，网络也是read，write，只不过描述符不一样，然后形成事件，记录下来还有个强大的功能Chisel，很好玩，可以自己扩展功能，用lua写Writing a Sysdig Chisel, a Tutorial sysdig cloud装一个agent，用的是开源的sysdig采集数据，然后上报到sysdig cloud的服务器。 可以展示topo，调用耗时等等 分析http，可以精确到url 通过分析开源代码，分析出具体的调用，原理应该和chisel中的memcache差不多 其他dynatrace &amp; apptrace都差不多 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"APM","slug":"APM","permalink":"http://blog.decbug.com/tags/APM/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"VxLan原理","slug":"VxLan","date":"2016-10-08T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2016/10/09/VxLan/","link":"","permalink":"http://blog.decbug.com/2016/10/09/VxLan/","excerpt":"VxLan，网络虚拟化，应用很广泛 简单记录一下原理","text":"VxLan，网络虚拟化，应用很广泛 简单记录一下原理 VM1发送IP数据包到VM2，即192.168.0.100 到 192.168.0.101； VTEP1查找自己的VXLAN表知道要发给VTEP2，然后依次封装以下数据包头； VXLAN包头 标准UDP包头，校验和checksum为0x0000； 标准IP包头，目标地址为VTEP2的IP地址，协议号设为0x11表面为UDP包。 标准MAC数据包，目标地址为下一跳设备的MAC地址00:10:11:FE:D8:D2，可路由到目标隧道端VTEP2。 VTEP2接收数据包，根据UDP的destination端口找到VXLAN数据包。接着查找所有所在VXLAN的VNI为864的端口组，找到VM2的 VM2接收并处理数据包，拿到Payload数据。 参考http://www.aboutyun.com/thread-11189-1-1.html 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"VxLan","slug":"VxLan","permalink":"http://blog.decbug.com/tags/VxLan/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"分布式系统调度算法的公平","slug":"scheduler_fair","date":"2016-09-29T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/09/30/scheduler_fair/","link":"","permalink":"http://blog.decbug.com/2016/09/30/scheduler_fair/","excerpt":"调度，在计算机世界里随处可见，只要有资源抢占，就需要调度。","text":"调度，在计算机世界里随处可见，只要有资源抢占，就需要调度。 CFS操作系统要调度一堆进程，也是离不开调度算法的，linux喜欢用CFS，这里可以稍微扩展记录一下，加深印象 分布式系统的调度公平与不公平所谓公平，就是人人有饭吃，不能有人饿死 不公平 job1先来，job1有很多个task，就开始执行job1的task 之后job2过来，但是job1的task还没执行完，那么job2就要一直等待，这就叫饥饿 公平公平就是，大家都有饭吃 job1先来，job1有很多个task，开始执行job1的task 然后job2过来，这时候job1的task还有一些没有执行完 调度器就会block job1，也就是说，会把job1剩余的task挂起 开始执行job2的task 一段时间后，由于job1饥饿了，所以又把job2 block，执行job1的task 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"fair","slug":"fair","permalink":"http://blog.decbug.com/tags/fair/"},{"name":"scheduler","slug":"scheduler","permalink":"http://blog.decbug.com/tags/scheduler/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"TCPIP ping ssh","slug":"ping_ssh","date":"2016-09-08T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/09/09/ping_ssh/","link":"","permalink":"http://blog.decbug.com/2016/09/09/ping_ssh/","excerpt":"数据库部署在k8s上，两个pod一主一备，却无法同步，一直同步失败，提示socket 什么什么什么。据同事说，还有一个现象是ping都会报错","text":"数据库部署在k8s上，两个pod一主一备，却无法同步，一直同步失败，提示socket 什么什么什么。据同事说，还有一个现象是ping都会报错 ping我看了下ping的报错,说permission啥啥啥的，于是谷歌一下，找到答案。是因为权限问题，用chmod u+s /bin/ping解决。 能ping通，为何还是传输有问题因为ping是ICMP协议，基于IP层，能ping说，说明IP层是好的，无法确定TCP正常 尝试用SSH测试TCP是否正常12345678910ssh -vvv [ip]# 返回debug1: Connection established.debug1: Local version string SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2.8debug1: Remote protocol version 2.0, remote software version OpenSSH_6.6.1p1 Ubuntu-2ubuntu2debug1: match: OpenSSH_6.6.1p1 Ubuntu-2ubuntu2 pat OpenSSH_6.6.1* compat 0x04000000debug1: SSH2_MSG_KEXINIT sent 在SSH2_MSG_KEXINIT之后就没有了响应， debug1: Connection established.说明tcp连接建立成功 版本协商 debug1: Local version string SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2.8，本地ssh版本 debug1: Remote protocol version 2.0, remote software version OpenSSH_6.6.1p1 Ubuntu-2ubuntu2，远端版本 debug1: match: OpenSSH_6.6.1p1 Ubuntu-2ubuntu2 pat OpenSSH_6.6.1* compat 0x04000000 说明成功通信一次 debug1: SSH2_MSG_KEXINIT sent，开始进行key的协商，然后就没有然后了 后面的定位过程，就涉及到容器组网方案，不适合公开。 顺便理解一下SSH协议 6,7,8握手 9,11协议协商阶段 16，17,20,23,24交换密钥阶段 认证阶段 会话 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"TCPIP","slug":"TCPIP","permalink":"http://blog.decbug.com/tags/TCPIP/"},{"name":"protocol","slug":"protocol","permalink":"http://blog.decbug.com/tags/protocol/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"随手记录DHCP","slug":"dhcp","date":"2016-08-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/08/29/dhcp/","link":"","permalink":"http://blog.decbug.com/2016/08/29/dhcp/","excerpt":"同事用PXE装系统，在装完最小系统后，会再次获取IP，然而DHCP却给了一个不一样的IP","text":"同事用PXE装系统，在装完最小系统后，会再次获取IP，然而DHCP却给了一个不一样的IP 网上别人抓的正常包可以看到 装miniOS之前Discover,offer,request,ack 完成miniOS之后，request,ack 同事抓的包没有办法带出公司，只能凭记忆 装miniOS之前Discover,offer,request,ack 完成miniOS之后，Discover,offer,request,ack 由于Discover了两次，所以得到了两个IP 疑问为什么会Discoverr两次？即使是Discover两次，那么对于同一个mac，DHCP也应该分配同样的IP吧？DHCP的配置里有一个忽略clientID的参数 复习DHCP流程 参考http://tasnrh.blog.51cto.com/4141731/1744495DHCP发现（DISCOVER）目标设备在物理子网上发送广播来寻找可用的服务器。网络管理员可以配置一个本地路由来转发DHCP包给另一个子网上的DHCP服务器。该目标设备实现生成一个目的地址为255.255.255.255或者一个子网广播地址的UDP包。DHCP提供（OFFER）当DHCP服务器收到一个来自目标设备的IP租约请求时，它会提供一个IP租约。DHCP为目标设备保留一个IP地址，然后通过网络单播一个DHCPOFFER消息给目标设备。该消息包含目标设备的MAC地址、服务器提供的IP地址、子网掩码、租期以及提供IP的DHCP服务器的IP。服务器基于在CHADDR字段指定的目标设备硬件地址来检查配置。这里的服务器，10.1.1.1，将IP地址指定于YIADDR字段。DHCP请求（REQUEST）当目标设备PC收到一个IP租约提供时，它必须告诉所有其他的DHCP服务器它已经接受了一个租约提供。因此，该目标设备会发送一个DHCPREQUEST消息，其中包含提供租约的服务器的IP。当其他DHCP服务器收到了该消息后，它们会收回所有可能已提供给目标设备的租约。然后它们把曾经给目标设备保留的那个地址重新放回到可用地址池中，这样，它们就可以为其他计算机分配这个地址。任意数量的DHCP服务器都可以响应同一个IP租约请求，但是每一个目标设备网卡只能接受一个租约提供。DHCP确认（Acknowledge，ACK）当DHCP服务器收到来自目标设备的REQUEST消息后，它就开始了配置过程的最后阶段。这个响应阶段包括发送一个DHCPACK包给目标设备。这个包包含租期和目标设备可能请求的其他所有配置信息。这时候，TCP/IP配置过程就完成了。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"DHCP","slug":"DHCP","permalink":"http://blog.decbug.com/tags/DHCP/"},{"name":"wireshark","slug":"wireshark","permalink":"http://blog.decbug.com/tags/wireshark/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"通过故事谈消息队列","slug":"sth_about_MQ","date":"2016-08-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/08/23/sth_about_MQ/","link":"","permalink":"http://blog.decbug.com/2016/08/23/sth_about_MQ/","excerpt":"通过简单的例子，讲故事的方式解释消息队列","text":"通过简单的例子，讲故事的方式解释消息队列 我们在做架构设计的时候，我个人理解，有一点很重要，叫各司其职。如何才算各司其职呢？首先，你得让他们各自有职责，才有职可依。比如说，举个不恰当的例子，以前没有数据库的时候，我们要吧数据持久化，可能需要自己写文件，自己写查找算法。后面大家觉得自己存取数据太麻烦，而且不通用，于是就想办法专门做一个模块来存取数据。这个，就是职责划分产生的必然结果。 故事 在很久很久以前，人们住得很近，所谓鸡犬之声相闻，邻居之间有个啥事需要帮忙，吼一声，大家都能听到，就会帮你做事。 再后来，村庄变城市，大家住的越来越远，家庭的独立性越来越强，相互之间再通过吼一声来已然不现实，所以，就有了电话。想让对方帮忙，足不出户，一个电话就能通知到。 但是，你想要对方帮忙，还得知道电话号码，如果换号码了也没有通知到你，那么你就无法找对方帮忙了。于是乎，就出了信使这个职业。你只要告诉信使，你需要人来做某某事，信使就会把你的任务通知到所有能做这个事的人。收到任务的人，就会去做，做完之后他就告诉信使已完成，信使再告诉你结果。 对应到计算机世界 在同一个进程，想调用别人，知道接口就行。对应的是村庄时代 再后来，单机性能不够，所以，就需要拆分到多个机器。比如，数据库就部署到单独的机器，别人通过远程调用来使用。对应的是电话时代 再后来，集群时代到来，于是消息队列就红红火火恍恍惚惚。对应信使时代 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://blog.decbug.com/tags/MQ/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"Docker基础知识--namespace cgroup","slug":"docker_basic","date":"2016-08-14T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/08/15/docker_basic/","link":"","permalink":"http://blog.decbug.com/2016/08/15/docker_basic/","excerpt":"记录一下docker基础知识 namespace是环境隔离，cgroup是资源隔离，加起来就是docker的基础","text":"记录一下docker基础知识 namespace是环境隔离，cgroup是资源隔离，加起来就是docker的基础 namespace CLONE_NEWPID CLONE_NEWUTS CLONE_NEWNS CLONE_NEWIPC CLONE_NEWNET CLONE_NEWUSER 不带namespace12345678910111213141516171819202122232425262728293031323334353637#define _GNU_SOURCE#include &lt;sched.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;//子进程堆栈空间大小#define STACK_SIZE (1024 * 1024)static char child_stack[STACK_SIZE];char* const child_cmd[] = &#123; \"/bin/bash\", NULL&#125;;int child()&#123; printf(\"Child start!\\n\"); printf(\"Child pid in child process: %5d\\n\", getpid()); //使用bash替换掉原进程便于观察 execv(child_cmd[0], child_cmd); printf(\"Child stop!\\n\"); return 0;&#125;int main()&#123; printf(\"Parent start!\\n\"); printf(\"Parent pid: %5d\\n\", getpid()); int child_pid = clone(child, child_stack+STACK_SIZE, SIGCHLD, NULL); printf(\"Child pid in parent process: %5d\\n\", child_pid); waitpid(child_pid, NULL, 0); printf(\"Parent stop!\\n\"); return 0;&#125; 结果123456i3@i3:~/code/namespace$ ./baseParent start!Parent pid: 7816Child pid in parent process: 7817Child start!Child pid in child process: 7817 UTScgroup参考https://yq.aliyun.com/articles/57743http://coolshell.cn/articles/17049.html 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"cgroup","slug":"cgroup","permalink":"http://blog.decbug.com/tags/cgroup/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"namespace","slug":"namespace","permalink":"http://blog.decbug.com/tags/namespace/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"kubernetes尝试有状态服务","slug":"k8s_stateful","date":"2016-08-02T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/08/03/k8s_stateful/","link":"","permalink":"http://blog.decbug.com/2016/08/03/k8s_stateful/","excerpt":"有状态服务的概念既然名叫有状态，那么就与之相对，会有我们很熟悉的无状态。无状态的概念，就是只负责运算，不负责任何数据的存储，这样就能很轻松地做到水平扩展。 之前写的关于无状态的例子 那么，有状态的概念又是什么呢，简单来说，就是会有数据的存储，需要持久化。","text":"有状态服务的概念既然名叫有状态，那么就与之相对，会有我们很熟悉的无状态。无状态的概念，就是只负责运算，不负责任何数据的存储，这样就能很轻松地做到水平扩展。 之前写的关于无状态的例子 那么，有状态的概念又是什么呢，简单来说，就是会有数据的存储，需要持久化。 k8s的petset简单来说，pod是用来跑无状态服务，petset就是跑有状态服务。1.3之前k8s大多是用于无状态的web应用，但是我们实际业务却有很多有状态的服务，对于谷歌来说，绝对不会放弃这一块的机会，所以petset就应运而生。 那么，作为有状态服务的基石，petset需要具备哪些特征呢： 有唯一的编号 在网络上有个不会改变的标识，k8s是通过域名实现的。pod，则是名字后面还有随机数，所以需要有service来做转发 每个有状态服务，都需要有自己的卷，这样就能保证数据可靠存储 petset的典型场景MySQLZookeeperCassandraredis 小试验1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# A headless service to create DNS recordsapiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web # *.nginx.default.svc.cluster.local clusterIP: None selector: app: nginx---apiVersion: apps/v1alpha1kind: PetSetmetadata: name: webspec: serviceName: \"nginx\" replicas: 2 template: metadata: labels: app: nginx annotations: pod.alpha.kubernetes.io/initialized: \"true\" spec: terminationGracePeriodSeconds: 0 containers: - name: nginx image: gcr.io/google_containers/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi 提示123456789101112$ ./kubectl describe pvc www-web-0Name: www-web-0Namespace: defaultStatus: PendingVolume:Labels: app=nginxCapacity:Access Modes:Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 5m 10s 22 &#123;persistentvolume-controller &#125; Warning ProvisioningFailed No provisioner plugin found for the claim! 这是因为需要设置Persistent Volume Provisioning方法是在controller manager的启动参数加上--enable-hostpath-provisioner=true，然后重启controller，再create就OK了。 redishttps://github.com/kubernetes/kubernetes/tree/master/test/e2e/testing-manifests/petset/redis service.yml1234567891011121314151617# A headless service to create DNS recordsapiVersion: v1kind: Servicemetadata: annotations: service.alpha.kubernetes.io/tolerate-unready-endpoints: \"true\" name: redis labels: app: redisspec: ports: - port: 6379 name: peer # *.redis.default.svc.cluster.local clusterIP: None selector: app: redis petset.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798apiVersion: apps/v1alpha1kind: PetSetmetadata: name: rdspec: serviceName: \"redis\" replicas: 3 template: metadata: labels: app: redis annotations: pod.alpha.kubernetes.io/initialized: \"true\" pod.alpha.kubernetes.io/init-containers: '[ &#123; \"name\": \"install\", \"image\": \"gcr.io/google_containers/redis-install-3.2.0:e2e\", \"imagePullPolicy\": \"Always\", \"args\": [\"--install-into=/opt\", \"--work-dir=/work-dir\"], \"volumeMounts\": [ &#123; \"name\": \"opt\", \"mountPath\": \"/opt\" &#125;, &#123; \"name\": \"workdir\", \"mountPath\": \"/work-dir\" &#125; ] &#125;, &#123; \"name\": \"bootstrap\", \"image\": \"debian:jessie\", \"command\": [\"/work-dir/peer-finder\"], \"args\": [\"-on-start=\\\"/work-dir/on-start.sh\\\"\", \"-service=redis\"], \"env\": [ &#123; \"name\": \"POD_NAMESPACE\", \"valueFrom\": &#123; \"fieldRef\": &#123; \"apiVersion\": \"v1\", \"fieldPath\": \"metadata.namespace\" &#125; &#125; &#125; ], \"volumeMounts\": [ &#123; \"name\": \"opt\", \"mountPath\": \"/opt\" &#125;, &#123; \"name\": \"workdir\", \"mountPath\": \"/work-dir\" &#125; ] &#125; ]' spec: terminationGracePeriodSeconds: 0 containers: - name: redis image: debian:jessie ports: - containerPort: 6379 name: peer command: - /opt/redis/redis-server args: - /opt/redis/redis.conf readinessProbe: exec: command: - sh - -c - \"/opt/redis/redis-cli -h $(hostname) ping\" initialDelaySeconds: 15 timeoutSeconds: 5 volumeMounts: - name: datadir mountPath: /data - name: opt mountPath: /opt volumes: - name: opt emptyDir: &#123;&#125; - name: workdir emptyDir: &#123;&#125; volumeClaimTemplates: - metadata: name: datadir annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi 参考 构建可伸缩的有状态服务 无状态服务 vs 有状态服务 Pet Sets 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.decbug.com/tags/kubernetes/"},{"name":"stateful","slug":"stateful","permalink":"http://blog.decbug.com/tags/stateful/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"体验docker UCP","slug":"evaluate_docker_UCP","date":"2016-08-01T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/08/02/evaluate_docker_UCP/","link":"","permalink":"http://blog.decbug.com/2016/08/02/evaluate_docker_UCP/","excerpt":"背景docker官方也有私有云版本","text":"背景docker官方也有私有云版本 installdocker engine感谢Daoloud提供的一键式安装1curl -sSL https://get.daocloud.io/docker | sh ucp123456789export DOCKER_TLS_VERIFY=\"0\"export DOCKER_HOST=\"tcp://104.236.158.191:2376\"export DOCKER_CERT_PATH=\"\"export DOCKER_MACHINE_NAME=\"node1\"docker run --rm -it \\&gt; -v /var/run/docker.sock:/var/run/docker.sock \\&gt; --name ucp docker/ucp install -i \\&gt; --swarm-port 3376 --host-address 104.236.158.191 提示1Could not read CA certificate \"/root/.docker/ca.pem\": open /root/.docker/ca.pem: no such file or directory 看来需要生成一个123openssl req -out ca.pem -new -x509# aaaa# 104.236.158.191 再次运行run12345678910111213141516171819202122232425262728Unable to find image 'docker/ucp:latest' locallylatest: Pulling from docker/ucpe110a4a17941: Pull completea1c3e1c9e147: Pull completebca4748868da: Pull completeDigest: sha256:46154615e2429a9a8f3d019c414f69cd47f9f7dd5d5c35f54016c01fad1d99efStatus: Downloaded newer image for docker/ucp:latestINFO[0000] Verifying your system is compatible with UCPINFO[0000] Your engine version 1.12.0, build 8eab29e (4.4.0-31-generic) is compatibleWARN[0000] Your system does not have enough memory. UCP suggests a minimum of 2.00 GB, but you only have 0.97 GB. You may have unexpected errors.Please choose your initial UCP admin password:Confirm your initial password:INFO[0024] Pulling required images... (this may take a while)WARN[0080] None of the hostnames we'll be using in the UCP certificates [ubuntu-1gb-sfo1-01 127.0.0.1 172.17.0.1 104.236.158.191] contain a domain component. Your generated certs may fail TLS validation unless you only use one of these shortnames or IPs to connect. You can use the --san flag to add more aliasesYou may enter additional aliases (SANs) now or press enter to proceed with the above list.Additional aliases: abcINFO[0192] Installing UCP with host address 104.236.158.191 - If this is incorrect, please specify an alternative address with the '--host-address' flagINFO[0000] Checking that required ports are available and accessibleINFO[0005] Generating UCP Cluster Root CAINFO[0047] Generating UCP Client Root CAINFO[0060] Deploying UCP ContainersINFO[0113] New configuration established. Signalling the daemon to load it...INFO[0114] Successfully delivered signal to daemonINFO[0114] UCP instance ID: DKVU:ULUA:C3SO:O36W:4WUE:OM4Z:5V4X:IA46:ZLS5:L2KE:KE5J:O56DINFO[0114] UCP Server SSL: SHA-256 Fingerprint=71:C8:1D:AB:CA:EE:E7:91:07:D6:23:83:F2:A7:67:2A:F8:DE:88:43:5C:D4:2E:76:9D:BA:B9:39:B4:11:64:86INFO[0114] Login as \"admin\"/(your admin password) to UCP at https://104.236.158.191:443 安装完成，效果图 分析系统容器 NODE NAME IMAGE CREATED ubuntu-1gb-sfo1-01 ucp-controller docker/ucp-controller:1.1.2 2016-08-02 20:30:12 +0800 ubuntu-1gb-sfo1-01 ucp-auth-worker docker/ucp-auth:1.1.2 2016-08-02 20:30:09 +0800 ubuntu-1gb-sfo1-01 ucp-auth-api docker/ucp-auth:1.1.2 2016-08-02 20:30:08 +0800 ubuntu-1gb-sfo1-01 ucp-auth-store docker/ucp-auth-store:1.1.2 2016-08-02 20:30:04 +0800 ubuntu-1gb-sfo1-01 ucp-cluster-root-ca docker/ucp-cfssl:1.1.2 2016-08-02 20:30:03 +0800 ubuntu-1gb-sfo1-01 ucp-client-root-ca docker/ucp-cfssl:1.1.2 2016-08-02 20:30:02 +0800 ubuntu-1gb-sfo1-01 ucp-swarm-manager docker/ucp-swarm:1.1.2 2016-08-02 20:30:01 +0800 ubuntu-1gb-sfo1-01 ucp-swarm-join docker/ucp-swarm:1.1.2 2016-08-02 20:30:01 +0800 ubuntu-1gb-sfo1-01 ucp-proxy docker/ucp-proxy:1.1.2 2016-08-02 20:29:59 +0800 ubuntu-1gb-sfo1-01 ucp-kv docker/ucp-etcd:1.1.2 2016-08-02 20:29:56 +0800 Name Description ucp-proxy A TLS proxy. It allows secure access to the local Docker Engine. ucp-controller The UCP application. It uses the key-value store for persisting configurations. ucp-swarm-manager Provides the clustering capabilities. It uses the key-value store for leader election, and keeping track of cluster members. ucp-swarm-join Heartbeat to record on the key-value store that this node is alive. If the node goes down, this heartbeat stops, and the node is removed from the cluster. ucp-auth-api The centralized API for identity and authentication used by UCP and DTR. ucp-auth-worker Performs scheduled LDAP synchronizations and cleans data on the ucp-auth-store. ucp-auth-store Stores authentication configurations, and data for users, organizations and teams. ucp-kv Used to store the UCP configurations. Don’t use it in your applications, since it’s for internal use only. ucp-cluster-root-ca A certificate authority to sign the certificates used when joining new nodes, and on administrator client bundles. ucp-client-root-ca A certificate authority to sign user bundles. Only used when UCP is installed without an external root CA. 基本上明白都有什么作用了 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"UCP","slug":"UCP","permalink":"http://blog.decbug.com/tags/UCP/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"kubernetes多租户分析","slug":"k8s_multi_tenant","date":"2016-07-31T17:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/08/01/k8s_multi_tenant/","link":"","permalink":"http://blog.decbug.com/2016/08/01/k8s_multi_tenant/","excerpt":"背景公有云产品有个很重要的概念叫多租户，比如OpenStack的Domain/Project。提供资源隔离，权限控制，等等。kubernetes如果作为PaaS的基础，那么也需要具备此能力。","text":"背景公有云产品有个很重要的概念叫多租户，比如OpenStack的Domain/Project。提供资源隔离，权限控制，等等。kubernetes如果作为PaaS的基础，那么也需要具备此能力。 NameSpace Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces. 一组逻辑的集群，可以大概类似于租户的概念，可以做到一定程度的资源隔离，Quota。如果非要和OpenStack做个映射，那么就大概对应于Project吧。 举个例子 kubectl –namespace=abc run nginx –image=nginx kubectl run nginx –image=nginx这两条命令虽然都是run起来一个nginx，但是作用域却不一样。命令1是在一个叫abc的namespace里运行nginx，命令2则是在Default Resource Quota A resource quota, defined by a ResourceQuota object, provides constraints that limit aggregate resource consumption per namespace.限制某个name space的资源总数 使用方法: It is enabled when the apiserver –admission-control= flag has ResourceQuota as one of its arguments Compute Resource Quota Resource Name Description cpu Across all pods in a non-terminal state, the sum of CPU requests cannot exceed this value. limits.cpu Across all pods in a non-terminal state, the sum of CPU limits cannot exceed this value. limits.memory Across all pods in a non-terminal state, the sum of memory limits cannot exceed this value. memory Across all pods in a non-terminal state, the sum of memory requests cannot exceed this value. requests.cpu Across all pods in a non-terminal state, the sum of CPU requests cannot exceed this value. requests.memory Across all pods in a non-terminal state, the sum of memory requests cannot exceed this value. Object Count Quota Resource Name Description configmaps The total number of config maps that can exist in the namespace. persistentvolumeclaims The total number of persistent volume claims that can exist in the namespace. pods The total number of pods in a non-terminal state that can exist in the namespace. A pod is in a terminal state if status.phase in (Failed, Succeeded) is true. replicationcontrollers The total number of replication controllers that can exist in the namespace. resourcequotas The total number of resource quotas that can exist in the namespace. services The total number of services that can exist in the namespace. services.loadbalancers The total number of services of type load balancer that can exist in the namespace. services.nodeports The total number of services of type node port that can exist in the namespace. secrets The total number of secrets that can exist in the namespace. 对象的总数，比如限制最多可以创建几个pod，最多几个rc 12345678910111213141516171819202122$ kubectl describe quota compute-resources --namespace=myspaceName: compute-resourcesNamespace: myspaceResource Used Hard-------- ---- ----limits.cpu 0 2limits.memory 0 2Gipods 0 4requests.cpu 0 1requests.memory 0 1Gi$ kubectl describe quota object-counts --namespace=myspaceName: object-countsNamespace: myspaceResource Used Hard-------- ---- ----configmaps 0 10persistentvolumeclaims 0 4replicationcontrollers 0 20secrets 1 10services 0 10services.loadbalancers 0 2 Limit Range需要在Admission Controller启用LimitRanger插件 By default, pods run with unbounded CPU and memory limits. Let’s create a simple limit in our namespace.123$ kubectl create -f docs/admin/limitrange/limits.yaml --namespace=limit-examplelimitrange \"mylimits\" created Let’s describe the limits that we have imposed in our namespace.123456789$ kubectl describe limits mylimits --namespace=limit-exampleName: mylimitsNamespace: limit-exampleType Resource Min Max Default Request Default Limit Max Limit/Request Ratio---- -------- --- --- --------------- ------------- -----------------------Pod cpu 200m 2 - - -Pod memory 6Mi 1Gi - - -Container cpu 100m 2 200m 300m -Container memory 3Mi 1Gi 100Mi 200Mi - ABAC限定某个用户能做的事情，比如Alice can do anything to all resources:12345678910&#123; \"apiVersion\":\"abac.authorization.kubernetes.io/v1beta1\", \"kind\":\"Policy\", \"spec\":&#123; \"user\":\"alice\", \"namespace\":\"*\", \"resource\":\"*\", \"apiGroup\":\"*\" &#125;&#125; Bob can just read pods in namespace “projectCaribou”12345678910&#123; \"apiVersion\":\"abac.authorization.kubernetes.io/v1beta1\", \"kind\":\"Policy\", \"spec\":&#123; \"user\":\"bob\", \"namespace\":\"projectCaribou\", \"resource\":\"pods\", \"readonly\":true &#125;&#125; 缺点是，必须在api server启动的时候就传入文件。如果需要对权限做修改，那么必须重启api server才能生效 RBAC之前提到了ABAC比较弱，所以呢1.3出来个新特性，叫RBAC，目前还是Alpha。从名字就能看出来“RBAC” (Role-Based Access Control)，基于角色，有点像OpenStack的角色了 Roles12345678910kind: RoleapiVersion: rbac.authorization.k8s.io/v1alpha1metadata: namespace: default name: pod-readerrules: - apiGroups: [\"\"] # The API group \"\" indicates the default API Group. resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] nonResourceURLs: [] RolesBindings1234567891011121314# This role binding allows \"jane\" to read pods in the namespace \"default\"kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1alpha1metadata: name: read-pods namespace: defaultsubjects: - kind: User # May be \"User\", \"Group\" or \"ServiceAccount\" name: janeroleRef: kind: Role namespace: default name: pod-reader apiVersion: rbac.authorization.k8s.io/v1alpha1 一图胜千言 userA和userB是通过[role_binding1][role1]连接到name space 1，得到在name space1进行操作的权限。userB则是[role_binding2]-&gt;[role2]得到在name space2进行操作的权限。 webhook感觉很强大，是否可以和keystone对接？把OpenStack的多租户能力借鉴过来？ 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.decbug.com/tags/kubernetes/"},{"name":"multi-tenant","slug":"multi-tenant","permalink":"http://blog.decbug.com/tags/multi-tenant/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"在家玩DaoCloud企业版--部署/网络/存储","slug":"play_dce3","date":"2016-07-24T17:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/07/25/play_dce3/","link":"","permalink":"http://blog.decbug.com/2016/07/25/play_dce3/","excerpt":"背景前面分析了系统容器，http://blog.decbug.com/2016/07/25/play_dce2/接下来看看到底是如何部署的，以及网络存储是如何创建的。","text":"背景前面分析了系统容器，http://blog.decbug.com/2016/07/25/play_dce2/接下来看看到底是如何部署的，以及网络存储是如何创建的。 安装去掉–rm ，看看install到底做了什么1docker run -i daocloud.io/daocloud/dce install 不加–rm竟然无法运行，DaoCloud还挺厉害 大概推测一下部署过程吧 daocloud.io/daocloud/dce install 安装compose？ 生成/etc/daocloud/dce/docker-compose.yml docker-compose up ? 网络准备证书docker -H :2375 network ls 查看network 但是提示 没有证书 123docker cp c165f85044a9:/etc/ssl/private/engine/engine-cert.pem /etc/ssl/private/engine/engine-cert.pemdocker cp c165f85044a9:/etc/ssl/private/engine/engine-key.pem /etc/ssl/private/engine/engine-key.pemdocker cp c165f85044a9:/etc/ssl/private/engine/ca.pem /etc/ssl/private/engine/ca.pem 把证书从manager容器里拷贝出来 然后network ls1docker -H :2375 --tls --tlscacert /etc/ssl/private/engine/ca.pem --tlscert /etc/ssl/private/engine/engine-cert.pem --tlskey /etc/ssl/private/engine/engine-key.pem network ls 结果是123456789101112NETWORK ID NAME DRIVERbd796525b91c docker-512mb-sfo2-01/bridge bridge26e3c48a34b9 docker-512mb-sfo2-01/dce_default bridgeb6928df6352f docker-512mb-sfo2-01/host host242e13239dcb docker-512mb-sfo2-01/none null0ea714042165 docker-512mb-sfo2-02/bridge bridgeea7e447dbb71 docker-512mb-sfo2-02/dce_default bridgee61de07d7d1f docker-512mb-sfo2-02/docker_gwbridge bridge38af5aff9349 docker-512mb-sfo2-02/host hostc448a5c9ee19 docker-512mb-sfo2-02/none null48ac6678f478 tty_default overlaybd2f14e19718 ubuntusshttyjs_default overlay 可以看到，自建容器都是用到了overlay，目测用的就是docker原生的overlay 从上图可以看到，果然是原生overlay 存储貌似只能挂本地卷 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"DaoCloud","slug":"DaoCloud","permalink":"http://blog.decbug.com/tags/DaoCloud/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"swarm","slug":"swarm","permalink":"http://blog.decbug.com/tags/swarm/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"在家玩DaoCloud企业版--分析系统容器","slug":"play_dce2","date":"2016-07-24T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/07/25/play_dce2/","link":"","permalink":"http://blog.decbug.com/2016/07/25/play_dce2/","excerpt":"背景DaoCloud是国内领先的容器云，我的山寨容器云需要多向他学习。前几天把环境弄好了，也简单试用了，大概知道DCE技术栈。http://blog.decbug.com/2016/07/20/play_dce/果然是把docker原生技术发挥到了很棒的境界，很值得学习。","text":"背景DaoCloud是国内领先的容器云，我的山寨容器云需要多向他学习。前几天把环境弄好了，也简单试用了，大概知道DCE技术栈。http://blog.decbug.com/2016/07/20/play_dce/果然是把docker原生技术发挥到了很棒的境界，很值得学习。 系统应用有controller，agent，manager，etcd，4个容器从名字上来看 controller应该是nginx+UI+reigstry的组合 agent，应该是swarm agent manager，不用说，是swarm manager吧 etcd，做分布式存储 接下来我一个个exec进去看看 controller容器本来想用ps aux看下进程，竟然提示cmd不存在，看来DaoCloud对为了减少镜像体积，做了很深入的优化。 初步分析当然，这个难不倒我，在/proc/里找到进程ID，然后cat每个进程的cmd，方法find /proc -mindepth 2 -maxdepth 2 -name exe -exec ls -lh {} \\; 2&gt;/dev/null结果 1234567891011121314lrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/1/exe -&gt; /usr/bin/python2.7lrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/6/exe -&gt; /usr/local/bin/dce-nginxlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/7/exe -&gt; /usr/local/bin/dce-streamlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/11/exe -&gt; /usr/sbin/nginxlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/12/exe -&gt; /usr/local/bin/redis-serverlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/15/exe -&gt; /usr/local/bin/dce-controllerlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/27/exe -&gt; /usr/local/bin/dce-streamlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/30/exe -&gt; /usr/local/bin/dce-controllerlrwxrwxrwx 1 root root 0 Jul 25 12:53 /proc/5289/exe -&gt; /usr/local/bin/dce-controllerlrwxrwxrwx 1 root root 0 Jul 25 12:52 /proc/5297/exe -&gt; /usr/local/bin/dce-registrylrwxrwxrwx 1 root root 0 Jul 25 12:52 /proc/5302/exe -&gt; /usr/local/bin/registrylrwxrwxrwx 1 root root 0 Jul 25 12:52 /proc/5309/exe -&gt; /usr/sbin/nginxlrwxrwxrwx 1 root root 0 Jul 25 12:52 /proc/5657/exe -&gt; /bin/bashlrwxrwxrwx 1 root root 0 Jul 25 12:59 /proc/5707/exe -&gt; /usr/bin/find 进程1是python，可能是监控进程 进程6、11、5309，nginx，目测是worker 进程7和27，stream是什么么？记得首页上有个资源使用情况预测吗？ 进程12，redis，看来是用来做持久化了哦 进程15、30、5289， dce-controller，不清楚，还需要分析，难道也是UI？ 5279，5302，为啥有两个registry 后面两个都是我产生的进程，可以忽略。 进一步分析把所有PID的cmdline都cat出来看看12345files=$(find /proc -type f -name 'cmdline' | grep -v 'task' | grep -v \"/proc/cmdline\")for file in $files; do cat $file &gt;&gt; aaa echo \"\" &gt;&gt; aaadone 结果12345678910111213/usr/bin/python/usr/bin/supervisord/usr/local/bin/dce-nginx/usr/local/bin/dce-streamnginx: master process nginx -g daemon off;/usr/local/bin/redis-server *:6379/usr/local/bin/dce-controller/usr/local/bin/dce-stream/usr/local/bin/dce-controller/usr/local/bin/dce-controller/usr/local/bin/dce-registry/usr/local/bin/registryserve/etc/docker/registry/conf.ymlnginx: worker processbash 通过命令行，每个进程的作用就更清晰了再来分析一遍 进程1是python，supervisord，果然是监控进程 进程6、11、5309，nginx，果然是master+worker 进程7和27，stream是什么么？记得首页上有个资源使用情况预测吗？ 进程12，redis，看来是用来做持久化了哦 进程15、30、5289， dce-controller，应该就是UI？还可能会接受各个节点上报的资源使用情况 5279，5302，为啥有两个registry dce-registry 可能是index，用来做权限控制的？ registry就仓库了 推测代码nginx 配置123456789101112131415161718upstream registry &#123; server registry:5000;&#125;upstream ui &#123; server ui:80;&#125;server &#123; listen 80; location /v2/ &#123; proxy_pass http://registry/v2/; &#125; location / &#123; proxy_pass http://ui/;&#125; etcdetcd没有刻意分析的必要，看下启动命令/etcd --name dce-etcd-138.68.2.15 --data-dir /data manager1/swarm manage --replication --engine-refresh-min-interval 5s --engine-refresh-max-interval 10s --tls --tlscacert /etc/ssl/private/engine/ca.pem --tlscert /etc/ssl/private/engine/engine-cert.pem --tlskey /etc/ssl/private/engine/engine-key.pem etcd://dce_etcd_1:2379 比我之前用的swarm多了证书，etcd的地址应该是通过compose的service创建的网络来互联的 agent启动命令1bash /usr/local/bin/supervisord.sh 结合部署节点的命令1bash -c \"$(docker run -i --rm daocloud.io/daocloud/dce join &#123;你的控制器IP&#125;)\" 应该是把控制节点的IP写入到supervisord.sh，然后调用swarm join compose仅仅是猜测，还是不够，还得找出compose来看看，看下到底是怎么写的通过ps aux找到了一个daotunnel，他的启动命令是1/usr/lib/daomonit/daotunnel -log /var/log/daotunnel.log -config /etc/daocloud/daotunnel.yml start docker dce-controller 看来好货都藏在/etc/daocloud/里 源码之下没有密码，慢慢看吧12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879services: agent: depends_on: - etcd environment: - SWARM_ADVERTISE=138.68.2.15:12376 - SWARM_AGENT_ARGS=join etcd://138.68.2.15:12379 - CADVISOR_ARGS=-housekeeping_interval=1m --global_housekeeping_interval=1m -max_housekeeping_interval=10m image: daocloud.io/daocloud/dce-agent:1.3.2 labels: - io.daocloud.dce.version=1.3.2 - io.daocloud.dce.system=build-in - io.daocloud.dce.controller-ip=138.68.2.15 - io.daocloud.dce.host-address=138.68.2.15 ports: - 12376:2376 restart: unless-stopped volumes: - /var/run/docker.sock:/var/run/docker.sock - /sys:/sys:ro - /root:/rootdir:rw controller: depends_on: - swarm-manager - etcd environment: - ETCD_URL=etcd://138.68.2.15:12379 - CONTROLLER_ADVERTISE=138.68.2.15:80 image: daocloud.io/daocloud/dce-controller:1.3.2 labels: - io.daocloud.dce.version=1.3.2 - io.daocloud.dce.system=build-in - io.daocloud.dce.controller-ip=138.68.2.15 - io.daocloud.dce.host-address=138.68.2.15 ports: - 80:80 - 443:443 privileged: true restart: unless-stopped volumes: - /var/local/dce/registry:/var/lib/registry etcd: command: '--name dce-etcd-138.68.2.15 --data-dir /data ' environment: - ETCD_ADVERTISE_CLIENT_URLS=http://138.68.2.15:12379 - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379 - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:12380 - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://138.68.2.15:12380 - ETCD_CORS=* - ETCD_INITIAL_CLUSTER_STATE=new - ETCD_INITIAL_CLUSTER=dce-etcd-138.68.2.15=http://138.68.2.15:12380 image: daocloud.io/daocloud/dce-etcd:1.3.2 labels: - io.daocloud.dce.version=1.3.2 - io.daocloud.dce.system=build-in ports: - 12380:12380 - 12379:2379 restart: unless-stopped volumes: - /var/local/dce/etcd:/data swarm-manager: command: manage --replication --engine-refresh-min-interval 5s --engine-refresh-max-interval 10s --tls --tlscacert /etc/ssl/private/engine/ca.pem --tlscert /etc/ssl/private/engine/engine-cert.pem --tlskey /etc/ssl/private/engine/engine-key.pem etcd://dce_etcd_1:2379 depends_on: - etcd environment: - SWARM_ADVERTISE=138.68.2.15:2375 image: daocloud.io/daocloud/dce-swarm:1.3.2 labels: - io.daocloud.dce.version=1.3.2 - io.daocloud.dce.system=build-in - io.daocloud.dce.controller-ip=138.68.2.15 - io.daocloud.dce.host-address=138.68.2.15 ports: - 2375:2375 restart: unless-stoppedversion: '2' agent比我之前猜测的多了个cadvisor 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"DaoCloud","slug":"DaoCloud","permalink":"http://blog.decbug.com/tags/DaoCloud/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"swarm","slug":"swarm","permalink":"http://blog.decbug.com/tags/swarm/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"高级docker镜像仓库之删除镜像与恢复镜像","slug":"del_restore_docker_image","date":"2016-07-20T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/07/21/del_restore_docker_image/","link":"","permalink":"http://blog.decbug.com/2016/07/21/del_restore_docker_image/","excerpt":"背景看到有容云的AppHouse有删除、恢复镜像的功能，觉得很厉害，打算在我的山寨容器云的仓库上也加上这个功能","text":"背景看到有容云的AppHouse有删除、恢复镜像的功能，觉得很厉害，打算在我的山寨容器云的仓库上也加上这个功能 抓包分析有容云抓包 因为容器间通信肯定会经过docker0，所以抓docker0就够了 1tcpdump -i docker0 -w del_restore.cap 查看AppHouse的registry容器的IP 12345docker ps | grep app# 得到registry的container IDdocker inspect 3a9d50c216de#找到IP \"IPAddress\": \"172.16.52.3\" wireshark加上条件(ip.src == 172.16.52.3) || (ip.dst == 172.16.52.3) &amp;&amp; tcp.port ==5002 &amp;&amp; http 分析包获取镜像信息 获取镜像信息，应该是把返回的body都保存下来了 删除镜像 这个没啥好说 恢复镜像 应该是把之前保存的body又再put进去 官方不建议删除镜像因为https://github.com/docker/distribution/blob/master/ROADMAP.md#deletes NOTE: Deletes are a much asked for feature. Before requesting this feature or participating in discussion, we ask that you read this section in full and understand the problems behind deletes. 删除固然简单，删除manifest和blob就行。但是，blob是分层的，可能是多个镜像共用的，如果在删除某个blob的时候，其他人正在使用这个blob，那么就麻烦了。 其实是有删除接口的123DELETE /v2/&lt;name&gt;/manifests/&lt;reference&gt;Host: &lt;registry host&gt;Authorization: &lt;scheme&gt; &lt;token&gt; 配置文件123456789101112131415161718192021version: 0.1log: fields: service: registrystorage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registry# 这里需要把delelte设置为true delete: enabled: truehttp: addr: :5000 headers: X-Content-Type-Options: [nosniff]health: storagedriver: enabled: true interval: 10s threshold: 3 用python写的测试代码12345678910111213141516171819202122232425262728293031323334353637383940# -*- coding: utf-8 -*import requestsimport simplejson as jsonregistry = \"http://192.168.1.245:25678/v2/\"image = \"test/consul\"tag = \"latest\"r = requests.get(registry + \"_catalog/\", verify=False)print r.textheaders = &#123;'Accept': 'application/vnd.docker.distribution.manifest.v2+json'&#125;r = requests.get(registry + image + \"/manifests/\" + tag, headers=headers, verify=False)# 获取manifestmanifest = r.headers['Docker-Content-Digest']print \"manifest: \" + manifestdata = r.textprint data# for blob in data['fsLayers']:# blob_digest = blob['blobSum']# print blob_digest# r = requests.delete(registry + \"v2/xx/hello/blobs/\" + blob_digest, verify=False)# print r# 删除print \"delete\"r = requests.delete(registry + image + \"/manifests/\" + manifest, verify=False)print r.status_code# 恢复print \"restore\"r = requests.put(registry + image + \"/manifests/\" + tag, data=data, verify=False)print r.status_code 时序图 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"image","slug":"image","permalink":"http://blog.decbug.com/tags/image/"},{"name":"registry","slug":"registry","permalink":"http://blog.decbug.com/tags/registry/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"看harbor源码","slug":"inspect_harbor","date":"2016-07-20T12:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/07/20/inspect_harbor/","link":"","permalink":"http://blog.decbug.com/2016/07/20/inspect_harbor/","excerpt":"背景之前自己搞了个玩具registry，没有权限控制，没有角色，没有统计。正好vmware开源了harbor，号称是企业级仓库，我自然是不会放过，要研究一下。","text":"背景之前自己搞了个玩具registry，没有权限控制，没有角色，没有统计。正好vmware开源了harbor，号称是企业级仓库，我自然是不会放过，要研究一下。 部署官方方法 Install Harbor with the following commands. Note that the docker-compose process can take a while.123456789cd Deploy$ ./prepareGenerated configuration file: ./config/ui/envGenerated configuration file: ./config/ui/app.confGenerated configuration file: ./config/registry/config.ymlGenerated configuration file: ./config/db/envdocker-compose up -d 特殊国情下的模式不建议用，最好还是番茄自己build因为Daoloud和CaiCloud的版本都太老，很多新特性都没有。 离线模式由于公司坑爹的模式，很多镜像下载不了，只好在家pull下来，然后save成tar，再到公司load具体看这链接 架构图 我画的架构图 代码结构通过tree -d ./生成，略去部分不重要代码1234567891011121314151617181920212223242526272829303132333435363738394041├── api│ └── jobs├── auth│ ├── db│ └── ldap├── contrib├── controllers├── dao├── Deploy│ ├── config│ │ ├── db│ │ ├── jobservice│ │ ├── nginx│ │ │ └── cert│ │ ├── registry│ │ └── ui│ ├── db│ ├── kubernetes│ │ └── dockerfiles│ ├── log│ └── templates│ ├── db│ ├── jobservice│ ├── registry│ └── ui├── job│ ├── config│ ├── replication│ └── utils├── jobservice├── models├── service│ ├── cache│ ├── token│ └── utils├── static前端├── tests├── ui├── utils共用组件├── vendor三方库└── views 对应架构图来看 proxy就是nginx，Deploy/config/nginx/nginx.conf UI就是ui/main.go token就是service/token/token.go registry的webhook就是Deploy/templates/registry/config.yml的notifications和auth auth指向beego.Router(&quot;/service/token&quot;, &amp;token.Handler{})，service/token/token.go notification指向beego.Router(&quot;/service/notifications&quot;, &amp;service.NotificationHandler{})，用来同步备份到远端仓库。service/notification.go auth/authenticator.go接口，有本地db和LDAP两种实现，在init时会registrer，根据配置选择用哪个实现。 备份策略这个特性很不错啊，registry有了新的更新，就notify到ui的notification，根据配置的策略，是否要备份到远端registry LDAP用的是open LDAP代码在auth/ldap/ldap.goLDAP_BASE_DN 这个还不会配置 RBACRole Based Access Controlservice/token/authutils.go的FilterAccess，通过token里的scope获取action，再到数据库里查询是否有权限 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"harbor","slug":"harbor","permalink":"http://blog.decbug.com/tags/harbor/"},{"name":"registry","slug":"registry","permalink":"http://blog.decbug.com/tags/registry/"},{"name":"vmware","slug":"vmware","permalink":"http://blog.decbug.com/tags/vmware/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"在家玩DaoCloud企业版","slug":"play_dce","date":"2016-07-19T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/07/20/play_dce/","link":"","permalink":"http://blog.decbug.com/2016/07/20/play_dce/","excerpt":"背景DaoCloud是国内领先的容器云，我的山寨容器云需要多向他学习。以前只用过公有云版本，大概把持续集成持续交付那一块弄明白了。最近发现有DaoCloud企业版，简称DEC，看了下截图，感觉很不错，决定也自己搞一个玩。","text":"背景DaoCloud是国内领先的容器云，我的山寨容器云需要多向他学习。以前只用过公有云版本，大概把持续集成持续交付那一块弄明白了。最近发现有DaoCloud企业版，简称DEC，看了下截图，感觉很不错，决定也自己搞一个玩。 创建机器在DigitalOcean创建两台最低配. 开始安装控制节点也就是master一条命令搞定1bash -c \"$(docker run -i --rm daocloud.io/daocloud/dce install)\" 竟然内存太小，凑着着用12345678910111213141516171819Verifying System compatibility...Requirement Value Note----------------------- ----------------------------- -------------------------------------------------------CPU 1 Recommended more than 4 CPU Core.Memory 489.9921875 MiB WARN: Should be installed where more than 1G memory.Storage For Docker 16.7933425903 GiB Recommended more than 30GB.Network to Controller OK OKNetwork from Controller OK OKOperating System Ubuntu 14.04.4 LTS WARN: Recommended Ubuntu 16.04.Linux Kernel 3.13.0-85-generic Recommended the latest maintained version Linux kernel.Docker Version 1.11.2 OKDocker Storage Driver aufs OKDocker Feature All Supported OKDocker ID MIM2:DL6F:WVJN:UDDF:... OKFirewalld UnKnown Make sure the firewalld has been closed.Host Name docker-512mb-sfo2-01 OKPort 80,443,2375,12376,12380,12379 OKTime 0ms OKSELinux permissive SELinux has been disabled. 容器节点也就是slave看起来像是swarm join在另一台机器上运行 1bash -c \"$(docker run -i --rm daocloud.io/daocloud/dce join &#123;你的控制器IP&#125;)\" 效果 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"DaoCloud","slug":"DaoCloud","permalink":"http://blog.decbug.com/tags/DaoCloud/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"swarm","slug":"swarm","permalink":"http://blog.decbug.com/tags/swarm/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"net-speeder番茄加速","slug":"net_speeder","date":"2016-07-14T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/07/15/net_speeder/","link":"","permalink":"http://blog.decbug.com/2016/07/15/net_speeder/","excerpt":"背景由于流量不够用，又买了个廉价vps，3年只要8刀，64M内存，1G硬盘，250M流量。由于配置比较差，且机房离大陆远，ping有300多ms，看youtube略卡，只好使用net-speeder","text":"背景由于流量不够用，又买了个廉价vps，3年只要8刀，64M内存，1G硬盘，250M流量。由于配置比较差，且机房离大陆远，ping有300多ms，看youtube略卡，只好使用net-speeder 方法安装依赖1234#安装libnet-dev：apt-get install libnet1-dev#安装libpcap-dev：apt-get install libpcap0.8-dev 安装net-speeder12345wget https://github.com/snooda/net-speeder/archive/master.zipunzip master.zipcd net-speeder-master# openvz 用这个命令makesh build.sh -DCOOKED 添加开机启动打开/etc/local.rc，加上1[net_speeder安装目录]/net_speeder venet0:0 \"ip\" 结果不知是不算心理作用，果然不那么卡了 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"番茄","slug":"番茄","permalink":"http://blog.decbug.com/tags/番茄/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"kubernetes:pod内IPC","slug":"docker_kubernetes_IPC_pod","date":"2016-07-02T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/07/03/docker_kubernetes_IPC_pod/","link":"","permalink":"http://blog.decbug.com/2016/07/03/docker_kubernetes_IPC_pod/","excerpt":"要动态更新容器里某些进程的配置，例如nginx。所以需要实时获取配置更新，并同步到容器里的配置文件里，采用的方法是用confd从etcd采集数据，然后更新配置文件的方法。现有的方案是把confd+nginx放在同一个容器里，虽然能解决问题，但是不够优雅，毕竟一个容器只跑一个进程好。恰好业务是跑在k8s上，k8s关于pod的文档上说 Containers within a pod share an IP address and port space, and can find each other via localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and can not communicate by IPC 如果同一个pod里的进程，可以互相看到对方，那么就可以不用修改，直接把现有一个容器拆成两个容器了。","text":"要动态更新容器里某些进程的配置，例如nginx。所以需要实时获取配置更新，并同步到容器里的配置文件里，采用的方法是用confd从etcd采集数据，然后更新配置文件的方法。现有的方案是把confd+nginx放在同一个容器里，虽然能解决问题，但是不够优雅，毕竟一个容器只跑一个进程好。恰好业务是跑在k8s上，k8s关于pod的文档上说 Containers within a pod share an IP address and port space, and can find each other via localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and can not communicate by IPC 如果同一个pod里的进程，可以互相看到对方，那么就可以不用修改，直接把现有一个容器拆成两个容器了。 提前剧透一下结论，是看不到的。因为 The context of the pod can be defined as the conjunction of several Linux namespaces: PID namespace (applications within the pod can see each other’s processes) network namespace (applications within the pod have access to the same IP and port space) IPC namespace (applications within the pod can use SystemV IPC or POSIX message queues to communicate) UTS namespace (applications within the pod share a hostname) In terms of Docker constructs, a pod consists of a colocated group of Docker containers with shared volumes. PID namespace sharing is not yet implemented with Docker. 创建pod创建两个容器的pod12345678910111213141516apiVersion: v1kind: Podmetadata: name: ipc2 labels: app: webspec: containers: - name: registry image: registry ports: - containerPort: 5000 - name: nginx image: nginx:1.9 ports: - containerPort: 80 进入其中一个ps和netstat12345678910111213141516171819202122./kubectl exec -it ipc2 bash# 看进程ps aux# 结果，只能看到registry的进程USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.4 53228 15992 ? Ss 14:56 0:00 /usr/bin/pythonroot 13 1.0 1.0 110492 39600 ? S 14:56 0:03 /usr/bin/pythonroot 14 1.0 0.9 110256 38804 ? S 14:56 0:03 /usr/bin/pythonroot 17 0.9 0.9 110272 38820 ? S 14:56 0:03 /usr/bin/pythonroot 18 1.0 0.9 110276 38816 ? S 14:56 0:03 /usr/bin/pythonroot 44 0.0 0.0 18148 3364 ? Ss+ 15:00 0:00 bashroot 60 2.0 0.0 18152 3192 ? Ss 15:01 0:00 bashroot 74 0.0 0.0 15572 2164 ? R+ 15:01 0:00 ps aux# 看端口root@ipc2:/# netstat -anplt# 结果，网络共享了Active Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:5000 0.0.0.0:* LISTEN -tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - 进入另一个容器进入nginx容器看看进程123456789docker exec -it k8s_nginx.fb0f31c6_ipc2_default_82fd2fb7-42c0-11e6-a4f1-d43d7e2c2527_c689aa68 bashroot@ipc2:/# ps axu# 只能看到nginx的进程USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 31684 5100 ? Ss 14:57 0:00 nginx: master process nginx -g daemon off;nginx 5 0.0 0.0 32068 2904 ? S 14:57 0:00 nginx: worker processroot 6 0.0 0.0 20224 3272 ? Ss 15:00 0:00 bashroot 19 0.0 0.0 17500 2096 ? R+ 15:09 0:00 ps axu 结论网络、UTC、IPC都共享，但是PID不能共享。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.decbug.com/tags/kubernetes/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"kubernetes自定义admission插件","slug":"k8s_admission","date":"2016-06-27T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/28/k8s_admission/","link":"","permalink":"http://blog.decbug.com/2016/06/28/k8s_admission/","excerpt":"背景quotak8s的resourcequota的粒度太粗，只能针对namespace级进行quota。为了实现更细粒度的quota，有必要自制一个admission插件。 ABAC由于ABAC是在api server启动的时候载入，如果有修改，就必须重启api server才能生效。所以我想做个动态ABAC插件，把权限信息保存到etcd","text":"背景quotak8s的resourcequota的粒度太粗，只能针对namespace级进行quota。为了实现更细粒度的quota，有必要自制一个admission插件。 ABAC由于ABAC是在api server启动的时候载入，如果有修改，就必须重启api server才能生效。所以我想做个动态ABAC插件，把权限信息保存到etcd 分析源码代码在plugin/pkg/admission，已有admit, deny, resourcequota等插件。有两个函数需要重点关注 init12345func init() &#123; admission.RegisterPlugin(\"AlwaysAdmit\", func(client clientset.Interface, config io.Reader) (admission.Interface, error) &#123; return NewAlwaysAdmit(), nil &#125;)&#125; 注册AlwaysAdmit，返回值是admission.Interface，注意看admit函数 admit123func (alwaysAdmit) Admit(a admission.Attributes) (err error) &#123; return nil&#125; 自定义插件也要实现一个init，用于注册及返回Interface。然后完成admit函数12345678func (l *myadmission) Admit(a admission.Attributes) (err error) &#123; // 加上我的判断逻辑 if allow &#123; return nil &#125; else &#123; return admission.NewForbidden() &#125;&#125; 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.decbug.com/tags/kubernetes/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"plantuml","slug":"plantuml","date":"2016-06-26T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/06/27/plantuml/","link":"","permalink":"http://blog.decbug.com/2016/06/27/plantuml/","excerpt":"概念架构图即代码PlantUML is a open-source tool that allows to quickly write : Sequence diagram, Usecase diagram, Class diagram, Activity diagram, (here is the new syntax), Component diagram, State diagram, Deployment diagram, Object diagram. wireframe graphical interface","text":"概念架构图即代码PlantUML is a open-source tool that allows to quickly write : Sequence diagram, Usecase diagram, Class diagram, Activity diagram, (here is the new syntax), Component diagram, State diagram, Deployment diagram, Object diagram. wireframe graphical interface 效果 在hexo博客加上plantuml插件install1npm install hexo-tag-plantuml --save add to _config.ymlAnd add this plugin in _config.yml.12plugins: - hexo-tag-plantuml testadd text to markdown file123&#123;% plantuml %&#125; Bob-&gt;Alice : hello&#123;% endplantuml %&#125; test1hexo clean &amp;&amp; hexo generate &amp;&amp; hexo server 效果 公司内网搭建plantuml服务虽然http://plantuml.com/提供了online server，但是由于信息安全问题，不能直接把代码贴到那生成图片，所以需要自己在内网建一个. 选型其实也没啥选的，由于linux机器都被回收，只有自己用的windows办公机，所以只能用windows了。前端用bootstrap+angularjs，好吧，我承认我是前端小白，其实我就只会这哥俩后端就用go的gin框架，原因就是之前用gin写了个玩具，基本可以复用 准备工作 plantuml需要jdk 下载plantuml.jar，进入http://plantuml.com/download.html，下载last version，http://sourceforge.net/projects/plantuml/files/plantuml.jar/download 由于plantuml在生成图片时会用到graphviz，也需要一并下载并安装http://www.graphviz.org/Download_windows.php plantuml会调用graphviz的dot.exe，所以需要增加环境变量GRAPHVIZ_DOT，值就是dot.exe的全路径 java -jar plantuml.jar -testdot，如果返回OK，那么说明安装成功 实现过程启动plantuml1java -jar plantuml.jar 会监控当前目录，如果有.txt等文件的变更，就会生成同名的png 时序图 期间有个比较蛋疼的事，由于golang的string是UTF8，保存到文件也是UTF8，plantuml不识别，总提示语法错误。解决方法: 参考http://mengqi.info/html/2015/201507071345-using-golang-to-convert-text-between-gbk-and-utf-8.html 将string转换成gbk的bytes，然后写入到文件 炫耀花了3个小时搞定，就推荐给周围同事，得到一致好评，大家都可以抛弃visio等图形化工具了。通过markdown实现了设计文档即代码那么通过plantuml实现了架构图即代码文本化，可以版本管理 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"diagram","slug":"diagram","permalink":"http://blog.decbug.com/tags/diagram/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"flannel与overlay","slug":"flannel","date":"2016-06-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/23/flannel/","link":"","permalink":"http://blog.decbug.com/2016/06/23/flannel/","excerpt":"正在搞docker与neutron融合，所以需要储备一些网络虚拟化知识，了解下原理","text":"正在搞docker与neutron融合，所以需要储备一些网络虚拟化知识，了解下原理 overlay我的理解 复用已有物理网络，很容易搭建 有很好的开源组件，比如flannel 需要转发 需要对原报文进行封装和解释，因为会加上overlay的src ip和des ip 性能会损耗 阿里云的大侠们曾做过试验原文链接 Overlay网络的最大问题是性能很不理想。我们做了Overlay网络和非Overlay网络在各种数据包大小情况下的性能对比，tcp payload 20 bytes，Overlay性能大约 75%，tcp payload 1kbytes，Overlay性能80%，对于大块数据传输，Overlay性能大约88%，这个数字可以认为是 Overlay性能的极限了。当然，不同的场景下具体测试数字不一定完全一致，但Overlay的开销还是很大的。 flannelcoreos的又一力作，docker生态常用组网方式 对于原理，我的理解 flannel0网桥，连接docker0和flanneld flanneld通过etcd感知到网络内所有docker IP的变化，知道如果投递到其他宿主机上的flanneld docker daemon启动参数可以限制IP范围，避免冲突 从容器A到另外一台宿主机上的容器B，大概流程 报文到容器A的veth0 再到docker0 转到容器A所在宿主机的flanneld，简称flanneldA flanneldA，所谓的封装，src ip，des ip 投递到容器B所在宿主机的flanneld，简称flanneldB flanneldB解释，获取到des ip，取出原始报文，投递到容器B 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"network","slug":"network","permalink":"http://blog.decbug.com/tags/network/"},{"name":"overlay","slug":"overlay","permalink":"http://blog.decbug.com/tags/overlay/"},{"name":"virtualization","slug":"virtualization","permalink":"http://blog.decbug.com/tags/virtualization/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"玩openstack:1","slug":"openstack_playground_1","date":"2016-06-21T11:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/21/openstack_playground_1/","link":"","permalink":"http://blog.decbug.com/2016/06/21/openstack_playground_1/","excerpt":"背景要基于公司已有的openstack结合docker搞一个好玩的东西，所以又开始撸openstack了，这就需要对虚拟化有个更深入的理解。昨天搞整了一下KVM和vlan，http://blog.decbug.com/2016/06/20/kvm/今天就要在家搞一套openstack开发环境","text":"背景要基于公司已有的openstack结合docker搞一个好玩的东西，所以又开始撸openstack了，这就需要对虚拟化有个更深入的理解。昨天搞整了一下KVM和vlan，http://blog.decbug.com/2016/06/20/kvm/今天就要在家搞一套openstack开发环境 devstackdevstack是一个一键式搭建open stack环境的脚本，如官网所说DevStack is a series of extensible scripts used to quickly bring up a complete OpenStack environment.123456789101112131415161718git clone https://github.com/openstack-dev/devstack.gitcd devstack/# 切换到m版本分支git co stable/mitakacd tools# 创建stack用户sudo bash create-stack-user.sh# cd ../../sudo mv devstack /opt/stacksudo chown -R stack:stack /opt/stack/devstack# switch to stacksudo -isu stack 参照官网在/opt/stack/devstack创建local.conf，内容是记得改host_ip,service_host,PUBLIC_INTERFACE controller1234567891011121314151617181920212223242526272829303132333435363738394041[[local|localrc]]HOST_IP=192.168.1.245SERVICE_HOST=192.168.1.245MYSQL_HOST=192.168.1.245RABBIT_HOST=192.168.1.245GLANCE_HOSTPORT=192.168.1.245:9292PUBLIC_INTERFACE=p1p1ADMIN_PASSWORD=secretMYSQL_PASSWORD=secretRABBIT_PASSWORD=secretSERVICE_PASSWORD=secret## Neutron optionsQ_USE_SECGROUP=TrueENABLE_PROJECT_VLANS=TruePROJECT_VLAN_RANGE=3001:4000PHYSICAL_NETWORK=defaultOVS_PHYSICAL_BRIDGE=br-exQ_USE_PROVIDER_NETWORKING=True# Do not use Nova-Networkdisable_service n-net# NeutronENABLED_SERVICES+=,q-svc,q-dhcp,q-meta,q-agt## Neutron Networking options used to create Neutron SubnetsFIXED_RANGE=\"203.0.113.0/24\"NETWORK_GATEWAY=203.0.113.1PROVIDER_SUBNET_NAME=\"provider_net\"PROVIDER_NETWORK_TYPE=\"vlan\"SEGMENTATION_ID=2010# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git compute node123456789101112131415161718192021222324[[local|localrc]]HOST_IP=192.168.1.148SERVICE_HOST=192.168.1.245MYSQL_HOST=192.168.1.245RABBIT_HOST=192.168.1.245GLANCE_HOSTPORT=192.168.1.245:9292ADMIN_PASSWORD=secretMYSQL_PASSWORD=secretRABBIT_PASSWORD=secretSERVICE_PASSWORD=secret# Services that a compute node runsENABLED_SERVICES=n-cpu,rabbit,q-agt## Open vSwitch provider networking optionsPHYSICAL_NETWORK=defaultOVS_PHYSICAL_BRIDGE=br-exPUBLIC_INTERFACE=p2p1Q_USE_PROVIDER_NETWORKING=True# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git 然后运行1bash /stack.sh 参考http://blog.csdn.net/u011521019/article/details/51114681改成我的实际IP提示12345672016-06-21 14:07:28.255 | ovs-ofctl: br-int is not a bridge or a socket2016-06-21 14:07:28.262 | ovs-ofctl: br-tun is not a bridge or a socket2016-06-21 14:07:28.269 | ovs-ofctl: br-ex is not a bridge or a socket2016-06-21 14:07:28.277 | ovs-ofctl: br-int is not a bridge or a socket2016-06-21 14:07:28.284 | ovs-ofctl: br-tun is not a bridge or a socket2016-06-21 14:07:28.292 | ovs-ofctl: br-ex is not a bridge or a socket2016-06-21 14:07:28.446 | +^[[3242mstack.sh:exit_trap:498 ^[(B^[[m exit 1 说要unstack.sh，然后reboot，再stack.sh，然而还是一样的错 1234# minimal config# devstack generate-subunit failsudo apt-get install python-pipsudo pip install --upgrade pip 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"devstack","slug":"devstack","permalink":"http://blog.decbug.com/tags/devstack/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"在内网写的文章","slug":"blog_huawei","date":"2016-06-20T18:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/21/blog_huawei/","link":"","permalink":"http://blog.decbug.com/2016/06/21/blog_huawei/","excerpt":"说明在内网也写了不少文章，但是由于安全问题，不能搬运出来，只能把标题都记录下来，以免遗忘","text":"说明在内网也写了不少文章，但是由于安全问题，不能搬运出来，只能把标题都记录下来，以免遗忘 install 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://blog.decbug.com/tags/blog/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"2016上半年随笔","slug":"essay20160620","date":"2016-06-20T17:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/21/essay20160620/","link":"","permalink":"http://blog.decbug.com/2016/06/21/essay20160620/","excerpt":"时间已经来到2016的6月底，是时候回顾这上半年的收获与教训","text":"时间已经来到2016的6月底，是时候回顾这上半年的收获与教训 工作 对docker的应用越发纯熟，用registry+swarm+用golang写的一些服务，搞了个持续交付容器云，从代码-&gt;持续集成-&gt;镜像-&gt;仓库-&gt;运行服务 上半年在的部门是研发质量部，主要是基于一些砖家们的YY做了一些没人用的产品。我不断地反对他们的想法，因为我觉得他的方案完全是不可行的，他们都很久不写代码，而且离业务很远，根本不知道业务的情况。反对的次数多了，我们互相之间就两看两相厌。事实证明，我的意见是正确的，他们花了4个月做出来的东西，在演示阶段就被否决了。 这次教训挺深刻的，让我从一个纯粹的技术人员，进化成有产品意识的程序员。技术是解决业务的问题，做出来的东西要有价值，那么什么是价值呢，好吧，其实就是能赚钱。公司是商业组织，目的就是为了盈利。唉。 以前是在百人团队里当技术砖家，就是技术选型，写demo，写核心代码，还有教小朋友写代码，帮他们解决疑难杂症，只需要管技术方面的问题，其他事都不用操心，压力不怎么大。16年上半年算是自己独立带团队了，虽然人不多，但是压力不小，要定技术方案，写代码，画流程图，测试，关注小弟们的进展，把控进度，还要思考产品的价值。 技术上进步不大，但是技术之外的能力进步很大，总体来说，收获还是挺大的。 学习 看书 分布式的书 看了TCP/IP，HTTP协议 容器相关的书 JVM的书 前端，学了angularjs，bootstrap，写了几个小项目练手 英语，整理了计算机英语1500词 更好的工作机会 面了京东云，offer T4 面了阿里云，offer P7 一直在传统行业厮混，没有互联网经验。凭借我自己在家折腾的一些玩具，得到一线互联网公司的认可，也算是证明了我的实力然而在我提了离职之后，父亲得了重病住院。此病几乎就是不治之症，只能缓解并发症，延长存活时间。母亲一人照顾不过来，我不能那么自私，抛下家里去北京。本打算7月去北京工作，但由于父亲生病，暂时去不了，不得不放弃这个机会。希望以后有机会再去互联网公司干一番事业悲剧的是，我提离职了却去不了北京，几乎就要失业。好在我司这边还有部门愿意接收我，不然我就要失业一段时间。其实挺感激的，对我来说算是雪中送炭吧。在接下来的工作中，我要好好努力另外，还要感谢我自己，一直都在学习进步，保持了足够的竞争力。只要有实力，就不用担心工作的事，一大堆职位等着我挑选 买房还是在西安买房了。本打算买了房就去北京的，然后几年之后再回西安。然而计划总是赶不上变化，早知如此，就不买了。好在买的房还可以，也算是有所收获吧 位置比较偏，但小区门口就是地铁，也还算方便。 小区里的小学已拿到政府批文，正在建造。旁边有初中和一般高中，还有某一流高中的分校，教育资源貌似还可以。 附近正在建一家三甲医院 小区旁边有个万象城，商业也还可以 2011年来到西安工作，至今已经4年半，在家里负担比较重的情况下，能在5年之内搞定二套房，也还算可以。 希望这次的选择是正确的 买车下半年把驾照搞定，到明年过年的时候整辆小车车开 下半年计划 英语必然不能落下，要继续听说读 底层原理还是不够熟悉，打算把那几本神书再翻一遍 接下来的工作是基于华为云做Docker相关的产品。OpenStack和Docker都是分布式系统的经典之作，我要在这个过程中，把分布式架构/网络/存储搞懂 想有一个代表作，一个由我设计，架构，开发的产品 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}],"tags":[{"name":"essay","slug":"essay","permalink":"http://blog.decbug.com/tags/essay/"}],"keywords":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}]},{"title":"学习KVM与网络虚拟化","slug":"kvm","date":"2016-06-19T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/06/20/kvm/","link":"","permalink":"http://blog.decbug.com/2016/06/20/kvm/","excerpt":"背景要基于公司已有的openstack结合docker搞一个好玩的东西，所以又开始撸openstack了，这就需要对虚拟化有个更深入的理解。那么从KVM开始，是一个不错的选择。","text":"背景要基于公司已有的openstack结合docker搞一个好玩的东西，所以又开始撸openstack了，这就需要对虚拟化有个更深入的理解。那么从KVM开始，是一个不错的选择。 KVM基础概念 虚拟化的三种类型，1型，2型，进程虚拟化 KVM是2型，是运行在操作系统之上的 docker就是进程虚拟化，直接用host的内核 安装KVM1234567sudo apt-get install qemu-kvm qemu-system libvirt-bin virt-manager bridge-utils vlan# 查看是否支持虚拟化，要返回vmxegrep -o '(vmx|svm)' /proc/cpuinfo# 查看是否安装成功sudo service libvirt-bin status 启动虚拟机下载镜像cirros-0.3.4-x86_64-disk.img，拷贝到cp cirros-0.3.4-x86_64-disk.img /var/lib/libvirt/images/ 123sudo virt-manager# 图形界面，创建虚拟机 网络虚拟化nat和br vlan 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"kvm","slug":"kvm","permalink":"http://blog.decbug.com/tags/kvm/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"hexo通过travis CI自动发布","slug":"hexo_travis","date":"2016-05-30T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/05/31/hexo_travis/","link":"","permalink":"http://blog.decbug.com/2016/05/31/hexo_travis/","excerpt":"背景github pages支持jekyll自动发布，只要修改了post的md，就会自动生成gh-pages。但不支持hexo，所以需要通过第三方的系统来执行hexo generate并把生成的静态页面push到gh-pages。之前用过Travis ci，感觉不错，打算继续用它。","text":"背景github pages支持jekyll自动发布，只要修改了post的md，就会自动生成gh-pages。但不支持hexo，所以需要通过第三方的系统来执行hexo generate并把生成的静态页面push到gh-pages。之前用过Travis ci，感觉不错，打算继续用它。 通过github帐号登录travis ci，把博客的repo加入到左边的My Repositories 在博客repo编写.travis.yml，用于编排 在github-setting-personal token-生成一个只能访问public repo的token 在travis ci的Repositories添加环境变量DEPLOY_REPO， https://{token}@github.com/{你的用户名}/{你的repo名}.git 1git clone --depth 1 --branch gh-pages --single-branch $DEPLOY_REPO . || (git init &amp;&amp; git remote add -t gh-pages origin $DEPLOY_REPO) PS: travis ci的日志放在aws s3上，所以要先番茄才能看到日志哦 参考http://www.jianshu.com/p/e22c13d85659 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://blog.decbug.com/tags/blog/"},{"name":"travis","slug":"travis","permalink":"http://blog.decbug.com/tags/travis/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"一切脱离业务的设计都是YY","slug":"biz_and_req","date":"2016-05-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/05/29/biz_and_req/","link":"","permalink":"http://blog.decbug.com/2016/05/29/biz_and_req/","excerpt":"背景现在是在工具团队，做的产品都是给业务来用的，业务就是我们的客户。那么业务又是什么呢？业务就是给公司赚钱的产品。然而有时候，我们的专家们却总是脱离业务来YY方案，然后做出一些令人难以理解的产品。","text":"背景现在是在工具团队，做的产品都是给业务来用的，业务就是我们的客户。那么业务又是什么呢？业务就是给公司赚钱的产品。然而有时候，我们的专家们却总是脱离业务来YY方案，然后做出一些令人难以理解的产品。 业务又到了一年一度组里领导和专家们YY方案的时候。在他们做4月份里程碑的时候，我就提出，这个方案不靠谱，甚至采用了不参与架构设计不参与开发来威胁，然而还是没有挡住。因为这个方案，都是基于他们的YY，完全脱离了业务。果然，等到验收的时候，业务完全不认可，只能推倒重来。 互联网公司的工具团队曾看过知乎，豆瓣，滴滴，京东的工具，他们都是属于平台部门，里边都是高手。给全公司提供监控，部署，性能优化，日志分析，以及各种牛逼中间件。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"business","slug":"business","permalink":"http://blog.decbug.com/tags/business/"},{"name":"requirement","slug":"requirement","permalink":"http://blog.decbug.com/tags/requirement/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"读tinyhttpd源码笔记","slug":"tinyhttpd","date":"2016-05-08T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/05/09/tinyhttpd/","link":"","permalink":"http://blog.decbug.com/2016/05/09/tinyhttpd/","excerpt":"背景C语言实现的http server，代码简短，看完可以明了原理。","text":"背景C语言实现的http server，代码简短，看完可以明了原理。 流程 startup，创建socket，bind，listen accept request 获取请求，读header 是否GET 或 POST 读content length 写header 200 GET就serve file，cat index.html 到 send POST就创建pipe执行脚本，结果send 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"httpserver","slug":"httpserver","permalink":"http://blog.decbug.com/tags/httpserver/"},{"name":"tinyhttpd","slug":"tinyhttpd","permalink":"http://blog.decbug.com/tags/tinyhttpd/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"读memcache源码笔记","slug":"memcache","date":"2016-05-03T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/05/04/memcache/","link":"","permalink":"http://blog.decbug.com/2016/05/04/memcache/","excerpt":"背景memcache应用很广泛，听说内存管理做的很好，以及通过事件驱动的方式效率很高，于是找来看看。","text":"背景memcache应用很广泛，听说内存管理做的很好，以及通过事件驱动的方式效率很高，于是找来看看。 内存举例子，疯狂动物城里有各种体型的动物，分别安置在不同的城区的街道上的房子里。例如小老鼠在微型动物区，朱迪在小动物区，牛局长在大动物区，大象在大型动物区。 先划分城区 再修路 再盖房子 分配房间 盖好的房子不拆，如果拆了再盖，会浪费资源。内存释放分配的开销很大 流程 总结 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://blog.decbug.com/tags/cache/"},{"name":"memcache","slug":"memcache","permalink":"http://blog.decbug.com/tags/memcache/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"读架构漫谈有感","slug":"architectrue_kevin","date":"2016-05-02T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2016/05/03/architectrue_kevin/","link":"","permalink":"http://blog.decbug.com/2016/05/03/architectrue_kevin/","excerpt":"前言来自聊聊架构公众号的系列文章，作者kevin老师。读过之后大开眼界，获益良多。于是再读几遍，记录一下感想。","text":"前言来自聊聊架构公众号的系列文章，作者kevin老师。读过之后大开眼界，获益良多。于是再读几遍，记录一下感想。 一：什么是架构起源 人多了，就会有分工 人类社会，每个人做擅长的事，与他人进行交换 很多人组成了整体 架构 定界 分工，分块 将模块组合为整体 摘要 这个时候人们对建筑的需求也就慢慢的越来越多，空间的切分也会变成很多种，组合的方式也会有很多种，比如每个人住的房子，群居所产生的宗教性质的房子，集体活动的房子等等。这个时候人们就开始有意识的去设计房子，架构师就慢慢的出现了。一切都是为了满足人的越来越高的需求，提升质量，减少时间，更有效率的切分空间，并且让空间之间更加有机的进行沟通。这就是建筑的架构以及建筑的架构的演变 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"architecture","slug":"architecture","permalink":"http://blog.decbug.com/categories/architecture/"}],"tags":[{"name":"architecture","slug":"architecture","permalink":"http://blog.decbug.com/tags/architecture/"}],"keywords":[{"name":"architecture","slug":"architecture","permalink":"http://blog.decbug.com/categories/architecture/"}]},{"title":"各种锁:自旋锁/互斥锁/读写锁/分布式锁","slug":"lock","date":"2016-04-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/04/29/lock/","link":"","permalink":"http://blog.decbug.com/2016/04/29/lock/","excerpt":"锁锁在计算机的世界里随处可见，当大家都想操作一个资源的时候，如果一窝蜂涌进来，就会出事的。举个例子，加入说有2个线程都在操作一个共享资源（一个int），给他+1。我们知道+1不是原子操作，所谓原子操作，就是如果这个操作开始执行了，那么就不会被打断。看过汇编的同学都知道，+1需要先mov然后在add，如线程1mov了，然后执行线程2的mov，就会出问题。轻则数据错误，重则程序崩溃。感觉这个例子不太恰当，还是领会精神吧。为了保护我们的操作，那么就需要使得这个共享资源的操作变成原子的，这就需要锁了。在并发编程中，尽量少用锁，能不用就不用，因为锁的开销很大很大。首先在业务层面进行分隔，尽量让不同的执行单元操作各自独立的数据，如果不可避免要用到锁，那么锁的范围要尽量小。","text":"锁锁在计算机的世界里随处可见，当大家都想操作一个资源的时候，如果一窝蜂涌进来，就会出事的。举个例子，加入说有2个线程都在操作一个共享资源（一个int），给他+1。我们知道+1不是原子操作，所谓原子操作，就是如果这个操作开始执行了，那么就不会被打断。看过汇编的同学都知道，+1需要先mov然后在add，如线程1mov了，然后执行线程2的mov，就会出问题。轻则数据错误，重则程序崩溃。感觉这个例子不太恰当，还是领会精神吧。为了保护我们的操作，那么就需要使得这个共享资源的操作变成原子的，这就需要锁了。在并发编程中，尽量少用锁，能不用就不用，因为锁的开销很大很大。首先在业务层面进行分隔，尽量让不同的执行单元操作各自独立的数据，如果不可避免要用到锁，那么锁的范围要尽量小。 自旋锁vs互斥锁举个例子 互斥锁：假如说你想进入一个房间，但是这个房间里已经有人了。那么就进不去，这个时候你就先睡一觉，等里边的人出来把你叫醒，然后你再进去。 自旋锁：还是这个房间，房间里有人，你不会睡着，只会每过一分钟就看房间里的人出来了么，如果没出来，那么就继续不停查看。如果出来了，你就进去。 对应到系统，就是你这个线程想获取这个锁，但是这个锁被别的线程持有了，那么你这个线程就得休眠，等待锁释放后再被唤醒。要知道，休眠再唤醒的开销很大，所以就出了自旋锁。自旋锁不会休眠，会不停的尝试。 类 特征 使用场景 自旋 不会休眠，不停重试，直到获得锁 多核，如果单核的话，就一直自旋，执行线程反而得不到时间片。锁住的代码执行时间很短。因为休眠再唤醒的开销很大。如果时间短，那么自旋的开销就很小。要多核 互斥 休眠，等锁被释放才会被唤醒 锁住的代码要执行很久，如果是自旋锁，就会不停尝试，被锁住的代码分不到足够的时间片，但是性能下降 读写锁场景：读多写少条件： 只要没有写锁，就能获取到读锁 只有没有任锁，才能获取到写锁 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"lock","slug":"lock","permalink":"http://blog.decbug.com/tags/lock/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"阿里面试经历","slug":"interview_aliyun","date":"2016-04-10T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/04/11/interview_aliyun/","link":"","permalink":"http://blog.decbug.com/2016/04/11/interview_aliyun/","excerpt":"背景之前一直都在通信行业撸代码，做的都是C/C++，感觉提升不大，所以打算往互联网转型，看看百万千万用户的产品是如何做出来的。于是在拉勾上投了阿里云。","text":"背景之前一直都在通信行业撸代码，做的都是C/C++，感觉提升不大，所以打算往互联网转型，看看百万千万用户的产品是如何做出来的。于是在拉勾上投了阿里云。 阿里云面试记录三轮（也许可以算四轮）技术面，一轮boss面，一轮hr，据说还有一轮hr的大boss价值观面试 一轮感觉是一位管理者，可能脱离技术一段时间，问的问题都是根据简历来的。 先是问项目经验，期间问到几次，为啥要重复造轮子。 docker run的原理，流程 dockerfile，docker build原理 C++虚函数，引用指针， 手写HashMap AngularJS绑定的原理 并发，我说锁啊，然后忽悠一大堆。后问如何提高性能，我说如果业务允许，应该让每个执行实例独立，不要共享资源，减少竞争 弹性伸缩 一致性 二轮好像是一位P8，曾在外面看过这个名字，title是高级专家 聊我之前的一个项目，关于我做的一个数据挖掘工具的消息推送模块的优化讨论，消息队列，锁 STL remove和erase的区别 vector构造析构 HIVE HBASE 我说给测试团队写过自动化测试框架，质疑说为啥需要自己写。我说业务啊，windows的啊，环境啊等等 基于一个随机读，追加写的文件系统，做一个KV存储系统，有增删改查的功能。这个比较好玩。 我说如果不考虑性能的话，我第一版会采用，每个K就对应一个文件，把V写到这个文件里，先实现功能，交付出去，接口调通，之后再进行优化。面试官说，快速完成的想法不错，那么后面该如何优化呢 第二版，增加索引，保存K，V的长度，V到数据文件，保存K，该K对应V在数据文件中的偏移到索引文件，面试官说如果有改的请求，就需要重写整个索引文件，性能会差。我说，是的，接下来我会继续优化。 第三版，如果内存够大，或者数据不会太多，那么把索引保存到内存中，省去重建索引文件的性能损耗。面试官说，内存不会太大。 第四版，针对K进行hash，每个hash对应一个文件夹，文件夹里是索引文件和数据文件，通过hash可缩短搜索路径。 第五版，可以把索引放到redis中，面试官说，不能用redis。我就说定时把索引文件快照到磁盘，面试官说不行，掉电就还是会丢数据。 数据文件中保存K L V，只有数据文件写入成功，才更新内存中的索引。即使掉电了，也能从数据文件中重建索引。 增加缓存，把热点索引保存在内存中，如内存未命中，则根据用户传入的K，从数据文件中恢复索引到内存中，冷索引则从内存中剔除。 go中map中 map[a].b = 1能生效吗，我说我不记得了，但如果你这么问，那么肯定是不能，因为可能是值，不是引用，指向的不是内存。 面完之后，让我等消息 三轮之前两轮面试说我技术不错，能力不错，经验不错，对技术也有热情，可惜工作经验不匹配，所以把我推荐到别的组，于是需要再做一轮技术面试。 PHP，我说我用过wordpress和phpwind，且做一个小的图片生成系统 python，django和flask 如何监控很多台机器，我说我看过小米open falcon的实现，在每台机器上装个agent 如何控制很多台机器，我说可以参考ansible，添加到ssh的可信里，然后通过ssh来控制 spring的原理 linux熟不熟，问了几个命令 问我会哪些脚本语言，都用来做过啥。我说shell powershell python 给出一个场景，分析并解决。场景好像很简单，我一下就解决了。我在此基础上发挥了一下，提出要总结，下次遇到类似问题的时候就可以很快查到。还可以给用户提供一键式解决办法，这样可以一劳永逸。 因为之前两轮技术面都太惨烈，所以这一轮似乎没问太多复杂的问题。这一轮基本上没啥问题了，后面就是BOSS和HR了 后来又面了一次，主要是谈了一些产品方面的问题，还有我的技术爱好 部门BOSS 主要是问当前工作，手下带了几个兄弟，我说之前是带100多，但我只需要管技术，不用管理。今年开始独立带人，组建团队。感觉很痛苦，要招聘，要带徒弟，要规划产品，还要写代码。 在产品开发运营过程中的难题，我说最难的就是如何抓住用户的痛点，用平滑的方式解决痛点，不能让用户抵触。 以及问了我对阿里云某些产品的看法，然后我就说了下对于学习aws的一些心得，顺便吐槽了阿里云。 再就是介绍他的团队以及产品，还有未来的规划。说了优点也说了缺点，而不像以前接触过的一些光吹牛的面试官。 HR问工作经历，之前每次跳槽的原因。为何想来阿里之类的。 HR的BOSS有点像背景调查，问是否统招啊之类的 offer拿下 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"career","slug":"career","permalink":"http://blog.decbug.com/tags/career/"},{"name":"interview","slug":"interview","permalink":"http://blog.decbug.com/tags/interview/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"京东面试经历","slug":"interview_jd","date":"2016-04-09T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/04/10/interview_jd/","link":"","permalink":"http://blog.decbug.com/2016/04/10/interview_jd/","excerpt":"京东云面试记录从通信行业转型到互联网，对云，分布式，高并发感兴趣，想搞底层。于是在拉勾投了京东云。面试分4轮，四位面试官分别是架构师、部门老大、大boss 、hr。","text":"京东云面试记录从通信行业转型到互联网，对云，分布式，高并发感兴趣，想搞底层。于是在拉勾投了京东云。面试分4轮，四位面试官分别是架构师、部门老大、大boss 、hr。 总体感觉，面试官都很友善，我平时比较不善言语，这次在面试官的引导之下，交流比较顺畅。 架构师先开始闲聊，平时看哪些技术网站啊，我说我是面向GitHub so 谷歌编程，然后聊了聊番茄手段，我说自己弄vps ，家里的路由。之后进入正题，问的问题比较偏原理。比如 linux的文件权限是如何实现的， 一个hello world程序是如何运行起来的（我回答先把可执行文件加载到进程的代码段，之后执行，然后我讲了讲进程地址空间的一些事，感觉面试官对我的回答不太满意。经提醒，我才明白是要讲fork，我大概说了下，可惜忘了说写时复制。 磁盘空间有空余，然而创建文件失败，是什么原因。我开始没答上来，然后就提示我是否知道，我说可以理解为索引。但还没答上来，后来架构师告诉我是inode space 不足。 设计一个系统，restful 接口，｛num ，返回对应的斐波纳契数组。我说先实现功能，不能用递归，栈溢出就惨了。日志的话，我说可以玩elk（因为我刚在家玩了下），但面试官想听到日志轮转，我回答一般日志库都可以设置单个文件上限，达到这个值就会创建新文件。还有选型，我说最近用了gorilla mux 。经提醒，我还忘了异常保护。还忘了，可以把每次结果缓存到redis中，如果下次有同样的请求，就可以从redis中直接取值并返回，这样性能会高。 总体来说，我没答好。但好在我在提醒之下都能跟上思路，所以勉强过关了吧。 部门老大先是简单聊了聊之前的项目经验，这个就不赘述了。之后是两个系统设计问题 设计一个用户登录注册系统。我说先来一个最简单的，单表单应用。当用户多了，就水平扩展服务，把服务发现做好，因为服务是无状态的。如果数据库有压力，就分表。由于用户系统可能是读取多于写入，所以可以搞写库，多个读库。写库可以加主备。最好再加个用户登录行为分析，如果突然变了地理位置，可以警告。这个是我看到的常用套路，也不知道面试官是否满意。 设计一个电梯系统。我说我做开发的一般喜欢先用一个简单粗暴的方法完成功能。我说记录每个电梯的运行状态，以及个楼层有坐电梯的请求，是到哪一层，可以放到请求列表。遍历列表，找到最近的电梯，然后调度过来。之后再统计电梯的运行数据，找出规律，比如上班高峰期，下班高峰期该如何调度。后来面试官问到如何让电梯的运行负载都均衡，我说暂时没有好的办法，我会给每个电梯设置一个角色，然后每天定时给电梯的角色互换。虽然某一天某个电梯会特别忙，但总体来看，负载会是均衡的。偏理论的东西居多，我看过的书也发挥作用了。对了，最后还问我最近看了啥书，我说正在读第二遍性能之巅。 大boss问的问题是偏团队管理，人员培养，以及产品落地的问题。我说我觉得招聘很难，招到合适的人不容易，招人的标准已经降低了，只要脑子灵活，工作认真，就可以。因为一个人工作不负责，就需要周围的人给他填坑，严重影响团队。关于人员培养，我说我喜欢主动学习，独立解决问题的人，并且会分享的同学，这样团队的技术氛围好了，大家水平提高很快，刻意的培训其实价值不大。产品落地，需要抓住用户的痛点，我们的产品能给用户带来收益，大家双赢。后来问我最近工作中的困惑，我说最近对于项目进度的把控做的不好，组里小伙子干活比较慢，我前端不熟，对于这个进度不知是否合理，我不喜欢逼着小伙子们加班，说白了还是我的技术水平不够，还需要积累。如果我确定这个速度不合理，就可以硬下心肠给小伙子们压力了。 hr问工作经历，教育背景，离职原因，当前薪资，期望薪资等等 offer拿下。然后之前一直都是通信行业，写C写C++，虽然号称全栈，会很多语言，做过很多领域。但和互联网产品的差异还是很大的，没有相关工作背景，被压价是不可避免的。还得继续努力啊。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"career","slug":"career","permalink":"http://blog.decbug.com/tags/career/"},{"name":"interview","slug":"interview","permalink":"http://blog.decbug.com/tags/interview/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(6)-swarm","slug":"docker_swarm","date":"2016-03-26T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/03/27/docker_swarm/","link":"","permalink":"http://blog.decbug.com/2016/03/27/docker_swarm/","excerpt":"背景正在撸自己的容器云，目前的业务不是复杂，所以做法比较土：自己管理集群，调用每个节点的docker daemon remote API来创建/启动/停止/删除镜像及容器，虽然简单，但是需要自己做集群管理（都还没上服务发现），比较麻烦。此后打算用k8s，但由于其他原因，暂时搁置。后来咨询swarm的maintainer线超博，以及DaoCloud的高手们，决定采用swarm","text":"背景正在撸自己的容器云，目前的业务不是复杂，所以做法比较土：自己管理集群，调用每个节点的docker daemon remote API来创建/启动/停止/删除镜像及容器，虽然简单，但是需要自己做集群管理（都还没上服务发现），比较麻烦。此后打算用k8s，但由于其他原因，暂时搁置。后来咨询swarm的maintainer线超博，以及DaoCloud的高手们，决定采用swarm 采用swarm的原因 自带服务发现，不用我自己弄 和docker daemon remote API的基本相同，仅有的差异请参照官方文档，基本可以复用原来的代码 虽然这次用了swarm，但有机会的话我还是想会继续安利k8s，毕竟k8s更好玩一些 安装节点分配 主机名 IP 角色 i3 192.168.1.245 sonsul,manage0,node g540 192.168.1.148 manage1,node g640 192.168.1.241 node g530 192.168.1.173 node 这里的主机名，都是我的机器的CPU型号，这几台机器都是我收购来的二手台式机，IP是openwrt自动分配的，貌似是hash算出来的，是个固定值。 暴露docker daemon的端口swarm应该也是调用每个节点的remote API吧，所以需要暴露端口 打开/etc/default/docker，在DOCKER_OPTS加上1-H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock 记住这个暴露的端口号，后面会用到，我这里是4243 启动consul在i3上执行1docker run --restart always -d -p 8500:8500 --name=consul progrium/consul -server -bootstrap 启动consul，端口是8500 启动manager0还是i31docker run --restart always -d -p 4000:4000 swarm manage -H :4000 --replication --advertise 192.168.1.245:4000 consul://192.168.1.245:8500 advertise的IP就是i3自身的IP，相当于告诉consul，我是manage，这是我的IP和端口consul就是之前在i3上创建的consul的IP和端口 启动manager1官网把这个叫secondary Swarm manager，领会精神即可这次是在g540上执行1docker run --restart always -d swarm manage -H :4000 --replication --advertise 192.168.1.148:4000 consul://192.168.1.245:8500 consul，还是i3上运行的consuladvertise 是manager1，也就是自己的IP和端口 启动node在4个节点上分别运行1docker run --restart always -d swarm join --advertise=自己的IP:4243 consul://192.168.1.245:8500 这里的4243就是之前暴露的docker daemon的端口了 在i3上查看info1docker -H :4000 info 这里表示，docker会向本机的4000端口发请求，也就是我们最开始启动manager0的时候声明的端口。可以看到1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Containers: 19 Running: 19 Paused: 0 Stopped: 0Images: 26Server Version: swarm/1.1.3Role: primaryStrategy: spreadFilters: health, port, dependency, affinity, constraintNodes: 4 g530: 192.168.1.173:4243 └ Status: Healthy └ Containers: 8 └ Reserved CPUs: 0 / 2 └ Reserved Memory: 0 B / 3.969 GiB └ Labels: executiondriver=native-0.2, kernelversion=3.19.0-25-generic, operatingsystem=Ubuntu 14.04.3 LTS, storagedriver=aufs └ Error: (none) └ UpdatedAt: 2016-03-27T09:46:45Z g540: 192.168.1.148:4243 └ Status: Healthy └ Containers: 4 └ Reserved CPUs: 0 / 2 └ Reserved Memory: 0 B / 3.93 GiB └ Labels: executiondriver=native-0.2, kernelversion=3.19.0-25-generic, operatingsystem=Ubuntu 14.04.4 LTS, storagedriver=aufs └ Error: (none) └ UpdatedAt: 2016-03-27T09:47:02Z g640: 192.168.1.241:4243 └ Status: Healthy └ Containers: 4 └ Reserved CPUs: 0 / 2 └ Reserved Memory: 0 B / 3.739 GiB └ Labels: executiondriver=native-0.2, kernelversion=3.19.0-25-generic, operatingsystem=Ubuntu 14.04.4 LTS, storagedriver=aufs └ Error: (none) └ UpdatedAt: 2016-03-27T09:46:56Z i3: 192.168.1.245:4243 └ Status: Healthy └ Containers: 3 └ Reserved CPUs: 0 / 4 └ Reserved Memory: 0 B / 16.12 GiB └ Labels: executiondriver=native-0.2, kernelversion=3.19.0-25-generic, operatingsystem=Ubuntu 14.04.3 LTS, storagedriver=aufs └ Error: (none) └ UpdatedAt: 2016-03-27T09:47:17ZPlugins: Volume: Network:Kernel Version: 3.19.0-25-genericOperating System: linuxArchitecture: amd64CPUs: 10Total Memory: 27.76 GiB 很帅吧 测试获取当前正在运行的容器1curl -X GET http://192.168.1.245:4000/containers/json 返回12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[ &#123; \"Id\":\"b7919e7e49b1fc580f046734ab6eba53435200a9b07a1f75b176afe6663ee573\", \"Names\":[ \"/i3/consul\" ], \"Image\":\"progrium/consul\", \"Command\":\"/bin/start -server -bootstrap\", \"Created\":1459070754, \"Status\":\"Up About an hour\", \"Ports\":[ &#123; \"IP\":\"\", \"PrivatePort\":8301, \"PublicPort\":0, \"Type\":\"udp\" &#125;, &#123; \"IP\":\"192.168.1.245\", \"PrivatePort\":8500, \"PublicPort\":8500, \"Type\":\"tcp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":8301, \"PublicPort\":0, \"Type\":\"tcp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":8302, \"PublicPort\":0, \"Type\":\"udp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":8300, \"PublicPort\":0, \"Type\":\"tcp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":53, \"PublicPort\":0, \"Type\":\"tcp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":53, \"PublicPort\":0, \"Type\":\"udp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":8400, \"PublicPort\":0, \"Type\":\"tcp\" &#125;, &#123; \"IP\":\"\", \"PrivatePort\":8302, \"PublicPort\":0, \"Type\":\"tcp\" &#125; ], \"SizeRw\":0, \"SizeRootFs\":0, \"Labels\":&#123; &#125;, \"NetworkSettings\":&#123; \"Networks\":&#123; \"bridge\":&#123; \"IPAMConfig\":null, \"Links\":null, \"Aliases\":null, \"NetworkID\":\"\", \"EndpointID\":\"3527825ec17c51e77cfe005a7bf364e2d2b8777dc500cd7554309e855fcc5395\", \"Gateway\":\"172.17.0.1\", \"IPAddress\":\"172.17.0.2\", \"IPPrefixLen\":16, \"IPv6Gateway\":\"\", \"GlobalIPv6Address\":\"\", \"GlobalIPv6PrefixLen\":0, \"MacAddress\":\"02:42:ac:11:00:02\" &#125; &#125; &#125; &#125;] 可以看到，和以前的remote API获取到的基本相同，只是在IP那里，从0.0.0.0变成了实际的IP pull一个镜像1curl -X POST http://192.168.1.245:4000/images/create?fromImage=ubuntu 整一个容器试试1234567891011121314# 创建curl -X POST -H \"Content-Type: application/json\" -d '&#123;\"Image\":\"registry:2.2.1\"&#125;' http://192.168.1.245:4000/containers/create# 记录返回的id# 启动#curl -X POST http://192.168.1.245:4000/containers/(id)/startcurl -X POST http://192.168.1.245:4000/containers/69e61f836c2fad4cf29a0f37c2b4575e267b45c2931737152ef6f40a9d8a4279/start# stopcurl -X POST http://192.168.1.245:4000/containers/69e61f836c2fad4cf29a0f37c2b4575e267b45c2931737152ef6f40a9d8a4279/stop# removecurl -X DELETE http://192.168.1.245:4000/containers/69e61f836c2fad4cf29a0f37c2b4575e267b45c2931737152ef6f40a9d8a4279?v=1 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"docker-swarm","slug":"docker-swarm","permalink":"http://blog.decbug.com/tags/docker-swarm/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(5)-kubernetes","slug":"docker_kubernetes","date":"2016-02-27T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/02/28/docker_kubernetes/","link":"","permalink":"http://blog.decbug.com/2016/02/28/docker_kubernetes/","excerpt":"背景需要做一个容器云，有同事在撸mesos+marathon+chronos，我就顺便折腾下kubernetes。","text":"背景需要做一个容器云，有同事在撸mesos+marathon+chronos，我就顺便折腾下kubernetes。 kubernetes简介 Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能 Kubernetes 是来自 Google 云平台的开源容器集群管理系统。基于 Docker 构建一个容器的调度服务。该系统可以自动在一个容器集群中选择一个工作容器供使用。 感觉像是Docker版PaaS版的OpenStack。OpenStack对外提供VM，Kubernetes则对外提供基于docker的服务。 安装下载包由于被墙，所以先把这几个包下载下来1234567891011wget https://github.com/coreos/etcd/releases/download/v3.0.1/etcd-v3.0.1-linux-amd64.tar.gzwget https://github.com/coreos/flannel/releases/download/v0.5.5/flannel-0.5.5-linux-amd64.tar.gzwget https://github.com/kubernetes/kubernetes/releases/download/v1.3.0/kubernetes.tar.gzwget https://storage.googleapis.com/kubernetes-release/easy-rsa/easy-rsa.tar.gzcp etcd-v3.0.1-linux-amd64.tar.gz ~/code/kubernetes/cluster/ubuntu/etcd.tar.gzcp flannel-0.5.5-linux-amd64.tar.gz ~/code/kubernetes/cluster/ubuntu/flannel.tar.gzcp kubernetes.tar.gz ~/code/kubernetes/cluster/ubuntu/kubernetes.tar.gzcp easy-rsa.tar.gz ~/code/kubernetes/cluster/ubuntu/easy-rsa.tar.gzexport KUBE_VERSION=1.3.0 &amp;&amp; export FLANNEL_VERSION=0.5.5 &amp;&amp; export ETCD_VERSION=3.0.1 修改ubuntu/config-default12345678910# 由于被墙，修改ubuntu/download-release.sh和ubuntu/util.sh，注释掉curl。因为提前下载了# 用户名@ipexport nodes=$&#123;nodes:-\"i3@192.168.1.245 530@192.168.1.173 g640@192.168.1.241 g540@192.168.1.148\"&#125;# a表示master，i表示node，ai表示master+noderoles=$&#123;roles:-\"ai i i i\"&#125;# 4个nodeexport NUM_NODES=$&#123;NUM_NODES:-4&#125; 清理环境由于我之前安装过，所以还是清理一下，在master和node上都执行1234567891011sudo rm -rf /opt/bin/etcd* /opt/bin/flanneld*sudo rm -rf /opt/bin/kube*sudo service etcd stopsudo service flanneld stopsudo service kube-apiserver stopsudo service --status-allsudo service kube-apiserver statussudo service kube-controller-manager stopsudo service kube-proxy stopsudo service kube-scheduler stopsudo service kubelet stop 开始部署在master上的kubernetes/cluster/路径执行 1KUBERNETES_PROVIDER=ubuntu ./kube-up.sh 输入密码，最后完成1234567./kubectl get nodes返回结果#NAME STATUS AGE#192.168.1.148 Ready 123d#192.168.1.173 Ready 123d#192.168.1.241 Ready 123d#192.168.1.245 Ready 123d 安装DNS和UI12cd cluster/ubuntu$ KUBERNETES_PROVIDER=ubuntu ./deployAddons.sh 然后查看ui打开master上的ui，http://:8080/ui 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://blog.decbug.com/tags/kubernetes/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"用go写的镜像构建微服务","slug":"go_image_build","date":"2016-02-16T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/02/17/go_image_build/","link":"","permalink":"http://blog.decbug.com/2016/02/17/go_image_build/","excerpt":"功能前面已经把私有registry，镜像下载加速器(摸我，其实就是基于registry官方镜像设置一个proxy，超级简单)完成了。这个时候就可以提供类似Daoloud的代码构建功能啦 用户点击构建按钮（或是其他触发方式） 我的镜像构建微服务收到请求后，就从内网github Clone代码 在刚Clone代码里找到Dockerfile 执行docker build -t 私有registry域名/用户名/镜像名：tag . docker push 刚build出来的镜像 构建日志，构建结果，入库 返回 私有registry域名/用户名/镜像名：tag 用户就可以 pull 私有registry域名/用户名/镜像名：tag 啦","text":"功能前面已经把私有registry，镜像下载加速器(摸我，其实就是基于registry官方镜像设置一个proxy，超级简单)完成了。这个时候就可以提供类似Daoloud的代码构建功能啦 用户点击构建按钮（或是其他触发方式） 我的镜像构建微服务收到请求后，就从内网github Clone代码 在刚Clone代码里找到Dockerfile 执行docker build -t 私有registry域名/用户名/镜像名：tag . docker push 刚build出来的镜像 构建日志，构建结果，入库 返回 私有registry域名/用户名/镜像名：tag 用户就可以 pull 私有registry域名/用户名/镜像名：tag 啦 记录终于用go写完了一个类似DaoCloud自动构建镜像的微服务，一边google一边写，全程都是用Docker来开发的，收获还是挺大的，简单记录下。 基于golang1.5.3基础镜像，然后在代码里增加一个Godeps，把用到的库都放在Godeps，然后在Dockefile里r把Goeps加入到GOPATH环境变量 参考了docker/distribution的Dockerfile，https://github.com/CodeJuan/distribution/blob/master/Dockerfile 由于只提供restful，就用的gorilla/mux框架 数据库MySQL，orm用的是gorm 用到了sync,crypt等库 在docker内使用宿主机docker daemon的方法 RUN (wget “https://get.docker.com/builds/…” -O /usr/bin/docker &amp;&amp;\\ chmod +x /usr/bin/docker) 然后再启动的时候指定/var/run/docker.sock:/var/run/docker.sock 开发测试部署都是用的Docker，数据库也是Docker。大概流程是 修改代码，build我的微服务镜像，push到我的私有registry docker-compose从私有registry获取刚build的镜像，由于link了MySQL，就会先启动MySQL。 接下来自动跑测试，我用的是python给我的微服务发post get等等。 后续计划 自动测试的脚本要加上从数据库里获取结果，与我的期望值进行比对。目前还是人肉比对，有些慢 jenkins自动触发，有代码上了库就自动拉下来完成打镜像，推镜像，拉镜像，compse up，测试的一系列操作 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"golang","slug":"golang","permalink":"http://blog.decbug.com/tags/golang/"},{"name":"microservice","slug":"microservice","permalink":"http://blog.decbug.com/tags/microservice/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"分布式消息系统架构图","slug":"msg_arch","date":"2016-01-31T17:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/02/01/msg_arch/","link":"","permalink":"http://blog.decbug.com/2016/02/01/msg_arch/","excerpt":"哈哈哈手画的架构图","text":"哈哈哈手画的架构图 本博客欢迎转发,但请保留原作者信息 github:codejuan 博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"architecture","slug":"architecture","permalink":"http://blog.decbug.com/tags/architecture/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"2016学习计划","slug":"planning2016","date":"2016-01-30T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2016/01/31/planning2016/","link":"","permalink":"http://blog.decbug.com/2016/01/31/planning2016/","excerpt":"总觉得今天才是2015的最后一天，那么就计划一下2016吧","text":"总觉得今天才是2015的最后一天，那么就计划一下2016吧 英语 每天10个单词，要求能造句 每天一篇技术文章，要求能复述 继续每天一篇听力 要多开口说了，2015说的太少 已经可以在github上和第一语言是英语的同僚对话了，接下来要尝试用英文写博客 代码 虽然我很讨厌架构师这个头衔，因为太多嘴炮架构师，啥都不会光会吹。但是有时候为了展示自己的实力，不得不给自己也挂上 ….. 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"planning","slug":"planning","permalink":"http://blog.decbug.com/categories/planning/"}],"tags":[{"name":"career","slug":"career","permalink":"http://blog.decbug.com/tags/career/"}],"keywords":[{"name":"planning","slug":"planning","permalink":"http://blog.decbug.com/categories/planning/"}]},{"title":"docker(4)-nexus3","slug":"docker_distribution_nexus","date":"2016-01-12T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/01/13/docker_distribution_nexus/","link":"","permalink":"http://blog.decbug.com/2016/01/13/docker_distribution_nexus/","excerpt":"背景前面说到要搭建自己的私有docker云，尝试了registry，感觉还不错。不过，今天有大神推荐nexus3，说很方便。所以呢，我就尝试一下。","text":"背景前面说到要搭建自己的私有docker云，尝试了registry，感觉还不错。不过，今天有大神推荐nexus3，说很方便。所以呢，我就尝试一下。 下载安装nexu3 repo manager oss下载链接https://support.sonatype.com/hc/en-us/articles/213466018-Nexus-Repository-Manager-3-0-Technology-Preview-Milestone-6-Release-我选择了Unix bundle12345wget http://download.sonatype.com/nexus/oss/nexus-installer-3.0.0-m6-unix-archive.tar.gztar -zxf nexus-installer-3.0.0-m6-unix-archive.tar.gzcd nexus-installer-3.0.0-m6-unix-archivecd bin./nexus run 时间会比较久，直到出现Started Nexus Repository Manager 3.0.0-xxxxxxx然后访问http://192.168.1.173:8081/，其中的IP换成安装nexus3机器的IP 配置httpsregistry V2需要https，参考这里进行配置https://books.sonatype.com/nexus-book/3.0/reference/security.html#ssl-inbound 还有这位印度GG的视频http://www.sonatype.org/nexus/2015/09/22/docker-and-nexus-3-ready-set-action/ 按照http://www.eclipse.org/jetty/documentation/current/configuring-ssl.html生成不了jdx，奇怪 个人感觉还是nexus比原生的registry好用，希望能搞定 累成狗了，明天继续 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"docker-distribution","slug":"docker-distribution","permalink":"http://blog.decbug.com/tags/docker-distribution/"},{"name":"docker-registry","slug":"docker-registry","permalink":"http://blog.decbug.com/tags/docker-registry/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(3)-distribution分析","slug":"docker_distribution","date":"2016-01-11T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/01/12/docker_distribution/","link":"","permalink":"http://blog.decbug.com/2016/01/12/docker_distribution/","excerpt":"背景要搞自己的容器云了，那么就得有自己的docker hub，于是采用docker/registry V1。但由于registry V1荒废许久，所以最后决定采用docker/distribution鉴于很多地方称呼distribution为registry V2，我这里就不区分版本了，都叫做registry好了。","text":"背景要搞自己的容器云了，那么就得有自己的docker hub，于是采用docker/registry V1。但由于registry V1荒废许久，所以最后决定采用docker/distribution鉴于很多地方称呼distribution为registry V2，我这里就不区分版本了，都叫做registry好了。 通过docker运行先尝试一个简单的用法，即直接pull一个registry好了123456# 从DaoCloud pull一个registry镜像docker pull daocloud.io/library/registry:2.2.1docker run -p 5000:5000 --name registry daocloud.io/library/registry:2.2.1docker pull golang:1.5.2docker tag golang:1.5.2 localhost:5000/golangdocker push localhost:5000/golang 通过查看源码中的Dockerfile，有一句VOLUME [&quot;/var/lib/registry&quot;]，那么这个路径就是docker里存放push上来的镜像的路径1234567891011121314151617181920# 获取registry的IDdocker ps# 进入docker中调试,31f029b39e3c就是上一条命令获取到的IDdocker exec -it 31f029b39e3c bash# 这个路径下就有一个golang的文件夹cd /var/lib/registry/docker/registry/v2/repositories# 退出dockerexit# 在宿主机中查看路径docker inspect 31f029b39e3c# 查看Mounts字段# /var/lib/docker/volumes/3bd3f857da3e887fd5d890066b1065450751aa3daf0d405e472e2d31abf44a61/_datacd /var/lib/docker/volumes/3bd3f857da3e887fd5d890066b1065450751aa3daf0d405e472e2d31abf44a61/_data# 果然也有docker/registry/v2/repositories/golang 源码运行下载并安装源码12345678910111213141516171819202122232425git clone git@github.com:docker/distribution.gitcd distribution# 通过查看distribution的Dockerfile，发现需要把$PWD/Godeps/_workspace添加到GOPATH# 不然就会编译不过，会报缺少一堆库。当然，如果不嫌麻烦的话，也可以把缺失的库都go get下来export GOPATH=$GOPATH:$PWD/Godeps/_workspace# Dockerfile添加了DOCKER_BUILDTAGS，在make时会用到export DOCKER_BUILDTAGS=\"include_rados include_oss include_gcs\"# 需要安装sudo yum install librados2-develsudo yum install httpd-tools# makemake clean binaries# 运行bin/registry --version# 启动，也是查看Dockerfile# ENTRYPOINT [\"registry\"] CMD [\"/etc/docker/registry/config.yml\"]# 而这个config.yml又是从cmd/registry/config-dev.yml拷贝过去的# 所以，我们这里直接用cmd/registry/config-dev.ymlbin/registry cmd/registry/config-dev.yml 这样就运行起来了，但是仅仅是运行还不够，还得深入了解一下原理 源码分析makefile在上一节中，输入了make clean binaries构建出binaries，那么这个binaries就会build${PREFIX}/bin/registry ${PREFIX}/bin/digest ${PREFIX}/bin/registry-api-descriptor-template1234567891011$&#123;PREFIX&#125;/bin/registry: version/version.go $(shell find . -type f -name '*.go') @echo \"+ $@\" @go build -tags \"$&#123;DOCKER_BUILDTAGS&#125;\" -o $@ $&#123;GO_LDFLAGS&#125; $&#123;GO_GCFLAGS&#125; ./cmd/registry$&#123;PREFIX&#125;/bin/digest: version/version.go $(shell find . -type f -name '*.go') @echo \"+ $@\" @go build -tags \"$&#123;DOCKER_BUILDTAGS&#125;\" -o $@ $&#123;GO_LDFLAGS&#125; $&#123;GO_GCFLAGS&#125; ./cmd/digest$&#123;PREFIX&#125;/bin/registry-api-descriptor-template: version/version.go $(shell find . -type f -name '*.go') @echo \"+ $@\" @go build -o $@ $&#123;GO_LDFLAGS&#125; $&#123;GO_GCFLAGS&#125; ./cmd/registry-api-descriptor-template 结合前面的启动命令bin/registry cmd/registry/config-dev.yml，就找到了registry的程序入口，就是cmd/registry/main.go 流程1cmd/registry/main.go/main -&gt; registry/registry.go/Cmd:Excute 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"docker-distribution","slug":"docker-distribution","permalink":"http://blog.decbug.com/tags/docker-distribution/"},{"name":"docker-registry","slug":"docker-registry","permalink":"http://blog.decbug.com/tags/docker-registry/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(3)-搭建registry,nginx,mirror","slug":"docker_distribution_build","date":"2016-01-11T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/01/12/docker_distribution_build/","link":"","permalink":"http://blog.decbug.com/2016/01/12/docker_distribution_build/","excerpt":"背景关于registry的基本知识已经了解差不多了，现在开始搭建一个可用的私有registry","text":"背景关于registry的基本知识已经了解差不多了，现在开始搭建一个可用的私有registry 架构 就采用钟成提到的架构 进展1搭建了registry+front，配置了https折腾一天，累成狗了，不详细写拉。直接看代码吧，都写成脚本和compose了https://github.com/CodeJuan/private_registry 进展2:registry集群实现了负载均衡用的是nginx1.9的镜像https://github.com/CodeJuan/private_registry/commit/7233fbf7def7b32daccc065f6ef546b234606e0d 进展3:后端存储后端存储采用的是某共享存储技术，所有的registry都访问同一个存储集群，路径都一样 进展4：mirror If you have multiple instances of Docker running in your environment (e.g., multiple physical or virtual machines, all running the Docker daemon), each time one of them requires an image that it doesn’t have it will go out to the internet and fetch it from the public Docker registry. By running a local registry mirror, you can keep most of the redundant image fetch traffic on your local network. 1234567891011mirror: restart: always image: registry:2.2.1 volumes: - ./mirror:/var/lib/registry environment: STANDALONE: 'false' MIRROR_SOURCE: https://registry-1.docker.io MIRROR_SOURCE_INDEX: https://index.docker.io registry ports: - 5555:5000 第一次pull12docker pull django0.19user 0.06system 9:16.60elapsed 0%CPU (0avgtext+0avgdata 26432maxresident)k mirror log123456time=\"2016-01-22T13:15:27Z\" level=info msg=\"response completed\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=884f518d-f69c-4d7d-8189-0afb70d1f351 http.request.method=GET http.request.remoteaddr=\"192.168.1.245:54369\" http.request.uri=\"//v2/\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.duration=\"142.245µs\" http.response.status=301 http.response.written=0 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:15:27 +0000] \"GET //v2/ HTTP/1.1\" 301 0 \"\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\"time=\"2016-01-22T13:15:27Z\" level=info msg=\"response completed\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=d38c459d-b0e8-4e40-9991-537999b206ca http.request.method=GET http.request.referer=\"http://docker-hub.mymirror.com:5555//v2/\" http.request.remoteaddr=\"192.168.1.245:54370\" http.request.uri=\"/v2/\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.contenttype=\"application/json; charset=utf-8\" http.response.duration=4.311715ms http.response.status=200 http.response.written=2 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:15:27 +0000] \"GET /v2/ HTTP/1.1\" 200 2 \"http://docker-hub.mymirror.com:5555//v2/\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\"time=\"2016-01-22T13:15:27Z\" level=error msg=\"response completed with error\" err.code=\"MANIFEST_UNKNOWN\" err.detail=\"unknown manifest name=library/django tag=latest\" err.message=\"manifest unknown\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=6c236f9c-53e9-4f4a-b61a-bf90e61c4c95 http.request.method=GET http.request.remoteaddr=\"192.168.1.245:54371\" http.request.uri=\"/v2/library/django/manifests/latest\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.contenttype=\"application/json; charset=utf-8\" http.response.duration=4.919044ms http.response.status=404 http.response.written=120 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 vars.name=\"library/django\" vars.reference=latest version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:15:27 +0000] \"GET /v2/library/django/manifests/latest HTTP/1.1\" 404 120 \"\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" rmi django再次pull12docker pull django0.21user 0.05system 13:35.23elapsed 0%CPU (0avgtext+0avgdata 27152maxresident)k 时间还变长了 mirror log123456time=\"2016-01-22T13:36:29Z\" level=info msg=\"response completed\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=5317fae0-9ead-4bc4-a016-3df313f7873a http.request.method=GET http.request.remoteaddr=\"192.168.1.245:54431\" http.request.uri=\"//v2/\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.duration=\"126.687µs\" http.response.status=301 http.response.written=0 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:36:29 +0000] \"GET //v2/ HTTP/1.1\" 301 0 \"\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\"time=\"2016-01-22T13:36:29Z\" level=info msg=\"response completed\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=86ed3aa8-a2ec-4b88-8a28-adcd4780ef78 http.request.method=GET http.request.referer=\"http://docker-hub.mymirror.com:5555//v2/\" http.request.remoteaddr=\"192.168.1.245:54432\" http.request.uri=\"/v2/\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.contenttype=\"application/json; charset=utf-8\" http.response.duration=4.279031ms http.response.status=200 http.response.written=2 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:36:29 +0000] \"GET /v2/ HTTP/1.1\" 200 2 \"http://docker-hub.mymirror.com:5555//v2/\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\"time=\"2016-01-22T13:36:29Z\" level=error msg=\"response completed with error\" err.code=\"MANIFEST_UNKNOWN\" err.detail=\"unknown manifest name=library/django tag=latest\" err.message=\"manifest unknown\" go.version=go1.5.2 http.request.host=\"docker-hub.mymirror.com:5555\" http.request.id=2097bff1-98f8-443b-9e6d-9c4b93d0c87f http.request.method=GET http.request.remoteaddr=\"192.168.1.245:54433\" http.request.uri=\"/v2/library/django/manifests/latest\" http.request.useragent=\"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" http.response.contenttype=\"application/json; charset=utf-8\" http.response.duration=4.300812ms http.response.status=404 http.response.written=120 instance.id=3d1817be-d0b8-4c98-8560-fe88c5039957 vars.name=\"library/django\" vars.reference=latest version=v2.2.1192.168.1.245 - - [22/Jan/2016:13:36:29 +0000] \"GET /v2/library/django/manifests/latest HTTP/1.1\" 404 120 \"\" \"docker/1.9.1 go/go1.4.2 git-commit/a34a1d5 kernel/3.19.0-25-generic os/linux arch/amd64\" 奇怪 更新，搞定了，原因是在compose里写环境变量不管用，等在config.yml里加上proxy，参见https://github.com/CodeJuan/private_registry/blob/master/mirror_config.yml 进展5：调通删除镜像APII sent the same request with @adolphlwq ‘s request, and got the same response123curl -v -X DELETE http://myregistry/v2/busybox/manifests/sha256:blablabla...&#123;\"errors\":[&#123;\"code\":\"UNSUPPORTED\",\"message\":\"The operation is unsupported.\"&#125;]&#125; updateI got the solution to delete images enable delete set the environment variable REGISTRY_STORAGE_DELETE_ENABLED = True the API to delete image get the manifest from registry1get v2/&lt;repoName&gt;/manifests/&lt;tagName&gt; the Docker-Content-Digest is response.Header[“Docker-Content-Digest”]the layerDigests is response.body[“fsLayers”][“blobSum”] delete layerDigests 1delete v2/&lt;repoName&gt;/blobs/&lt;layerDigests&gt; delete Docker-Content-Digest 1delete v2/&lt;repoName&gt;/manifests/&lt;Docker-Content-Digest&gt; then pull the image from registry, the response is invalid character &#39;&lt;&#39; looking for beginning of value But when I get ‘v2/repoName/tags/list’, the tag which was been deleted is still exist……. 参考关于私有安全docker registry的实验搭建Docker私有仓库Registry-v2 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"docker-distribution","slug":"docker-distribution","permalink":"http://blog.decbug.com/tags/docker-distribution/"},{"name":"docker-registry","slug":"docker-registry","permalink":"http://blog.decbug.com/tags/docker-registry/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(2)-compose","slug":"docker_compose","date":"2016-01-10T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/01/11/docker_compose/","link":"","permalink":"http://blog.decbug.com/2016/01/11/docker_compose/","excerpt":"背景之前已经把docker的常用命令都试了一遍，也通过命令启动了一个django+mysql+redis的应用。需要敲很多行命令才能完成，感觉还是有些麻烦。有鉴于此，正好可以尝试一下docker-compose，通过一个yml文件，就能启动一个服务。","text":"背景之前已经把docker的常用命令都试了一遍，也通过命令启动了一个django+mysql+redis的应用。需要敲很多行命令才能完成，感觉还是有些麻烦。有鉴于此，正好可以尝试一下docker-compose，通过一个yml文件，就能启动一个服务。 docker-compose简介 Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application’s services. Then, using a single command, you create and start all the services from your configuration. To learn more about all the features of Compose see the list of features.有点类似AWS的栈的概念，通过compose把一堆docker启动并组合起来，就是一个完整的服务。与dockerfile的区别： docerfile对应的是一个docker，compose定义的是一组docker。 install123456789sudo -icurl -L https://github.com/docker/compose/releases/download/1.5.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose# 由于github经常连不上，那么也可以用DaoCloud的链接# curl -L https://get.daocloud.io/docker/compose/releases/download/1.5.2/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composeexitdocker-compose --version 把当前用户加到docker组由于docker的运行需要root权限，在非root用户时每次都要输入sudo，有点麻烦。可以把当前用户加入到docker组，这样就不用每次都输入sudo了，方法 sudo vi /etc/group 在docker组的最后加入当前用户名1docker:x:993:your_name 简单的docker-compose代码在https://github.com/CodeJuan/test_docker_compose 创建一个app.py12345678910111213141516from flask import Flaskfrom redis import Redisapp = Flask(__name__)redis = Redis(host='redis', port=6379)@app.route('/')def hello(): redis.incr('hits') return 'Hello World! I have been seen %s times.' % redis.get('hits')if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", debug=True) 创建requirements.txt12flaskredis 这里没有指定版本，那么pip install的就是最新的版本 创建Dockerfile12345FROM daocloud.io/python:2-onbuildADD . /codeWORKDIR /codeRUN pip install -r requirements.txtCMD python app.py docker-compose.yml12345678910web: build: . ports: - \"5000:5000\" volumes: - .:/code links: - redisredis: build: ./redis DaoCloud的redis默认有随机密码所以需要给redis写一个dockerfile1234FROM daocloud.io/daocloud/dao-redis:master-init# 设置环境变量，表示不需要密码ENV REDIS_PASS=**None** 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"http://blog.decbug.com/tags/docker-compose/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"django","slug":"django","date":"2016-01-04T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2016/01/05/django/","link":"","permalink":"http://blog.decbug.com/2016/01/05/django/","excerpt":"背景开始撸django","text":"背景开始撸django 1234python manage.py startapp products#rm migratepython manage.py sql productspython manage.py syncdb 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"django","slug":"django","permalink":"http://blog.decbug.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://blog.decbug.com/tags/python/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"吐槽KPI","slug":"kpi","date":"2015-12-30T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/31/kpi/","link":"","permalink":"http://blog.decbug.com/2015/12/31/kpi/","excerpt":"背景有同僚吐槽KPI，言语犀利，直指要害，发人深省。余读毕，久久不能释怀，便手抄一份置于键盘边，每日提醒自己，莫要堕落，莫要成为KPI的奴隶。","text":"背景有同僚吐槽KPI，言语犀利，直指要害，发人深省。余读毕，久久不能释怀，便手抄一份置于键盘边，每日提醒自己，莫要堕落，莫要成为KPI的奴隶。 转载–手抄版 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}],"tags":[{"name":"KPI","slug":"KPI","permalink":"http://blog.decbug.com/tags/KPI/"}],"keywords":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}]},{"title":"软件开发中的反馈","slug":"feedback_software","date":"2015-12-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/29/feedback_software/","link":"","permalink":"http://blog.decbug.com/2015/12/29/feedback_software/","excerpt":"现实中的反馈反馈，即信息的返回。在现实生活中，有很多反馈控制系统，系统的控制器会根据系统的输出进行调整，以期得到正确的输出。 一个小实验试想，有如下三个场景 你的前方100米有一瓶水，让你去把水取回来，允许全程睁着眼睛 还是把水取回来，但是只允许每一分钟睁开眼睛观察一次 依旧是取水，但是不允许睁开眼睛，全程都闭着眼睛。 那么，会得到怎样的结果呢？ 场景一：可以避开所有障碍，并按照最优路径把水取回来。 场景二：由于可以睁眼观察，行进过程中会碰到障碍，会走弯路，但依旧可以完成任务 场景三：两眼一抹黑，也许走一路摔一路，也许方向完全走偏，等到后期才发现完全错误，以至于推倒重建。","text":"现实中的反馈反馈，即信息的返回。在现实生活中，有很多反馈控制系统，系统的控制器会根据系统的输出进行调整，以期得到正确的输出。 一个小实验试想，有如下三个场景 你的前方100米有一瓶水，让你去把水取回来，允许全程睁着眼睛 还是把水取回来，但是只允许每一分钟睁开眼睛观察一次 依旧是取水，但是不允许睁开眼睛，全程都闭着眼睛。 那么，会得到怎样的结果呢？ 场景一：可以避开所有障碍，并按照最优路径把水取回来。 场景二：由于可以睁眼观察，行进过程中会碰到障碍，会走弯路，但依旧可以完成任务 场景三：两眼一抹黑，也许走一路摔一路，也许方向完全走偏，等到后期才发现完全错误，以至于推倒重建。 关于实验的思考同样的人，同样的场景，为何结果会有这么大的差异？原因就在于，是否可以用眼睛观察。结合本文的主题，就是：有反馈和没反馈的区别。我们在有反馈的时候，可以及时根据输出情况调整我们的方向，以避免弯路。反馈在现实中是如此重要，那么在软件开发过程中又是怎样的情况呢？ 软件开发与反馈软件开发，其实也是一个输入输出系统，用户的需求经过我们的分析设计开发直到成为一个可运行的产品。然而，在开发过程中，我们对反馈却不够重视。也许会有很极端的情况，我们的产品一直都不符合要求，直到最后死亡。联想到现实生活中，我们看到的高楼大厦，也是从无到有创造出来的，一般很少有失败的情形，当然开发商跑路的烂尾楼除外。那么，二者究竟有什么差异导致不同的结局呢？因为楼房在修建过程中，看得见摸得着，每时每刻都有反馈，细小的误差都会在最快的时间内解决。那么软件开发为什么很难得到反馈呢？盖因软件不可见，只有可以运行的软件才能被我们感知。在《程序员修炼之道》里有提到曳光弹 注重实效的程序员往往更喜欢使用曳光弹。曳光弹之所以行之有效，是因为它们与真正的子弹在相同环境、相同条件下工作。它们快速飞向目标，所以枪手可以得到即时的反馈。 时间-成本 时间越久，成本就越高 及时反馈，及时发现问题，及时解决 软件开发该如何反馈 敏捷也好，持续集成也罢，从头到尾都强调着反馈。软件开发中反馈的重要性 后记这个是在公司内网发的一篇完成任务的帖子，凭记忆复述了一遍，感觉不如原文多矣。文笔变差了～sigh 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"SoftwareEngineering","slug":"SoftwareEngineering","permalink":"http://blog.decbug.com/categories/SoftwareEngineering/"}],"tags":[{"name":"agile","slug":"agile","permalink":"http://blog.decbug.com/tags/agile/"},{"name":"feedback","slug":"feedback","permalink":"http://blog.decbug.com/tags/feedback/"}],"keywords":[{"name":"SoftwareEngineering","slug":"SoftwareEngineering","permalink":"http://blog.decbug.com/categories/SoftwareEngineering/"}]},{"title":"nodejs(MEAN)","slug":"mean","date":"2015-12-27T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/28/mean/","link":"","permalink":"http://blog.decbug.com/2015/12/28/mean/","excerpt":"背景刚试过了golang+beego+angularjs做restful api，还挺好用的，只是orm不是特别方便。所以呢，试试传说中性能也很强大的nodejs，正好MEAN比较火，那么就试试吧","text":"背景刚试过了golang+beego+angularjs做restful api，还挺好用的，只是orm不是特别方便。所以呢，试试传说中性能也很强大的nodejs，正好MEAN比较火，那么就试试吧 安装通过binary安装nodejs123456wget https://nodejs.org/dist/v5.3.0/node-v5.3.0.tar.gztar -zxf node-v5.3.0.tar.gzcd node-v5.3.0./configuremakesudo make install 安装MEAN1sudo npm install -g mean-cli 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"angular","slug":"angular","permalink":"http://blog.decbug.com/tags/angular/"},{"name":"express","slug":"express","permalink":"http://blog.decbug.com/tags/express/"},{"name":"mongoDB","slug":"mongoDB","permalink":"http://blog.decbug.com/tags/mongoDB/"},{"name":"nodejs","slug":"nodejs","permalink":"http://blog.decbug.com/tags/nodejs/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"尝试travis CI","slug":"travisci","date":"2015-12-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2015/12/23/travisci/","link":"","permalink":"http://blog.decbug.com/2015/12/23/travisci/","excerpt":"前言看到别的开源软件的ReadMe上总一些build success的图标，感觉很帅，也想尝试一下。","text":"前言看到别的开源软件的ReadMe上总一些build success的图标，感觉很帅，也想尝试一下。 步骤 首先，用github帐号登录https://travis-ci.org/ 把某个工程打开，我选的工程是https://github.com/CodeJuan/python_convert_json2lua 创建’.travis.yml’，根据https://docs.travis-ci.com/user/languages/python填写一个python的yml 1234567language: pythonpython: - \"2.7\"# command to install dependenciesinstall: \"pip install simplejson\"# command to run testsscript: python go.py 点击工程的status图标，拷贝链接 在readme加上 1[![Build Status](https://travis-ci.org/CodeJuan/python_convert_json2lua.svg?branch=master)](https://travis-ci.org/CodeJuan/python_convert_json2lua) 效果如图 感想 有提交就触发，很方便 log很完整 可以自由配置环境 省去自己搭建jenkins的步骤 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"travisCI","slug":"travisCI","permalink":"http://blog.decbug.com/tags/travisCI/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"一次去中心化的性能优化","slug":"decentralized","date":"2015-12-14T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/15/decentralized/","link":"","permalink":"http://blog.decbug.com/2015/12/15/decentralized/","excerpt":"前言一个分布式计算系统，在数据量越来越大的情况下，处理时间太久，不符合用户需求，需要优化。 经过分析，发现有一个从存储节点把数据拷贝到计算节点的动作，这个过程比较耗时间。如果能把这个拷贝过程去掉，对于系统的整体性能将会有很大提升。","text":"前言一个分布式计算系统，在数据量越来越大的情况下，处理时间太久，不符合用户需求，需要优化。 经过分析，发现有一个从存储节点把数据拷贝到计算节点的动作，这个过程比较耗时间。如果能把这个拷贝过程去掉，对于系统的整体性能将会有很大提升。 过程原来的流程 如图，为简化流程，只画了一个存储节点和计算节点典型的数据向计算迁移，当数据特别大（数十G～百G）的时候，从存储节点拷贝到计算节点将特别耗时间。 而计算工具的身材特别苗条，几百M而已，拷贝过去也就是分分钟的事，如果能把计算工具放到存储节点，拷贝的时间就可以忽略不计，这个方法叫计算向数据迁移 优化后的流程 只是把百兆的计算工具拷过去，省去以前拷贝几百G数据的步骤～ 结论虽然不是什么很新的技术，但是简单几步就解决了业务问题，还是比较值得高兴一下的。 后面如果能把计算工具封装成docker，放到docker registry上去，每次计算的时候，存储节点把镜像pull过来，应该会比较好玩吧～ 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"decentralized","slug":"decentralized","permalink":"http://blog.decbug.com/tags/decentralized/"},{"name":"optimization","slug":"optimization","permalink":"http://blog.decbug.com/tags/optimization/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学golang(2):web框架","slug":"golang_revel","date":"2015-12-14T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/15/golang_revel/","link":"","permalink":"http://blog.decbug.com/2015/12/15/golang_revel/","excerpt":"背景上回已经把revel下载好了，顺利搞出个hello world， http://blog.decbug.com/2015/11/28/golang/","text":"背景上回已经把revel下载好了，顺利搞出个hello world， http://blog.decbug.com/2015/11/28/golang/ beego接下来就要深入学习一下了，用revel弄一个restful api玩玩。然而由于revel写restful api太难了，于是改为使用比较出名的beego，国人出品的框架，不知效果如何。 老规矩，从hello world开始 安装1234# 安装框架go get github.com/astaxie/beego# 安装工具go get github.com/beego/bee 建立工程12cd $GOPATH/srcbee new test_beego 运行12cd test_beegobee run Restful API安装mysql1234yum -y install mariadb-server mariadbsystemctl start mariadb.servicesystemctl enable mariadb.servicemysql_secure_installation 生成代码1bee generate scaffold post -fields=\"title:string,body:text\" 在server后台运行bee run在todo工程里运行1bee run 添加路由在main.go添加路由12beego.Router(\"/post/\", &amp;controllers.PostController&#123;&#125;, \"get:GetAll;post:Post\")beego.Router(\"/post/:id:int\", &amp;controllers.PostController&#123;&#125;, \"get:GetOne;put:Put;delete:Delete\") 注册数据库提示没有default数据库，所以需要注册一下1234567891011121314151617181920212223242526import ( \"github.com/astaxie/beego\" \"github.com/beego/samples/todo/controllers\"// 导入orm和mysql驱动 \"github.com/astaxie/beego/orm\" _ \"github.com/go-sql-driver/mysql\")// 在init时注册func init() &#123;orm.RegisterDriver(\"mysql\", orm.DR_MySQL)// 注意第三个参数连接字符串orm.RegisterDataBase(\"default\", \"mysql\", \"root:@/test?charset=utf8\")&#125;func main() &#123; beego.Router(\"/\", &amp;controllers.MainController&#123;&#125;) beego.Router(\"/task/\", &amp;controllers.TaskController&#123;&#125;, \"get:ListTasks;post:NewTask\") beego.Router(\"/task/:id:int\", &amp;controllers.TaskController&#123;&#125;, \"get:GetTask;put:UpdateTask\") //添加post路由 beego.Router(\"/post/\", &amp;controllers.PostController&#123;&#125;, \"get:GetAll;post:Post\") beego.Run()&#125; 改index123456789101112131415161718&lt;div class='container' ng-controller='PostCtrl'&gt; &lt;h1 class='charcoal rounded-box'&gt;Blog&lt;/h1&gt; &lt;h2&gt;Posts&lt;/h2&gt; &lt;ul class='grey rounded-box'&gt; &lt;li ng-repeat='t in posts'&gt; &lt;span class='checkbox'&gt;&lt;/span&gt;&#123;&#123;t.Id&#125;&#125;,&#123;&#123;t.Title&#125;&#125;,&#123;&#123;t.Body&#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;form&gt; &lt;input type='text' class='rounded-box' placeholder='add new post here' ng-model='postText'&gt; &lt;button class='grey rounded-box' ng-click='addPost()'&gt;New Post&lt;/button&gt; &lt;button class='grey rounded-box' ng-click='delPost()'&gt;Delete Post&lt;/button&gt; &lt;button class='grey rounded-box' ng-click='updatePost()'&gt;Update Post&lt;/button&gt; &lt;/form&gt;&lt;/div&gt; 改angularjs，增加PostCtrl123456789101112131415161718192021222324252627282930313233343536function PostCtrl($scope, $http) &#123; $scope.posts = []; var logError = function(data, status) &#123; console.log('code '+status+': '+data); &#125;; var refresh = function() &#123; return $http.get('/post/'). success(function(data) &#123; $scope.posts = data; &#125;). error(logError); &#125;; $scope.addPost = function() &#123; $http.post('/post/', &#123;Title: $scope.postText&#125;). error(logError). success(function() &#123; &#125;); &#125;; $scope.delPost = function() &#123; $http.delete('/post/'+$scope.postText). error(logError). success(function() &#123; &#125;); &#125;; $scope.updatePost = function() &#123; $http.put('/post/'+$scope.postText, &#123;Body: \"hahaha\"&#125;). error(logError). success(function() &#123; &#125;); &#125;; refresh().then(function() &#123; &#125;);&#125; sqlite 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://blog.decbug.com/tags/golang/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"讲讲缓存","slug":"cache","date":"2015-12-13T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/14/cache/","link":"","permalink":"http://blog.decbug.com/2015/12/14/cache/","excerpt":"背景缓存，可以说在计算机体系到处被用到。 CPU有指令缓存，还有L1L2L3缓存； 磁盘为了提高性能也有缓存； 就拿web开发来说，也会将经常访问的内容放到离用户更近的服务器上。 为何缓存的使用如此普遍？这个问题的确值得深入探讨一下。","text":"背景缓存，可以说在计算机体系到处被用到。 CPU有指令缓存，还有L1L2L3缓存； 磁盘为了提高性能也有缓存； 就拿web开发来说，也会将经常访问的内容放到离用户更近的服务器上。 为何缓存的使用如此普遍？这个问题的确值得深入探讨一下。 存储金字塔首先要说的算存储金字塔，如下图所示 可以看到，从上往下，速度越慢，容量越大，相应的成本就越低。 如果成本允许的情况下，我们自然尽量采购金字塔顶端的设备，然而现实却是残酷的，我们没有那么多资源可以挥霍。 缓存的概念在计算机体系中，缓存的概念其实是相对的。 寄存器是L1的缓存 L1是L2的缓存 CPU缓存是内存的缓存 内存是硬盘的缓存 CPU Cache hit &amp; miss我不说话，我只上图，能用图说清楚的，我就不说话。 这里顺便提以下CPU的提前预取？ 为了利用空间局部性，同时也为了覆盖传输延迟，可以随机性地在数据被用到之前就将其取入缓存。这一技术称为预取（Prefetch）。本质上讲，加载整个缓存块其实即是一种预取。 大概就是，CPU会提前给你把数据取过来，如果取到的数据正好是你要用的数据，那么恭喜你，速度会很快。 阶梯延时 内存数据库也是将热点数据放在内存中，相当于是把内存当作硬盘的缓存 硬盘自身的缓存 CDN 总结 可以看到，缓存命中的性能会比缓存miss高很多 合理利用缓存，将热点数据放在缓存中 缓存的概念很广泛，不仅仅是CPU缓存 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://blog.decbug.com/tags/cache/"},{"name":"storage","slug":"storage","permalink":"http://blog.decbug.com/tags/storage/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"openwrt内啥内啥","slug":"openwrt","date":"2015-12-02T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/12/03/openwrt/","link":"","permalink":"http://blog.decbug.com/2015/12/03/openwrt/","excerpt":"起因最近撸golang，下三方包太痛苦，挂代理太郁闷，所以。。。。。搞个openwrt全局内啥。 把家里的老路由FWR171翻出来刷openwrt，但是还没搞定（具体折腾经历在本文第二段）。只好在淘宝买了个华为HG225D，59+12的邮费，半个小时就搞定啦，太方便了，所以简单记录一下。 刷完HG225D之后，又翻出个DB120，顺手也弄了下。最后，由于我的集群都是千兆网卡，而HG225D的有线只有百兆，所以趁着双12在京东买了个WNDR4300，299-40=259。 至此，已经有三台openwrt设备了，嘿嘿嘿！","text":"起因最近撸golang，下三方包太痛苦，挂代理太郁闷，所以。。。。。搞个openwrt全局内啥。 把家里的老路由FWR171翻出来刷openwrt，但是还没搞定（具体折腾经历在本文第二段）。只好在淘宝买了个华为HG225D，59+12的邮费，半个小时就搞定啦，太方便了，所以简单记录一下。 刷完HG225D之后，又翻出个DB120，顺手也弄了下。最后，由于我的集群都是千兆网卡，而HG225D的有线只有百兆，所以趁着双12在京东买了个WNDR4300，299-40=259。 至此，已经有三台openwrt设备了，嘿嘿嘿！ HG225D购于淘宝，一定要uboot的刷不死版本，如果可以的话，建议买升级到64M内存的版本，速度会快一些。 刷机 固件openwrt-ramips-rt305x-hg255d-aria2-shadowsocks，http://pan.baidu.com/s/1kTst0gv#path=%252Fhg255d 按住reset不放，再给路由通电，直到power灯开始一闪一闪 进入192.168.1.1，此时看到的是刷机界面，选择刚才的固件openwrt-ramips-rt305x-hg255d-aria2-shadowsocks，耐心等待即可 内啥内啥的配置需要配置ss、Redsocks和chinadns，其中chinadns的作用就是，只有被墙了网站才会走ss。 进入服务-ss，填入你的服务器信息 进入服务-Redsocks，勾选启用Redsocks，在透明代理区域中，填写正确的代理服务器、代理服务器端口、代理服务器类型，加密方式以及密码。其中代理服务器类型选择ss代理 还是在Redsocks，UDP转发区域，也填入和透明代理一样的信息 进入网络-DHCP/DNS，在常规设置的DNS转发处填写127.0.0.1#1153 还是DHCP/DNS，点击HOSTS和解析文件，勾选忽略解析文件 再应用并保存所用配置，重启路由，就可以嘿嘿嘿了！ DB120 刷飞翔的http://downloads.openwrt.org.cn/OpenWrt-DreamBox/barrier_breaker/14.07/ 然后更新chinaDNS-C到1.21http://iweb.dl.sourceforge.net/project/openwrt-dist/chinadns/chinadns-c/1.2.1-102ab46/ChinaDNS-C_1.2.1-1_brcm63xx.ipk 不更新的话，就有一些访问不了 WNDR4300 下载石像鬼https://github.com/gygy/gygy.github.io 按住reset开机 等电源灯变绿并一闪一闪 用tftp把刚下载好的固件传给4300 刷好后关机再开机以激活5G 填写相关配置，然后@gygy提供了三种方式，点一下按钮就OK了。 FAST-FWR171失败的经历，可以不用看原厂固件FWR171到703Nhttp://pan.baidu.com/wap/share/home?uk=3457154703&amp;third=0 openwrthttp://downloads.openwrt.org/snapshots/trunk/ar71xx/generic/openwrt-ar71xx-generic-tl-wr703n-v1-squashfs-sysupgrade.binhttp://downloads.openwrt.org/snapshots/trunk/ar71xx/generic/openwrt-ar71xx-generic-tl-wr703n-v1-squashfs-factory.bin 先刷factory 然后ssh root@192.168.1.1 passwd改密码 开启wifi/etc/config/wireless radio0的disable一行需要删掉或注释掉顺便加个密123456789101112131415config wifi-iface option device radio0 option network lan option mode ap option ssid OpenWrt option encryption 'psk2' option key 'psk2' config wifi-iface option device radio0 option network lan option mode ap option ssid OpenWrt option encryption 'psk2' option key 'openwrt1234' 改 /etc/config/network1234567891011121314151617config interface 'loopback' option ifname 'lo' option proto 'static' option ipaddr '127.0.0.1' option netmask '255.0.0.0'config globals 'globals' option ula_prefix 'fdaa:5a73:9c8e::/48'config interface 'lan' option ifname 'eth0' option force_link '1' option type 'bridge' option proto 'static' option ipaddr '192.168.1.1' option netmask '255.255.255.0' option ip6assign '60' 搞挂了电脑的IP 192.168.1.2 gateway192.168.1.1 255.255.255.0first_bootreboot -f ssh 192.168.1.1 network加上123456789config interface 'lan' option ifname 'eth0' option force_link '1' option type 'bridge'# option proto 'static' option proto 'dhcp'# option ipaddr '192.168.1.1'# option netmask '255.255.255.0' option ip6assign '60' 连接已有的路由上网 装东西 软件安装 12opkg updateopkg install kmod-macvlan ip 编辑开机启动文件，在开机时虚拟出另外一张有线网卡，以区别WAN和LAN。 vi /etc/rc.local 在文件的exit 0之前加入以下内容。这里的MAC地址可以改成别的。12345ip link add link eth0 eth2 type macvlanifconfig eth2 hw ether 00:11:22:33:44:5bifconfig eth2 up exit 0 把虚拟出的网卡分配给LAN使用。1uci set network.lan.ifname=eth2 创建WAN接口。这里的协议设为DHCP，可以直接将703N插入已经存在的有线网络中，即可上网。 12345uci set network.wan=interfaceuci set network.wan.proto=dhcpuci set network.wan.hostname=openwrt-wanuci set network.wan.ifname=eth0uci commit network install ss1opkg install http://ncu.dl.sourceforge.net/project/openwrt-dist/shadowsocks-libev/2.4.1-6f44d53/ar71xx/shadowsocks-libev-spec-polarssl_2.4.1-1_ar71xx.ipk 提示空间不够。。。。 刷明月固件 http://pan.baidu.com/s/1i3uYGeh#path=%252F，下载最新的7100的upgrade固件 scp固件到路由的/tmp ssh连上路由，cd到/tmp sysupgrade -v openwrt-ar71xx-generic-tl-wr2543-v1-squashfs-sysupgrade.bin 耐心等待 参考http://www.cnblogs.com/Lifehacker/archive/2013/04/13/failure_on_fwr171-3g_with_openwrt.htmlhttp://www.isucc.me/555.htmlhttp://shuyz.com/install-shadowsocks-on-hg255d-openwrt-and-config-nat.htmlhttp://www.tuicool.com/articles/3Q7V7z3 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"openwrt","slug":"openwrt","permalink":"http://blog.decbug.com/tags/openwrt/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"尝试open falcon","slug":"open_falcon","date":"2015-11-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/29/open_falcon/","link":"","permalink":"http://blog.decbug.com/2015/11/29/open_falcon/","excerpt":"背景尝试一下小米的open falcon","text":"背景尝试一下小米的open falcon 步骤1234567891011121314151617181920212223242526272829303132sudo yum install -y redissudo yum install -y mysql-serverexport HOME=/home/workexport WORKSPACE=$HOME/open-falconmkdir -p $WORKSPACEcd $WORKSPACEgit clone https://github.com/open-falcon/scripts.gitcd ./scripts/mysql -h localhost -u root -p &lt; db_schema/graph-db-schema.sqlmysql -h localhost -u root -p &lt; db_schema/dashboard-db-schema.sqlmysql -h localhost -u root -p &lt; db_schema/portal-db-schema.sqlmysql -h localhost -u root -p &lt; db_schema/links-db-schema.sqlmysql -h localhost -u root -p &lt; db_schema/uic-db-schema.sqlDOWNLOAD=\"https://github.com/XiaoMi/open-falcon/releases/download/0.0.5/open-falcon-0.0.5.tar.gz\"cd $WORKSPACEmkdir ./tmp#下载wget $DOWNLOAD -O open-falcon-latest.tar.gz#解压tar -zxf open-falcon-latest.tar.gz -C ./tmp/for x in `find ./tmp/ -name \"*.tar.gz\"`;do \\ app=`echo $x|cut -d '-' -f2`; \\ mkdir -p $app; \\ tar -zxf $x -C $app; \\done 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.decbug.com/tags/monitoring/"},{"name":"ops","slug":"ops","permalink":"http://blog.decbug.com/tags/ops/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学golang(1):初学","slug":"golang","date":"2015-11-27T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/28/golang/","link":"","permalink":"http://blog.decbug.com/2015/11/28/golang/","excerpt":"背景最近经常听到有同事在安利golang，颇为心动。恰巧又看到这篇文章How We Moved Our API From Ruby to Go and Saved Our Sanity，于是便忍不住了，打算试试。毕竟是谷歌亲儿子，想必会有一番不错的表现。","text":"背景最近经常听到有同事在安利golang，颇为心动。恰巧又看到这篇文章How We Moved Our API From Ruby to Go and Saved Our Sanity，于是便忍不住了，打算试试。毕竟是谷歌亲儿子，想必会有一番不错的表现。 安装go原本以为需要用源码来安装，上网查了一下，得知centos7可以直接yum安装，so easy。 还是通过二进制安装一下吧yum安装的版本太低了，还是得自己安装1.51234567wget https://storage.googleapis.com/golang/go1.5.1.linux-amd64.tar.gztar -C /usr/local -xzf go1.5.1.linux-amd64.tar.gzecho 'export GOROOT=\"/usr/local/go\"' &gt;&gt; ~/.bashrcecho 'export PATH=$PATH:$GOROOT/bin' &gt;&gt; ~/.bashrcecho 'export GOPATH=\"$HOME/code/go_code\"' &gt;&gt; ~/.bashrcecho 'export PATH=$PATH:$GOROOT/bin' &gt;&gt; ~/.bashrc. ~/.bashrc golang plugin for idea作为idea的用户，自然首选的IDE还是idea，所以得装一个golang的插件https://github.com/go-lang-plugin-org/go-lang-idea-plugin然后参考https://www.jetbrains.com/idea/help/managing-enterprise-plugin-repositories.html进行安装即可 file-settings-plugins Browse repo Manage repo Custom plugin add url https://plugins.jetbrains.com/plugins/nightly/5047，这个nightly不错，我先试试 一路ok/close 然后在file-settings-plugins输入go,选择安装。 接下来就创建一个新的go工程，SDK就选择之前解压出来的/usr/local/go hello world创建一个hello.go，内容如下12345package mainimport \"fmt\"func main() &#123; fmt.Println(\"Hello, World!\")&#125; 然后go run hello.go也可以打包成一个可执行文件，go build hello.go simple http server123456789101112131415package mainimport ( \"fmt\" \"net/http\")func handler(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintf(w, \"Hi there, I love %s!\", r.URL.Path[1:])&#125;func main() &#123; http.HandleFunc(\"/\", handler) http.ListenAndServe(\":8080\", nil)&#125; 传说中的routine大概说一下我的理解，由于线程的切换成本较高，上下文，栈恢复之类的，所以需要考虑其他办法。多个routine，可以粗略的理解为共用一个线程，其CPU的抢占都是由routine自身来决定。由于只有一个线程，所以免去了切换的开销。感觉还是怪怪的，就先简单理解为routine的开销较小，可以有更高的并发数吧。 web frame打算试试revel1go get -u github.com/revel/cmd/revel 提示package golang.org/x/net/websocket: unrecognized import path &quot;golang.org/x/net/websocket&quot; 我只在我的办公机上装了SS，其他的几台挖掘机都没装，所以下不了。。看来我真的得把我的openwrt的路由弄好，用来全局Fxxk了。心情不好，今天就玩到这吧，擦擦擦！ 把内啥路由搞好了，HOHO，链接http://blog.decbug.com/2015/12/03/openwrt/。搞好了三台，网件WNDR4300、华为HG225D和DB120，搞挂了一个迅捷171。继续开搞吧 1234567891011# get revel frameworkgo get github.com/revel/revel# get 'revel' commandgo get github.com/revel/cmd/revel# get samples and run chat appgo get github.com/revel/samplesvi src/github.com/codejuan/my-app/conf/app.conf #8080sudo /sbin/iptables -I INPUT -p tcp -m tcp --dport 8080 -j ACCEPTrevel run github.com/revel/samples/chat 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://blog.decbug.com/tags/golang/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"virtualbox共享文件夹","slug":"virtualbox_share","date":"2015-11-23T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2015/11/24/virtualbox_share/","link":"","permalink":"http://blog.decbug.com/2015/11/24/virtualbox_share/","excerpt":"背景我的日常系统是ubuntu，但由于特殊国情，很多事情在只能在windows上面才能做。所以呢，只好用virtualbox弄了xp，专门用来做见不得人之事，比如用迅雷下载某些资源。下载完成之后，得把东西拷回到ubuntu吧，这个时候就可以通过共享文件夹的方式来做。","text":"背景我的日常系统是ubuntu，但由于特殊国情，很多事情在只能在windows上面才能做。所以呢，只好用virtualbox弄了xp，专门用来做见不得人之事，比如用迅雷下载某些资源。下载完成之后，得把东西拷回到ubuntu吧，这个时候就可以通过共享文件夹的方式来做。 步骤设置共享文件夹点击virtualbox的菜单，选择devices-shared folders settings 选中host上的一个文件夹 安装virtualbox插件会提示没有插件什么什么的，一路点next就行装完之后需要重启 映射host共享文件夹1net use x: \\\\vboxsvr\\share 然后在网络驱动器就会出现一个X盘，之后就能通过它来传文件了。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"share","slug":"share","permalink":"http://blog.decbug.com/tags/share/"},{"name":"virtualbox","slug":"virtualbox","permalink":"http://blog.decbug.com/tags/virtualbox/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"通过python将json转换成lua","slug":"json2lua","date":"2015-11-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/23/json2lua/","link":"","permalink":"http://blog.decbug.com/2015/11/23/json2lua/","excerpt":"背景某需求要将json转换成lua代码，同事们的做法是人肉翻译，肉眼读json，然后一条条拷贝到lua，如果遇到嵌套多的情况，一不小心就搞错了。即使没有出错，顺利翻译完成，一条简单的json将耗时半小时。如果是100条，将浪费50个小时，太恐怖了。 我在翻译了一次之后，实在是无法接受，于是想通过python来解析json，然后按照格式生成lua代码，也就是用代码写代码。这样可以避免机械劳动，不再浪费生命，可以从原来的半小时减少到1分钟，并且不容易出错。","text":"背景某需求要将json转换成lua代码，同事们的做法是人肉翻译，肉眼读json，然后一条条拷贝到lua，如果遇到嵌套多的情况，一不小心就搞错了。即使没有出错，顺利翻译完成，一条简单的json将耗时半小时。如果是100条，将浪费50个小时，太恐怖了。 我在翻译了一次之后，实在是无法接受，于是想通过python来解析json，然后按照格式生成lua代码，也就是用代码写代码。这样可以避免机械劳动，不再浪费生命，可以从原来的半小时减少到1分钟，并且不容易出错。 效果原始的json文件12345678910111213141516171819202122&#123; \"glossary\": &#123; \"title\": \"example glossary\", \"GlossDiv\": &#123; \"title\": \"S\", \"GlossList\": &#123; \"GlossEntry\": &#123; \"ID\": \"SGML\", \"SortAs\": \"SGML\", \"GlossTerm\": \"Standard Generalized Markup Language\", \"Acronym\": \"SGML\", \"Abbrev\": \"ISO 8879:1986\", \"GlossDef\": &#123; \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\", \"GlossSeeAlso\": [\"GML\", \"XML\"] &#125;, \"GlossSee\": \"markup\" &#125; &#125; &#125; &#125;&#125; 转换成lua的样子123456789101112131415161718192021local msg = &#123;&#125;local glossary = &#123;&#125;local GlossDiv = &#123;&#125;local GlossList = &#123;&#125;local GlossEntry = &#123;&#125;local GlossDef = &#123;&#125;GlossDef.GlossSeeAlso = &#123;\"GML\",\"XML\"&#125;GlossDef.para = \"A meta-markup language, used to create markup languages such as DocBook.\"GlossEntry.GlossDef = GlossDefGlossEntry.GlossSee = \"markup\"GlossEntry.Acronym = \"SGML\"GlossEntry.GlossTerm = \"Standard Generalized Markup Language\"GlossEntry.Abbrev = \"ISO 8879:1986\"GlossEntry.SortAs = \"SGML\"GlossEntry.ID = \"SGML\"GlossList.GlossEntry = GlossEntryGlossDiv.GlossList = GlossListGlossDiv.title = \"S\"glossary.GlossDiv = GlossDivglossary.title = \"example glossary\"msg.glossary = glossary 思路 simplejson解析原始的json文件 识别出array，subitem，alue subitem递归下去，然后一层一层往上汇总 根据规律分别组装出lua代码 输出 步骤simplejson先要安装simplejson 1sudo pip install simplejson 分析value12345678910def printValue(key, value, prefix, substring): left = '&#123;&#125;&#123;&#125;&#123;&#125;'.format(prefix, key, ' = ') right = '' if 'None' in substring: right = 'gLuaNULL.null' elif 'True' in substring: right = 'true' else: right = '\"&#123;&#125;\"'.format(value) print '&#123;&#125;&#123;&#125;'.format(left, right) 根据不同的值，转换成lua的结果。例如None对应的是gLuaNULL.null，True对应true,普通的值就等于’”json中的值”‘例如123\"GlossEntry\": &#123; \"ID\": \"SGML\" &#125; 转换成1GlossEntry.ID = \"SGML\" 分析array1\"GlossSeeAlso\": [\"GML\", \"XML\"] 类似于这样的，就要转换成1GlossDef.GlossSeeAlso = &#123;\"GML\",\"XML\"&#125; python代码如下1234567def printArray(key, value, prefix): elements = '&#123;' for i in value: elements += '\"&#123;&#125;\",'.format(i) elements = elements[:-1] elements += '&#125;' print '&#123;&#125;&#123;&#125;&#123;&#125;&#123;&#125;'.format(prefix, key, ' = ', elements) 分析subitem需要用到递归，将item不停的传递下去，直到完成不多解释了，直接看代码吧1234567def printSubItem(key, value, prefix): #print '&#123;&#125;11111111111'.format(key) local = 'local ' + key + ' = &#123;&#125;' print local parseJson(value, key+'.') print '&#123;&#125;&#123;&#125; = &#123;&#125;'.format(prefix, key, key) #print '&#123;&#125;22222222222'.format(key) 代码链接放在https://github.com/CodeJuan/python_convert_json2lua 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"json","slug":"json","permalink":"http://blog.decbug.com/tags/json/"},{"name":"lua","slug":"lua","permalink":"http://blog.decbug.com/tags/lua/"},{"name":"python","slug":"python","permalink":"http://blog.decbug.com/tags/python/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"openstack性能测试器(4):rabbitmq-server、kombu、tcpdump","slug":"openstack_perf_tester_4","date":"2015-11-09T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/10/openstack_perf_tester_4/","link":"","permalink":"http://blog.decbug.com/2015/11/10/openstack_perf_tester_4/","excerpt":"rabbitmq serverhttp://www.rabbitmq.com/download.html 12wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.5.6/rabbitmq-server-3.5.6-1.noarch.rpmsudo rpm -ivh rabbitmq-server-3.5.6-1.noarch.rpm 提示缺少erlang http://www.erlang.org/download.html 12345678910http://www.erlang.org/download/otp_src_18.1.tar.gztar -xvf otp_src_18.1.tar.gzcd otp_src_18.1./configuresudo makesudo make install# 提示缺少fop和wxWidgetssudo yum install fopsudo yum install wxWidgets 1sudo rpm -ivh --nodeps rabbitmq-server-3.5.6-1.noarch.rpm","text":"rabbitmq serverhttp://www.rabbitmq.com/download.html 12wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.5.6/rabbitmq-server-3.5.6-1.noarch.rpmsudo rpm -ivh rabbitmq-server-3.5.6-1.noarch.rpm 提示缺少erlang http://www.erlang.org/download.html 12345678910http://www.erlang.org/download/otp_src_18.1.tar.gztar -xvf otp_src_18.1.tar.gzcd otp_src_18.1./configuresudo makesudo make install# 提示缺少fop和wxWidgetssudo yum install fopsudo yum install wxWidgets 1sudo rpm -ivh --nodeps rabbitmq-server-3.5.6-1.noarch.rpm 说起来还是ubuntu安装简单，apt-get install rabbitmq-server就够了 management plugin123456# 启用managementrabbitmq-plugins enable rabbitmq_management# 停止服务sudo service rabbitmq-server stop# 开启服务sudo service rabbitmq-server start 然后访问serverIP:15672，就可以进入管理页面。此时只有guest帐号可用，然而rabbitmq-server的默认配置，guest帐号只能本机才能用，所以需要add_user 12345# 增加用户sudo rabbitmqctl add_user test test# 设置管理员权限sudo rabbitmqctl set_user_tags test administrator 然后再访问serverIP:15672，用刚才创建的test账户登录，就能看到管理界面了。 tracing plugin123456789cd /usr/lib/rabbitmq/bin# enable tracingsudo rabbitmq-plugins enable rabbitmq_tracing# trace onrabbitmqctl trace_on # stopsudo service rabbitmq-server stop# startsudo service rabbitmq-server start kombu Kombu是一个为Python写的消息库，目标是为AMQ协议提供一个傻瓜式的高层接口，让Python中的消息传递变得尽可能简单，并且也提供一些常见消息传递问题的解决方案。 kombu_cast1234567891011121314151617181920212223242526272829303132import datetimefrom kombu import Connection, Exchange, Queuemedia_exchange = Exchange('media', 'direct', durable=True)video_queue = Queue('video', exchange=media_exchange, routing_key='video')def process_media(body, message): print body message.ack()# connectionswith Connection('amqp://test:test@192.168.161.56:5672//') as conn: # produce producer = conn.Producer(serializer='json') now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') producer.publish(&#123;'name': '/tmp/lolcat1.avi', 'size': now&#125;, exchange=media_exchange, routing_key='video', declare=[video_queue]) # the declare above, makes sure the video queue is declared # so that the messages can be delivered. # It's a best practice in Kombu to have both publishers and # consumers declare the queue. You can also declare the # queue manually using: # video_queue(conn).declare() # consume# with conn.Consumer(video_queue, callbacks=[process_media]) as consumer:# # Process messages and handle events on all channels# while True:# conn.drain_events() kombu_consumer123456789101112131415161718from kombu import Connection, Exchange, Queueconn = Connection('amqp://test:test@192.168.161.56:5672//')media_exchange = Exchange('media', 'direct', durable=True)def process_media(body, message): print body message.ack()# Consume from several queues on the same channel:video_queue = Queue('video', exchange=media_exchange, key='video')image_queue = Queue('image', exchange=media_exchange, key='image')with conn.Consumer([video_queue, image_queue], callbacks=[process_media]) as consumer: while True: conn.drain_events() tcpdump抓包利器12345sudo tcpdump tcp -i wlan1 -n dst port 5672 -w cast.cap# tcp 表示抓tcp协议# -i，表示抓哪个网卡。我这里算wlan1抓无线网卡1# -w 表示写入到哪个文件# dst port 5672表示只抓目的端口为5672的数据 然后用wireshark打开cast.cap 顺便抓了下consumer的 等有时间把每一包的意思都解释一下，今天就到这吧。抓的包放在https://github.com/CodeJuan/test_rabbitmq可以对照代码看看 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"AMQP","slug":"AMQP","permalink":"http://blog.decbug.com/tags/AMQP/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.decbug.com/tags/rabbitmq/"},{"name":"tcpdump","slug":"tcpdump","permalink":"http://blog.decbug.com/tags/tcpdump/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"编译构建时间优化","slug":"compile_optimize","date":"2015-11-04T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/05/compile_optimize/","link":"","permalink":"http://blog.decbug.com/2015/11/05/compile_optimize/","excerpt":"背景项目是一个Windows桌面应用程序，用VS2010开发，后台是C++开发的DLL，UI是C#，目前已有103万行代码。在代码只有30万行的时候，编译时间大约是10多分钟，反馈的速度足够快。然而随着代码膨胀，编译时间急剧上涨，当前的编译构建时间高达120分钟，也就是说，当你提交了一行代码，需要等120分钟之后，才能做全量测试。如此长的等待时间，绝对是在浪费生命，此前我就一直想要优化，奈何见效不大。原因有二： 构建的机器太差了，4核4G的虚拟机，蜗牛速度。 项目中各组件（DLL）用的是隐式记载的方式。如果A依赖B，那么，必须等待B编译结束，才能编译A，只能串行。 我向领导安利了多次，采购一台好点的服务器，用来编译构建。也算了这么一笔账，项目组有100多人，如果有100个人在等待编译的话，这100个人的一小时的工资可不是小数目啊，绝对比一台服务器贵了。然而还是。。。。。。还向各开发组安利过，快速构建的好处，可以减少等待，缩短反馈周期，更快的进行测试验证，然而。。。。。对此我想说，呵呵！不能再吐槽了，还是讲正事吧。 由于家里没有windows系统，无法截图，只能凭记忆胡乱记录一下。","text":"背景项目是一个Windows桌面应用程序，用VS2010开发，后台是C++开发的DLL，UI是C#，目前已有103万行代码。在代码只有30万行的时候，编译时间大约是10多分钟，反馈的速度足够快。然而随着代码膨胀，编译时间急剧上涨，当前的编译构建时间高达120分钟，也就是说，当你提交了一行代码，需要等120分钟之后，才能做全量测试。如此长的等待时间，绝对是在浪费生命，此前我就一直想要优化，奈何见效不大。原因有二： 构建的机器太差了，4核4G的虚拟机，蜗牛速度。 项目中各组件（DLL）用的是隐式记载的方式。如果A依赖B，那么，必须等待B编译结束，才能编译A，只能串行。 我向领导安利了多次，采购一台好点的服务器，用来编译构建。也算了这么一笔账，项目组有100多人，如果有100个人在等待编译的话，这100个人的一小时的工资可不是小数目啊，绝对比一台服务器贵了。然而还是。。。。。。还向各开发组安利过，快速构建的好处，可以减少等待，缩短反馈周期，更快的进行测试验证，然而。。。。。对此我想说，呵呵！不能再吐槽了，还是讲正事吧。 由于家里没有windows系统，无法截图，只能凭记忆胡乱记录一下。 分析各组件的依赖关系既然无人支持，但我还是得试试。于是顺手写了个脚本分析组件之间的依赖关系，并且看C++代码，将项目整体分为4层。UI是C#工程，用显式加载的方式调用C++，故可以独立出来。脚本http://blog.decbug.com/2015/07/26/pe_depen/ 名称 framework midware plugin 名称 UI 下层依赖上层，也就是下层必须等待上层编译完成。同一层的组件相互独立，可以并行构建。 分层之后，编译还是那么滴慢，毕竟CPU内存资源有限，再优化的意义也不大。 升级服务器正当我无可奈何之际，公司出了这么一个要求：让每个项目的编译构建时间小于15分钟，这时候大家才重视起来。。各种资源刷刷滴都来了。 时间还增加了？有了领导的重视，事情就好办了，服务器刷刷的就到位了，24核96G，还有20T的硬盘，看着都爽啊。高高兴兴的把构建脚本拷贝过去，然后自动下代码，开始编译。原本以为在硬件有极大提升的情况下，构建时间应该会缩短一半多，达到50分钟的水平。可实际情况却让我无比郁闷，竟然时间还增加了。想起之前在领导面前夸下的海口，说有办法搞到25分钟左右，领导才同意申请服务器的。 分析并解决只好开始新一轮的构建，手动更新一下代码，发现更新速度超级慢，猜测是网络的原因，导致下载很慢，经过分析，网络正常。内存和CPU都极其给力，自然不会是瓶颈。于是把怀疑目标转向硬盘，用crystal mark测试一下硬盘速度，果然奇慢无比。看来真的是硬盘拖累了速度啊。远程开机，查看bios中关于磁盘的设置，竟然是RAID5。。。。好吧，反正是编译机器，不需要数据安全，那就改成不raid吧，再次编译，时间减少到了60分钟。 分析VC的工程文件减少文件拷贝sln：其实就是一个配置文件，把用到VC工程即vcxproj都include进来vcxproj其实就是xml文件，记录着cpp h的相对路径，各种编译选项等等。可以把它当成xml进行读写。 查看每个vcxproj，发现prebuild和postbuild的event都会做拷贝文件的操作，大约会拷贝近300M的文件。看了下拷贝路径，原来是用于本地调试的，对于编译构建来说，完全用不着。写个powershell脚本，在编译的ant脚本里调用一下，每次构建之前都调用一次，把这两个event都disable掉。经过测试，时间从60分钟降低到50分钟 开启mp观察编译过程，CPU利用率始终上不去，没有发挥多核的优势啊，得想办法把CPU都利用起来。看了下编译选项，有个/MP引起了我的注意，看看微软咋说的12/MP (Build with Multiple Processes)The /MP compiler option can significantly reduce build time when you compile many files. 我那可是24核的机器啊，不开启多核编译真的是太浪费资源了。老规矩，windows平台，写个powershell脚本，遍历所有工程的vcxproj文件，把/MP都打开。 在ant编译脚本里加入套餐，在编译之前执行powershell脚本，再次测试，时间降低到40分钟。 分布式编译继续观察编译过程，大部分时间的CPU都能有90%以上，但有一段时间内CPU始终只有10%左右。打开任务管理器，选择列，命令行。看下MSBUILD进程的命令行，找出此时是在搞哪个SLN，想办法把这个SLN的时间降下来。找到SLN后，查看它的代码结构，发现优化的空间不大。只好用别的方法，由于link的原因，每个SLN的编译过程，都是串行的，所以CPU一直上不去。找incredi build，可以并行link，充分利用CPU，修改编译脚本，在编译这个SLN的时候，不用MSBUILD，改incredi build，CPU果然上去了。经测试，整体的时间从40分钟降低到30分钟 这不是终点虽然用到incredi build，但这只是伪分布式，所有的计算资源都是在一台服务器上，当代码继续膨胀，编译时间还是会变长。这只是在治标不治本，真正要做到分布式构建，每个组件都能并行构建的话。需要把隐式加载改为显式加载，即组件之间只通过头文件进行依赖，而不是通过lib，这样就不用等待上游的完成。 具体方法是： 都改成loadlibrary，GetFunctionProcess的方式加载组件，组件之间在编译过程中相互独立。 如此便可把将每个组件的编译过程推送到agent上执行 汇总每个agent上的编译结果（DLL） 这样整体的编译构建时间，就是编译最慢的那个组件的时间了。 然而我已换部门，只能先把demo弄好，等待后来者完善了。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"build","slug":"build","permalink":"http://blog.decbug.com/tags/build/"},{"name":"compile","slug":"compile","permalink":"http://blog.decbug.com/tags/compile/"},{"name":"optimize","slug":"optimize","permalink":"http://blog.decbug.com/tags/optimize/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"cobbler自动部署系统","slug":"cobbler","date":"2015-10-31T17:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/11/01/cobbler/","link":"","permalink":"http://blog.decbug.com/2015/11/01/cobbler/","excerpt":"背景我司竟然还是人肉装系统，太TMD老土了。于是找到了cobbler，官网在http://cobbler.github.io/ 先看一段简介 Cobbler is a Linux installation server that allows for rapid setup of network installation environments. 很叼吧。","text":"背景我司竟然还是人肉装系统，太TMD老土了。于是找到了cobbler，官网在http://cobbler.github.io/ 先看一段简介 Cobbler is a Linux installation server that allows for rapid setup of network installation environments. 很叼吧。 开启PXE由于cobbler是通过PXE给裸机装系统的，所以要先改裸机的BIOS设置，改为从网卡启动。 某品牌主板的设置方法 另一品牌主板的设置方法 安装cobbler参考官网的quick start http://cobbler.github.io/manuals/quickstart/ disable SELinux由于我对SELinux不熟悉，根据官网的建议，还是把SELinux Disable吧 参考https://www.centos.org/docs/5/html/5.1/Deployment_Guide/sec-sel-enable-disable.html 修改/etc/sysconfig/selinux，修改SELINUX的值为disabled，并增加一行SETLOCALDEFS=0 1234567891011# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=enforcing # 改为 disabled# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted Installing Cobbler错误的方法1sudo yum install cobbler 提示没有package，说明要添加源。按照http://cobbler.github.io/manuals/2.4.0/3/2_-_Installing_From_Packages.html说 12# sudo rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-X-Y.noarch.rpm sudo rpm -Uvh http://download.fedoraproject.org/pub/epel/7/x86_64/epel-release-7-0.noarch.rpm 还是不行，因为我不知道具体的版本号。 只好找到最新release的页面http://cobbler.github.io/posts/2015/09/30/cobbler_2.6.10_released.html，根据Packages will be provided as soon as possible, please check的提示，找到http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-7/noarch/ 添加源 123sudo rpm -Uvh http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-7/noarch/cobbler-2.6.10-11.2.noarch.rpmsudo rpm -Uvh http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-7/noarch/cobbler-web-2.6.10-11.2.noarch.rpmsudo rpm -Uvh http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-7/noarch/koan-2.6.10-11.2.noarch.rpm 提示缺少python的一堆库， 12python-simplejson is needed by cobbler-2.6.10-11.2.noarchpython-cheetah is needed by cobbler-2.6.10-11.2.noarch 使用pip安装simplejson和cheetah，还是报这个错，看来此路不通，需要另想它法。 正确的方法找到了这个链接http://cobbler.readthedocs.org/en/latest/installation-guide.html Make sure you have the EPEL repository enabled on your system: 123yum -y install epel-releaseyum repolist# sudo curl -o cobbler30.repo http://download.opensuse.org/repositories/home:/libertas-ict:/cobbler30/CentOS_CentOS-7/home:libertas-ict:cobbler30.repo 接下来 1yum install cobbler cobbler-web 就安装成功了 启动cobbler改配置/etc/cobbler/settings 1234567default_password_crypted: \"$1$bfI7WLZz$PxXetL97LkScqJFxnW7KS1\" # 123456openssl passwd -1next_server: 192.168.161.51server: 192.168.161.51manage_dhcp = 1 1234567sudo service httpd startsudo service xinetd startsudo service cobblerd startsudo chkconfig cobblerd onsudo chkconfig xinetd onsudo chkconfig httpd on 检查配置 1sudo cobbler check 提示 123456781 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux2 : change 'disable' to 'no' in /etc/xinetd.d/tftp3 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.4 : file /etc/xinetd.d/rsync does not exist5 : debmirror package is not installed, it will be required to manage debian deployments and repositories6 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one7 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them 根据提示一一修改解决方法 disable selinux 改配置文件 执行cobbler get-loaders 新建/etc/xinetd.d/rsync，增加disable = no,修改 rsync 和 tftp 这两个服务的 xinetd 配置 1234567891011# vi /etc/xinetd.d/rsyncservice rsync&#123; disable = no&#125;# vi /etc/xinetd.d/tftpservice tftp&#123; disable = no&#125; 不支持debian系，cobbler服务器能同时部署CentOS/Fedora/Debian/Ubuntu系统，所以需要安装debmirror，安装debmirror-20090807-1.el5.noarch.rpm，在此之前，需要先安装一些其他的依赖包：暂时不管，我这里只测试centos12wget ftp://rpmfind.net/linux/epel/6/x86_64/debmirror-2.14-2.el6.noarch.rpmsudo rpm -ivh debmirror-2.14-2.el6.noarch.rpm 12345678910# yum install ed patch perl perl-Compress-Zlib perl-Cwd perl-Digest-MD5 perl-Digest-SHA1 perl-LockFile-Simple perl-libwww-perl# wget ftp://fr2.rpmfind.net/linux/epel/5/ppc/debmirror-20090807-1.el5.noarch.rpm# rpm –ivh debmirror-20090807-1.el5.noarch.rpm# 修改/etc/debmirror.conf 配置文件，注释掉 @dists 和 @arches 两行# vim /etc/debmirror.conf#@dists=”sid”;@sections=”main,main/debian-installer,contrib,non-free”;#@arches=”i386″; 生成密码。修改默认系统密码用 openssl 生成一串密码后加入到 cobbler 的配置文件（/etc/cobbler/settings）里，替换 default_password_crypted 字段： 12345# openssl passwd -1 -salt ‘bihan’ ‘Abcd1234′$1$‘bihan$bndMeAmxTpT0ldGYQoRSw0# vi /etc/cobbler/settings修改内容如下：default_password_crypted: “$1$‘bihan$bndMeAmxTpT0ldGYQoRSw0″ yum install cman或者fence-agents，我装的是fence-agents 改完之后运行 1234sudo service cobblerd restartsudo cobbler sync# 再check一下sudo cobbler check 就只剩下debmirror的问题了，可以暂时不管 下载并挂载iso 12345678910wget wget http://mirrors.sina.cn/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1503-01.iso#sudo mount -t iso9660 -o loop,ro ./CentOS-7-x86_64-Minimal-1503-01.iso /mntsudo mount -t iso9660 -o loop,ro /home/i3/save/iso/CentOS-7-x86_64-Minimal-1503-01.iso /mnt/centos#sudo cobbler import --name=centos7 --arch=x86_64 --path=/mntsudo cobbler import --name=centos7 --arch=x86_64 --path=/mnt/centos#sudo vi /etc/fstab# 增一行/home/i3/save/iso/CentOS-7-x86_64-Minimal-1503-01.iso /home/i3/save/cobbler_os iso9660 defaults,ro,loop 0 0#umount /somedir 挂载时报错 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# sudo cobbler import --name=centos7 --arch=x86_64 --path=/mnt/centostask started: 2015-11-04_215116_importtask started (id=Media import, time=Wed Nov 4 21:51:16 2015)Found a candidate signature: breed=redhat, version=rhel6Found a candidate signature: breed=redhat, version=rhel7Found a matching signature: breed=redhat, version=rhel7Adding distros from path /var/www/cobbler/ks_mirror/centos7-x86_64:creating new distro: centos7-x86_64trying symlink: /var/www/cobbler/ks_mirror/centos7-x86_64 -&gt; /var/www/cobbler/links/centos7-x86_64creating new profile: centos7-x86_64Exception occured: &lt;type 'exceptions.UnicodeEncodeError'&gt;Exception value: 'ascii' codec can't encode character u'\\u2018' in position 3: ordinal not in range(128)Exception Info: File \"/usr/lib/python2.7/site-packages/cobbler/remote.py\", line 87, in run rc = self._run(self) File \"/usr/lib/python2.7/site-packages/cobbler/remote.py\", line 231, in runner self.logger File \"/usr/lib/python2.7/site-packages/cobbler/api.py\", line 938, in import_tree return import_module.run(path,mirror_name,network_root,kickstart_file,arch,breed,os_version) File \"/usr/lib/python2.7/site-packages/cobbler/modules/manage_import_signatures.py\", line 140, in run os.path.walk(self.path, self.distro_adder, distros_added) File \"/usr/lib64/python2.7/posixpath.py\", line 246, in walk walk(name, func, arg) File \"/usr/lib64/python2.7/posixpath.py\", line 246, in walk walk(name, func, arg) File \"/usr/lib64/python2.7/posixpath.py\", line 238, in walk func(arg, top, names) File \"/usr/lib/python2.7/site-packages/cobbler/modules/manage_import_signatures.py\", line 255, in distro_adder adtls.append(self.add_entry(dirname,kernel,initrd)) File \"/usr/lib/python2.7/site-packages/cobbler/modules/manage_import_signatures.py\", line 360, in add_entry self.profiles.add(profile,save=True) File \"/usr/lib/python2.7/site-packages/cobbler/collection.py\", line 352, in add self.lite_sync.add_single_profile(ref.name) File \"/usr/lib/python2.7/site-packages/cobbler/action_litesync.py\", line 133, in add_single_profile self.sync.pxegen.make_pxe_menu() File \"/usr/lib/python2.7/site-packages/cobbler/pxegen.py\", line 330, in make_pxe_menu self.make_actual_pxe_menu() File \"/usr/lib/python2.7/site-packages/cobbler/pxegen.py\", line 480, in make_actual_pxe_menu menu_items = self.get_menu_items() File \"/usr/lib/python2.7/site-packages/cobbler/pxegen.py\", line 404, in get_menu_items arch=distro.arch, include_header=False) File \"/usr/lib/python2.7/site-packages/cobbler/pxegen.py\", line 702, in write_pxe_file image, arch, kickstart_path) File \"/usr/lib/python2.7/site-packages/cobbler/pxegen.py\", line 880, in build_kernel_options append_line = self.templar.render(append_line,utils.flatten(blended),None) File \"/usr/lib/python2.7/site-packages/cobbler/templar.py\", line 137, in render data_out = data_out.replace(\"@@%s@@\" % str(x), str(search_table[str(x)]))!!! TASK FAILED !!! 删除 12sudo cobbler profile remove --name=centos7-x86_64sudo cobbler distro remove --name=centos7-x86_64 再重来，看看是不是哪里代码的问题 python编码的问题，在python的Lib\\site-packages文件夹下新建一个sitecustomize.py12345# encoding=utf8 import sysreload(sys)sys.setdefaultencoding('utf8') 1234567891011sudo cobbler distro reportsudo cobbler system add --name=test --profile=centos7-x86_64sudo cobbler system listsudo cobbler system report --name=test# 待安装机器的mac和IPsudo cobbler system edit --name=test --interface=eth0 --mac=d0:27:88:d1:4d:7f --ip-address=192.168.161.52 --netmask=255.255.255.0 --static=1 #--dns-name=bogonsudo cobbler system edit --name=test --gateway=192.168.161.1 #--hostname=bogonsudo cobbler sync 本博客欢迎转发,但请保留原作者信息 github:codejuan 博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"cobbler","slug":"cobbler","permalink":"http://blog.decbug.com/tags/cobbler/"},{"name":"deploy","slug":"deploy","permalink":"http://blog.decbug.com/tags/deploy/"},{"name":"system","slug":"system","permalink":"http://blog.decbug.com/tags/system/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"絮叨ansible做持续交付,闲扯分布式","slug":"ansible4ci_distributed","date":"2015-10-31T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2015/11/01/ansible4ci_distributed/","link":"","permalink":"http://blog.decbug.com/2015/11/01/ansible4ci_distributed/","excerpt":"随手记录杂记而已，随便记录 ansbile做持续交付突然想到，ansible可以控制一大堆机器，那么是否可以像jenkins的master/slave那样，做分布式构建呢。应该是可以的吧 把代码同步到各个agent上，可以用git/svn都行 通过一堆参数，控制各个agent做不同的事情，并行构建。比如编译，静态检测，单元测试，自动化测试等等 artifact收集 部署 无缝接入呀，有时间可以试试。","text":"随手记录杂记而已，随便记录 ansbile做持续交付突然想到，ansible可以控制一大堆机器，那么是否可以像jenkins的master/slave那样，做分布式构建呢。应该是可以的吧 把代码同步到各个agent上，可以用git/svn都行 通过一堆参数，控制各个agent做不同的事情，并行构建。比如编译，静态检测，单元测试，自动化测试等等 artifact收集 部署 无缝接入呀，有时间可以试试。 分布式的一些感想想到一句话，不谋全局者，不足以谋一域；不谋万世者，不足以谋一时。 以前把玩有限的几台服务器，更多的是关注单点的CPU/IO/内存等等，现在得关注整体的性能，找出拖慢整体性能的瓶颈。 在考虑方案的时候，哪怕当前只有10台服务器，最好是按照1000台的规模去设计。 哈哈哈～～ 本博客欢迎转发,但请保留原作者信息 github:codejuan 博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://blog.decbug.com/tags/ansible/"},{"name":"continous delivery","slug":"continous-delivery","permalink":"http://blog.decbug.com/tags/continous-delivery/"},{"name":"distributed","slug":"distributed","permalink":"http://blog.decbug.com/tags/distributed/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"openstack性能测试器(3):移植rabbitmq-c","slug":"openstack_perf_tester_3","date":"2015-10-25T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/10/26/openstack_perf_tester_3/","link":"","permalink":"http://blog.decbug.com/2015/10/26/openstack_perf_tester_3/","excerpt":"rabbitmqrabbitmq是AMQP的一个具体实现。与之类似的还有apache的qpid。rabbitmq的官网是http://www.rabbitmq.com/ 我要做的是一个收发消息的模拟器，那么就用client就可以了。rabbitmq提供了各种语言的client版本，其中JAVA、C#、ErLang是官方维护的亲儿子版本。至于C语言的版本，则被归类到了other languages，下载链接是http://www.rabbitmq.com/devtools.html，C版本的链接是https://github.com/alanxz/rabbitmq-c","text":"rabbitmqrabbitmq是AMQP的一个具体实现。与之类似的还有apache的qpid。rabbitmq的官网是http://www.rabbitmq.com/ 我要做的是一个收发消息的模拟器，那么就用client就可以了。rabbitmq提供了各种语言的client版本，其中JAVA、C#、ErLang是官方维护的亲儿子版本。至于C语言的版本，则被归类到了other languages，下载链接是http://www.rabbitmq.com/devtools.html，C版本的链接是https://github.com/alanxz/rabbitmq-c 移植编译rabbitmq-c生产环境用的是suse，那边哥们给我的测试环境无法mount到我的本机，所以，只能在我docker ubuntu14.04来先验证一下。 CMake下载https://cmake.org/files/v3.4/cmake-3.4.0-rc2.tar.gz1234wget https://cmake.org/files/v3.4/cmake-3.4.0-rc2.tar.gztar -xzvf cmake-3.4.0-rc2.tar.gz cd cmake-3.4.0-rc2./bootstrap &amp;&amp; make &amp;&amp; sudo make install ./bootstrap1234567891011121314151617181920-- Check if the system is big endian-- Searching 16 bit integer-- Using unsigned short-- Check if the system is big endian - little endianCurses libraries were not found. Curses GUI for CMake will not be built.-- Looking for elf.h-- Looking for elf.h - found-- Looking for a Fortran compiler-- Looking for a Fortran compiler - NOTFOUNDqmake: could not exec '/usr/lib/x86_64-linux-gnu/qt4/bin/qmake': No such file or directoryqmake: could not exec '/usr/lib/x86_64-linux-gnu/qt4/bin/qmake': No such file or directory-- Performing Test run_pic_test-- Performing Test run_pic_test - Success-- Performing Test run_inlines_hidden_test-- Performing Test run_inlines_hidden_test - Success-- Configuring done-- Generating done-- Build files have been written to: /home/xh/save/code/cmake-3.4.0-rc2---------------------------------------------CMake has bootstrapped. Now run make. make1234567891011[ 61%] Built target cmjsoncppScanning dependencies of target CMakeLib[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmArchiveWrite.cxx.o[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmBootstrapCommands1.cxx.o[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmBootstrapCommands2.cxx.o[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCacheManager.cxx.o[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCommands.cxx.o[ 61%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCLocaleEnvironmentScope.cxx.o[ 62%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCommandArgumentLexer.cxx.o[ 62%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCommandArgumentParser.cxx.o[ 62%] Building CXX object Source/CMakeFiles/CMakeLib.dir/cmCommandArgumentParserHelper.cxx.o make install1234-- Installing: /usr/local/share/cmake-3.4/Templates/UtilityHeader.dsptemplate-- Installing: /usr/local/share/cmake-3.4/Templates/CTestScript.cmake.in-- Installing: /usr/local/share/cmake-3.4/Templates/CPack.GenericDescription.txt-- Installing: /usr/local/share/cmake-3.4/Templates/CPack.GenericLicense.txt version12cmake --version# cmake version 3.4.0-rc2 openssl1234567wget http://www.openssl.org/source/openssl-1.0.2d.tar.gztar -xzvf openssl-1.0.2dcd openssl-1.0.2d./configmakemake testmake install version一下看看12openssl version# OpenSSL 1.0.1f 6 Jan 2014 make12345git clone git@github.com:alanxz/rabbitmq-c.gitcd rabbitmq-cmkdir build &amp;&amp; cd buildcmake ..cmake --build . --config BUILD_TOOLS=OFF cmake ..时会提示找不到xmlto等等，因为我不需要生成辅助工具（文档、命令行工具等等)，暂时不管它。BUILD_TOOLS=OFF就表示不生成辅助工具 一路编译没有报错，至此，我们的rabbitmq就编译成功了，接下来就是要把librabbitmq移植到现有代码中。 移植过程 拷贝librabbitmq到原有代码中 在makefile里加上librabbitmq的路径 make，提示说找不到amqp_framing.h，原因是include用的是&lt;&gt;，而amqp_framing.h就在同一个目录。 sed -i s//\\”amqp_framing.h\\”/g改成相对路径，再次make，不报这个错了。 找不到threads.h，原因是没有把librabbitmq/unix-I，所以需要改以下路径为unix/threads.h 找不到AMQP_PLATFORM,这个是在config.h里定义的。看了下报错的c文件，确实有include了config.h，但为什么还报这个错呢？ 123#ifdef HAVE_CONFIG_H#include \"config.h\"#endif 原因就在于HAVE_CONFIG_H了，在makefile的gcc后加上-DHAVE_CONFIG_H，再次编译，就OK了。 在ubuntu上已经搞定，接下来就是迁移到suse上。关键点就在于config.h，因为config.h包含了内核版本以及epoll等等，所以需要在suse上编译一下rabbitmq-c，然后把suse上的config.h替换ubuntu上的config.h，编译就OK了。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"AMQP","slug":"AMQP","permalink":"http://blog.decbug.com/tags/AMQP/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://blog.decbug.com/tags/rabbitmq/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"openstack性能测试器(2):消息调用过程oslo.messaging","slug":"openstack_perf_tester_2","date":"2015-10-15T17:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/10/16/openstack_perf_tester_2/","link":"","permalink":"http://blog.decbug.com/2015/10/16/openstack_perf_tester_2/","excerpt":"openstack简介The OpenStack project is an open source cloud computing platform that supports all types of cloud environments. The project aims for simple implementation, massive scalability, and a rich set of features. Cloud computing experts from around the world contribute to the project.","text":"openstack简介The OpenStack project is an open source cloud computing platform that supports all types of cloud environments. The project aims for simple implementation, massive scalability, and a rich set of features. Cloud computing experts from around the world contribute to the project. OpenStack provides an Infrastructure-as-a-Service (IaaS) solution through a variety of complemental services. Each service offers an application programming interface (API) that facilitates this integration. openstack组件 Service Project name Description Dashboard Horizon Provides a web-based self-service portal to interact with underlying OpenStack services, such as launching an instance, assigning IP addresses and configuring access controls. Compute Nova Manages the lifecycle of compute instances in an OpenStack environment. Responsibilities include spawning, scheduling and decommissioning of virtual machines on demand. Networking Neutron Enables Network-Connectivity-as-a-Service for other OpenStack services, such as OpenStack Compute. Provides an API for users to define networks and the attachments into them. Has a pluggable architecture that supports many popular networking vendors and technologies. Storage Object Storage Swift Stores and retrieves arbitrary unstructured data objects via a RESTful, HTTP based API. It is highly fault tolerant with its data replication and scale-out architecture. Its implementation is not like a file server with mountable directories. In this case, it writes objects and files to multiple drives, ensuring the data is replicated across a server cluster. Block Storage Cinder Provides persistent block storage to running instances. Its pluggable driver architecture facilitates the creation and management of block storage devices. Shared services Identity service Keystone Provides an authentication and authorization service for other OpenStack services. Provides a catalog of endpoints for all OpenStack services. Image service Glance Stores and retrieves virtual machine disk images. OpenStack Compute makes use of this during instance provisioning. Telemetry Ceilometer Monitors and meters the OpenStack cloud for billing, benchmarking, scalability, and statistical purposes. Higher-level services Orchestration Heat Orchestrates multiple composite cloud applications by using either the native HOT template format or the AWS CloudFormation template format, through both an OpenStack-native REST API and a CloudFormation-compatible Query API. oslo.messaging消息组件，其中的/_drivers/impl_rabbit.py就是rabbitMQ的具体实现。我们要用的AMQP就是靠它来完成。 一个call的前世今生neutron/common/rpc.py init neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py call 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"AMQP","slug":"AMQP","permalink":"http://blog.decbug.com/tags/AMQP/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"},{"name":"perfmance","slug":"perfmance","permalink":"http://blog.decbug.com/tags/perfmance/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"openstack性能测试器(1):AMQP","slug":"openstack_perf_tester_1","date":"2015-10-15T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/10/16/openstack_perf_tester_1/","link":"","permalink":"http://blog.decbug.com/2015/10/16/openstack_perf_tester_1/","excerpt":"背景我司的公有云产品是基于OpenStack，一直以来都有做性能测试，但以前的性能测试方法比较老土。 有一部分基于http的消息是通过自己写的测试器来测试，即模拟真实场景的消息收发，测试各组件在高并发下的性能。 另外一些基于AMQP的消息则还是通过一堆虚拟机来做测试，需要耗费大量资源。 有鉴于此，需要再把测试器完善一下，使其能模拟OpenStack的各种组件，用有限的几台虚拟机，就能完成所有组件的性能测试。而作为什么都会一点的牛X人物，自然少不了被派来开荒。正好可以借此机会深入了解一下OpenStack，以前只是久闻其名，无缘深入探究，这次终于得偿所望。嘎嘎嘎！！","text":"背景我司的公有云产品是基于OpenStack，一直以来都有做性能测试，但以前的性能测试方法比较老土。 有一部分基于http的消息是通过自己写的测试器来测试，即模拟真实场景的消息收发，测试各组件在高并发下的性能。 另外一些基于AMQP的消息则还是通过一堆虚拟机来做测试，需要耗费大量资源。 有鉴于此，需要再把测试器完善一下，使其能模拟OpenStack的各种组件，用有限的几台虚拟机，就能完成所有组件的性能测试。而作为什么都会一点的牛X人物，自然少不了被派来开荒。正好可以借此机会深入了解一下OpenStack，以前只是久闻其名，无缘深入探究，这次终于得偿所望。嘎嘎嘎！！ AMQP要想做好模拟器，就需要了解AMQP协议，以及此协议在OpenStack中的应用场景。 概念AMQP是一种异步消息协议，在分布式系统就被大量使用。其传递流程可以大致理解成下图1producer-&gt;broker-&gt;consumer producer连接broker，broker可以理解为一个消息服务器，所有的消息都是通过它来中转。还有几个概念需要注意：exchange channel topic routing-key 等有空的时候，照着wireshark抓的包来对着讲解一下消息收发过程。以login为例， clien direct server 建立TCP连接 ==&gt; 发送heade ==&gt; 收 &lt;== connection connection ok ==&gt; 收 &lt;== connection.tune connection.tune ok ==&gt; open connection ==&gt; 收 &lt;== open connection ok openstackopenstack用的就是AMQP，具体实现有两种，是rabbitMQ和qpid，二者皆可使用。曾描过一眼，说ubuntu用rabbit，centos用qpid。我司用的是ubuntu，那么就看rabbitMQ好了。发送分为三类 cast:发送给特定的consumer，且不等待response call：发送给特定consumer，需要等待response fanout：发送给订阅了此消息的一组consumer，不等待response oslo.messaging这个组件专门负责消息。其中的/_drivers/impl_rabbit.py就是rabbitMQ的具体实现。 吐槽在折腾的过程中，在oslo.messaging的tools里发现了一个simulator.py，就是一个消息模拟器，然而由于原有框架是C写的，历史原因只能用C再做一个模拟器。其实openstack就有一个性能测试工具，名叫rally，也很不错，但是也不让用，sigh～～ 欲知后事如何，请看下集openstack的消息流程 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"AMQP","slug":"AMQP","permalink":"http://blog.decbug.com/tags/AMQP/"},{"name":"openstack","slug":"openstack","permalink":"http://blog.decbug.com/tags/openstack/"},{"name":"perfmance","slug":"perfmance","permalink":"http://blog.decbug.com/tags/perfmance/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学习ruby on rails","slug":"ror","date":"2015-10-13T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2015/10/14/ror/","link":"","permalink":"http://blog.decbug.com/2015/10/14/ror/","excerpt":"入门文档http://guides.ruby-china.org/getting_started.html","text":"入门文档http://guides.ruby-china.org/getting_started.html installruby-lang &amp; sqlite1234567891011yum install ruby-devel sqlite sqlite-devel ruby-rdocruby --version# show ############# ruby 2.0.0p598 (2014-11-13) [x86_64-linux]##############sqlite3 --version# show ############# 3.7.17 2013-05-20 00:56:22 118a3b35693b134d56ebd780123b7fd6f1497668############## gem换源需要换源，原因 由于国内网络原因（你懂的），导致 rubygems.org 存放在 Amazon S3 上面的资源文件间歇性连接失败。所以你会与遇到 gem install rack 或 bundle install 的时候半天没有响应，具体可以用 gem install rails -V 来查看执行过程。 以上引用自https://ruby.taobao.org/，好人一生平安。 方法1234567gem sources --add https://ruby.taobao.org/ --remove https://rubygems.org/gem sources -l# show ############# *** CURRENT SOURCES ***# # https://ruby.taobao.org/############## 说明换成了taobao的源 1bundle config mirror.https://rubygems.org https://ruby.taobao.org bundle也需要换，然而似乎还是没啥用，后面还是得改Gemfile rails1gem install rails 漫长的等待，就装好了，查看一下版本吧1234rails --version# show ############# Rails 4.2.4############## new project1rails new learn_ror 卡在bundle install，原因是learn_ror/Gemfile里的source指向的还是官网，所以需要手动改成淘宝的源12# source 'https://rubygems.org' source 'https://ruby.taobao.org' 再次执行install12cd learn_rorbundle install 启动执行启动命令1rails server 提示缺少jsruntime，看了下https://github.com/rails/execjs，决定采用therubyracer，在Gemfile里添加一行1https://github.com/cowboyd/therubyracer 再次bundle install，rails server，欢迎页面就出现了。 如果指定端口-p，则提示create_listener没权限123456789101112[2015-10-14 10:22:46] INFO WEBrick 1.3.1[2015-10-14 10:22:46] INFO ruby 2.0.0 (2014-11-13) [x86_64-linux][2015-10-14 10:22:46] WARN TCPServer Error: Permission denied - bind(2)Exiting/home/g640/.gem/ruby/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `require': cannot load such file -- abrt/handler (LoadError) from /home/g640/.gem/ruby/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `block in require' from /home/g640/.gem/ruby/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:240:in `load_dependency' from /home/g640/.gem/ruby/gems/activesupport-4.2.4/lib/active_support/dependencies.rb:274:in `require' from /home/g640/.gem/ruby/gems/abrt-0.1.1/lib/abrt.rb:6:in `block in &lt;top (required)&gt;'/usr/share/ruby/webrick/utils.rb:85:in `initialize': Permission denied - bind(2) (Errno::EACCES) from /usr/share/ruby/webrick/utils.rb:85:in `new' from /usr/share/ruby/webrick/utils.rb:85:in `block in create_listeners' 这个时候需要12sudo semanage port -a -t http_port_t -p tcp 3000sudo iptables -I INPUT -p TCP --dport 3000 -j ACCEPT hello world接下来就是照着教程做了，没啥技术含量。。。。。。。练习的代码放在https://github.com/CodeJuan/learn_ror 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"rails","slug":"rails","permalink":"http://blog.decbug.com/tags/rails/"},{"name":"ruby","slug":"ruby","permalink":"http://blog.decbug.com/tags/ruby/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学习ansible","slug":"ansible","date":"2015-10-10T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2015/10/11/ansible/","link":"","permalink":"http://blog.decbug.com/2015/10/11/ansible/","excerpt":"入门文档开始get ops技能，自动部署应该算是基础的基础了吧，而ansible美名远扬，自然不能错过。先从入门文档开始http://docs.ansible.com/","text":"入门文档开始get ops技能，自动部署应该算是基础的基础了吧，而ansible美名远扬，自然不能错过。先从入门文档开始http://docs.ansible.com/ install老规矩，从源码开始123456git clone https://github.com/ansible/ansible.git --recursivecd ./ansiblesource ./hacking/env-setup# 依赖的库sudo pip install paramiko PyYAML Jinja2 httplib2 six 当然，也可以直接用pip安装1sudo pip install ansible Inventory创建hosts123456sudo mkdir /etc/ansible/sudo vi /etc/ansible/hosts# 在hosts写上agent的IPexport ANSIBLE_INVENTORY=/etc/ansible/hosts 执行ping1ansible all -m ping 提示失败12345192.168.161.52 | UNREACHABLE! =&gt; &#123; \"changed\": false, \"msg\": \"ERROR! SSH encountered an unknown error during the connection. We recommend you re-run the command using -vvvv, which will enable SSH debugging output to help diagnose the issue\", \"unreachable\": true&#125; 我明明已经把master加入到可信SSH里了呀，可以不用密码ssh到agent呢。 配置ssh-agent试试12ssh-agent bashssh-add ~/.ssh/id_rsa 还是不行 解决查看官方文档http://docs.ansible.com/ansible/intro_inventory.html，提到 ansible_host The name of the host to connect to, if different from the alias you wish to give to it.ansible_port The ssh port number, if not 22ansible_user The default ssh user name to use.ansible_ssh_pass The ssh password to use (this is insecure, we strongly recommend using –ask-pass or SSH keys)ansible_ssh_private_key_file Private key file used by ssh. Useful if using multiple keys and you don’t want to use SSH agent.ansible_ssh_common_args This setting is always appended to the default command line for sftp, scp, and ssh. Useful to configure a ProxyCommand for a certain host (or group).ansible_sftp_extra_args This setting is always appended to the default sftp command line.ansible_scp_extra_args This setting is always appended to the default scp command line.ansible_ssh_extra_args This setting is always appended to the default ssh command line.ansible_ssh_pipelining Determines whether or not to use SSH pipelining. This can override the pipelining setting in ansible.cfg. 需要设置IP、port和user 改写hosts文件加上user1g530 ansible_user=g530 ansible_ssh_host=192.168.161.52 再次调用ansible all -m ping，提示成功 dynamic_inventoryhttp://docs.ansible.com/ansible/intro_dynamic_inventory.html暂时不看，等用到的时候再看 pattern &amp; ad-hoc command也暂时略过 playbookping先写一个最简单的ping 12345--- - hosts: g530 tasks: - name: ping ping: 然后调用1ansible-playbook -i /etc/ansible/hosts playbook.yml 显示12345678910PLAY ***************************************************************************TASK [setup] *******************************************************************ok: [g530 -&gt; localhost]TASK [ping] ********************************************************************ok: [g530 -&gt; localhost]PLAY RECAP *********************************************************************g530 : ok=2 changed=0 unreachable=0 failed=0 说明成功 代码放在https://github.com/CodeJuan/ansible_play/tree/master/ping advanced来尝试一个高端点的，带roles handler template的 playbook123456---- name: role_handler hosts: g530 roles: - test 创建roles12345678910current_dir|--playbook.yml|--roles |--test |--handlers |--main.yml |--tasks |--main.yml |--templates |--存放模板 需要创建一个roles文件夹，里边的子文件夹的名字就是playbook里写的roles名字 handlers每个role都会有handlers文件夹，里边的main.yml放一些响应事件123---- name: restart service: name=iptables state=restarted enabled=yes 例子里表示重启iptables tasksrole的tasks里的main.yml就是真正要执行的任务1234---- name: ping and restart iptables ping: notify: restart test 表示先ping，然后调用handler里的restart template在template里创建一个文件haha，将他拷贝到agent的/tmptasks mail.yml改为12345---- name: ping ping: template: src=haha dest=/tmp/haha notify: restart test 提示语法错误，看起来似乎一个name只能有一个操作 改为两个name貌似就好了1234567---- name: ping ping: - name: template iptables template: src=haha dest=/tmp/haha notify: restart test 再play一下12345678910111213PLAY [role_handler] ************************************************************TASK [setup] *******************************************************************ok: [g530 -&gt; localhost]TASK [test : ping] *************************************************************ok: [g530 -&gt; localhost]TASK [test : template iptables] ************************************************changed: [g530 -&gt; localhost]PLAY RECAP *********************************************************************g530 : ok=3 changed=1 unreachable=0 failed=0 果然多了一个操作 代码放在https://github.com/CodeJuan/ansible_play/tree/master/advancded_play 深入学习已经了解了基本概念，接下来就要看一些优秀案例了http://docs.ansible.com/ansible/playbooks_best_practices.htmlhttps://github.com/ansible/ansible-examples 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://blog.decbug.com/tags/ansible/"},{"name":"deploy","slug":"deploy","permalink":"http://blog.decbug.com/tags/deploy/"},{"name":"devops","slug":"devops","permalink":"http://blog.decbug.com/tags/devops/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"换部门","slug":"dept","date":"2015-10-09T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/10/10/dept/","link":"","permalink":"http://blog.decbug.com/2015/10/10/dept/","excerpt":"换了个好玩的部门","text":"换了个好玩的部门 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}],"tags":[{"name":"career","slug":"career","permalink":"http://blog.decbug.com/tags/career/"}],"keywords":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}]},{"title":"tornado+nginx+IP白名单","slug":"tornado","date":"2015-09-12T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2015/09/13/tornado/","link":"","permalink":"http://blog.decbug.com/2015/09/13/tornado/","excerpt":"背景实现白名单，只允许可信用户访问我的服务考虑采用iptables或者nginx 如果用nginx，那么可以建立一个allow_ip.conf，然后把这个配置文件include到nginx的配置中用户可以主动添加他们的IP到我这，打算玩玩tornado，用户输入他的IP，然后存入到我的文件中，最后定时合并到allow_ip.conf","text":"背景实现白名单，只允许可信用户访问我的服务考虑采用iptables或者nginx 如果用nginx，那么可以建立一个allow_ip.conf，然后把这个配置文件include到nginx的配置中用户可以主动添加他们的IP到我这，打算玩玩tornado，用户输入他的IP，然后存入到我的文件中，最后定时合并到allow_ip.conf 分析一下需求 一个input，一个button，点button就把input的内容追加到某个文件中，暂时不考虑input是否合法 tornado 写一个handler 定时把最新的IP合并到allow_ip.con tornado安装12345wget https://pypi.python.org/packages/source/t/tornado/tornado-4.2.1.tar.gztar zxvf tornado-4.2.1.tar.gzcd tornado-4.2.1python setup.py buildsudo python setup.py install 开搞demos先试用一下tornado源码里的demos，找到最简单的helloworld，运行1python helloworld.py 在另一台机器上访问，总是载入不了网页。于是开始排查 本机上查看端口netstat -tulpn | grep :8888 在本机上curl，可以打开 猜测可能是防火墙的问题，iptables -I INPUT -p TCP --dport 8888 -j ACCEPT再次访问，就OK啦 一个输入页面login.html12345678910111213&lt;html&gt; &lt;head&gt; &lt;title&gt;&#123;&#123; title &#125;&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=\"&#123;&#123; request.path &#125;&#125;\" method=\"post\"&gt; &lt;div&gt;&#123;&#123; _(\"你的IP\") &#125;&#125; &lt;input type=\"text\" name=\"username\"/&gt;&lt;/div&gt; &lt;!--&lt;div&gt;&#123;&#123; _(\"Password\") &#125;&#125; &lt;input type=\"password\" name=\"password\"/&gt;&lt;/div&gt; --&gt; &lt;div&gt;&lt;input type=\"submit\" value=\"&#123;&#123; _(\"输入\") &#125;&#125;\"/&gt;&lt;/div&gt; &#123;% module xsrf_form_html() %&#125; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; test.py123456789101112131415161718192021222324252627282930import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): #self.write(\"Hello, world\") items = [\"Item 1\", \"Item 2\", \"Item 3\"] self.render(\"temp.html\", title=\"My title\", items=items)# LoginHandlerclass LoginHandler(tornado.web.RequestHandler): def get(self): # template from login.html self.render(\"login.html\", title=\"login\") def post(self): usr=self.get_argument(\"username\", \"\") #pwd=self.get_argument(\"password\", \"\") self.write(usr) #self.write(pwd)application = tornado.web.Application([ (r\"/\", MainHandler), # login时通过LoginHandler处理 (r\"/login\", LoginHandler),])if __name__ == \"__main__\": application.listen(8888) tornado.ioloop.IOLoop.current().start() 运行效果 保存用户的IP到白名单先写入到一个临时文件，然后定时同步到nginx的配置里include白名单文件allow_ips.conf 写入文件先实现一个最简单的，不考虑锁啊，共享之类的 123456789101112131415161718192021222324252627282930313233343536import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): #self.write(\"Hello, world\") items = [\"Item 1\", \"Item 2\", \"Item 3\"] self.render(\"temp.html\", title=\"My title\", items=items)class LoginHandler(tornado.web.RequestHandler): file_name = \"ip.txt\" FILE = None def get(self): self.render(\"login.html\", title=\"login\") def post(self): usr=self.get_argument(\"username\", \"\") # 把用户输入的IP写入到文件 self.WriteIP(usr) self.write(\"Your IP have been added to the white list\\n\"+usr) # 增加一个writeIP的方法不考虑共享等问题 def WriteIP(self,ip): self.FILE = open(self.file_name, \"w\") self.FILE.writelines(ip)application = tornado.web.Application([ (r\"/\", MainHandler), (r\"/login\", LoginHandler),])if __name__ == \"__main__\": application.listen(8888) tornado.ioloop.IOLoop.current().start() nginx下载安装源码编译1234wget http://nginx.org/download/nginx-1.9.4.tar.gztar zxvf nginx-1.9.4.tar.gzcd nginx-1.9.4./configure 提示缺少C编译器，于是yum install gcc提示缺少pcre library，于是yum -y install pcre-devel接着又提示缺少zlib。。算了，还是换别的方式吧，不从源码编了 yum安装123wget http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpmsudo rpm -ivh nginx-release-centos-7-0.el7.ngx.noarch.rpm sudo yum install nginx 配置nginx.conf1234567server &#123; listen 8777; location / &#123; proxy_pass http://192.168.151.55:8888/; &#125;&#125; 12# 测试配置是否正确sudo nginx -t -c /etc/nginx/nginx.conf iptables我们只是需要一个白名单而已，用nginx是不是太重型化了？iptables热插拔，即使生效，也支持可信ip，而且用起来比较简单。 导入导出12345# export the rules of iptableiptables-save &gt; /some/file# restoreiptables-restore &lt;/some/file 即时生效 Is a reboot required after edit/saving linux iptables? iptables rules take effect immediately.Changes to iptables take effect immediately when they are run.However, your language of “edit and save” makes me think you are editing a conf file or script of some kind rather than actually running the iptables commands.If you are making your changes in a script, you must make sure that script gets run in order for the changes to take affect. 使用生产环境的使用最终还是采用了nginx 用户注册，将IP保存到数据库 定时从数据库中取IP，并生成allow_ips.conf nginx reload -s 12345678910# nginx 配置 server &#123; listen 8777; location / &#123; include allow_ips.conf deny all; errorpage 403 http://register_server:port; proxy_pass http://192.168.151.55:8888/; &#125; &#125; 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"python","slug":"python","permalink":"http://blog.decbug.com/tags/python/"},{"name":"tornado","slug":"tornado","permalink":"http://blog.decbug.com/tags/tornado/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"多线程同步镜像","slug":"multi_thread_rsync","date":"2015-09-06T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/09/07/multi_thread_rsync/","link":"","permalink":"http://blog.decbug.com/2015/09/07/multi_thread_rsync/","excerpt":"背景为了提高工作效率，我司的软件青年们搭建了一组内网mirror，包括apache，pip，npm，jenkins，ubuntu等等。想用得爽，就得保持与官方一致，需要很频繁的同步。以前的同步是单线程的，感觉没有完全发挥带宽的优势，所以想尝试一下多线程同步。 大概的思路 爬index，如hust的镜像http://mirrors.hust.edu.cn/ubuntu-releases/，找出所有href。 每个href就启动一个rsync或者wget，同步到对应的文件夹 记录每个href的同步状态 汇总全部状态，看所有href是否都同步成功","text":"背景为了提高工作效率，我司的软件青年们搭建了一组内网mirror，包括apache，pip，npm，jenkins，ubuntu等等。想用得爽，就得保持与官方一致，需要很频繁的同步。以前的同步是单线程的，感觉没有完全发挥带宽的优势，所以想尝试一下多线程同步。 大概的思路 爬index，如hust的镜像http://mirrors.hust.edu.cn/ubuntu-releases/，找出所有href。 每个href就启动一个rsync或者wget，同步到对应的文件夹 记录每个href的同步状态 汇总全部状态，看所有href是否都同步成功 shell爬步骤 wget镜像的index.html 正则匹配，找到二级目录href- xargs -P 八个线程同时wget -r 有个问题，如何获取每个href的同步状态，成功还是失败？ 代码放在https://github.com/CodeJuan/multi_thread_rsync_mirror wget index.html12# get index.htmlwget $link -O $file regex得到二级目录123# grep \"href\" \"&lt;a\" \"/$\"# cut \"\\\"\"cat $bak_file | grep \"href*=*\\\"\" | grep \"&lt;a\" | cut -d \"\\\"\" -f 2 | grep \"/$\" | grep -v \"\\.\\.\" xargs -P 八个线程同时wget -r1echo $&#123;whole_url_list[@]&#125; | xargs -n 1 -P 8 ./single_down.sh \"$des\" 还没实现获取同步状态如果下载失败了，完全没有办法知道。下一步实现 另一种玩法：python爬步骤装beautifulsoup12345678#下载并安装pipwget https://pypi.python.org/packages/source/p/pip/pip-7.1.2.tar.gztar zxvf pip-7.1.2.tar.gzcd pip-7.1.2sudo python setup.py install#装beautifulsoup4sudo pip install beautifulsoup4 开始爬由于index的页面都很简洁，爬起来还是相对比较容易。 以后有空搞定～～ 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"mirror","slug":"mirror","permalink":"http://blog.decbug.com/tags/mirror/"},{"name":"python","slug":"python","permalink":"http://blog.decbug.com/tags/python/"},{"name":"rsync","slug":"rsync","permalink":"http://blog.decbug.com/tags/rsync/"},{"name":"wget","slug":"wget","permalink":"http://blog.decbug.com/tags/wget/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"指标下的单元测试","slug":"fake_unit_test","date":"2015-08-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/08/23/fake_unit_test/","link":"","permalink":"http://blog.decbug.com/2015/08/23/fake_unit_test/","excerpt":"前言 最近领导强推单元测试覆盖率，要求达到80%。我打探了一下，据说覆盖率是更上层领导的考核指标，所以今年我们组一大任务就是这。没几个人觉得写好单元测试是为了提升软件质量，提高自己的代码水平。可以预见的是，有人会为了提高覆盖率，写一堆无效代码。 “上有所好，下必甚焉”。 距离我上一次吐槽已经过去了半年，我们的单元测试变成了什么情况呢？半年前我的猜测是为了提高覆盖率，写一堆无效代码，然而实际情况却比这更糟糕。 有人的测试函数的末尾始终是1EXPECT_EQ(TRUE=TRUE) 这样每个用例都是绿的 还有人这么写12//init module//run module 测试的是整个模块的输入输出，这样可以保证覆盖率 领导看到用例一片绿，覆盖率90%，觉得我们的代码质量很高。 然而，这并没有什么卵用！！！这真的没有什么卵用！这真的没有什么卵用！这真的没有什么卵用！","text":"前言 最近领导强推单元测试覆盖率，要求达到80%。我打探了一下，据说覆盖率是更上层领导的考核指标，所以今年我们组一大任务就是这。没几个人觉得写好单元测试是为了提升软件质量，提高自己的代码水平。可以预见的是，有人会为了提高覆盖率，写一堆无效代码。 “上有所好，下必甚焉”。 距离我上一次吐槽已经过去了半年，我们的单元测试变成了什么情况呢？半年前我的猜测是为了提高覆盖率，写一堆无效代码，然而实际情况却比这更糟糕。 有人的测试函数的末尾始终是1EXPECT_EQ(TRUE=TRUE) 这样每个用例都是绿的 还有人这么写12//init module//run module 测试的是整个模块的输入输出，这样可以保证覆盖率 领导看到用例一片绿，覆盖率90%，觉得我们的代码质量很高。 然而，这并没有什么卵用！！！这真的没有什么卵用！这真的没有什么卵用！这真的没有什么卵用！ 分析 正如我所说没几个人觉得写好UT是为了提升软件质量，提高自己的代码水平 责任心？能想出这样方法的人，都是比较聪明的人。只能说是责任心吧。 管理方式？为什么没有早点发现？为什么我没有去经常查看单元测试代码的提交记录（我平时会看看生产代码）？我有罪。 待续 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"indicator","slug":"indicator","permalink":"http://blog.decbug.com/tags/indicator/"},{"name":"unit_test","slug":"unit-test","permalink":"http://blog.decbug.com/tags/unit-test/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"docker(1)-初学","slug":"docker_tutorial","date":"2015-08-22T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/08/23/docker_tutorial/","link":"","permalink":"http://blog.decbug.com/2015/08/23/docker_tutorial/","excerpt":"背景虽然久闻docker大名，但一直没有尝试过，固然可以说是比较忙的原因，但忙不是我们不学习新技术的借口。也许以后工作可能会用到docker，我得未雨绸缪，提前准备，开始学docker了","text":"背景虽然久闻docker大名，但一直没有尝试过，固然可以说是比较忙的原因，但忙不是我们不学习新技术的借口。也许以后工作可能会用到docker，我得未雨绸缪，提前准备，开始学docker了 安装参考installation on CentOS 查看内核版本 Docker requires a 64-bit installation regardless of your CentOS version. Also, your kernel must be 3.10 at minimum, which CentOS 7 runs.要求centos7 64-bit 1uname -r 我的是CentOS7，3.10.0-229.el7.x86_64，符合要求 用脚本安装 yum package最新 1sudo yum update Run the Docker installation script. 1curl -sSL https://get.docker.com/ | sh This script adds the docker.repo repository and installs Docker. Start the Docker daemon.1sudo service docker start 失败了，提示Job for docker.service failed. See &#39;systemctl status docker.service&#39; and &#39;journalctl -xn&#39; for details.查了一下，#15498有人说要装docker-selinux1sudo yum install docker-selinux 然后1sudo service docker start 果然complete verify1sudo docker run hello-world 123456789101112131415161718192021222324252627Unable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world535020c3e8ad: Pull complete af340544ed62: Already exists library/hello-world:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.Digest: sha256:d5fbd996e6562438f7ea5389d7da867fe58e04d581810e230df4cc073271ea52Status: Downloaded newer image for hello-world:latestHello from Docker.This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker Hub account: https://hub.docker.comFor more examples and ideas, visit: https://docs.docker.com/userguide/ 进阶 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"centos","slug":"centos","permalink":"http://blog.decbug.com/tags/centos/"},{"name":"docker","slug":"docker","permalink":"http://blog.decbug.com/tags/docker/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"抄代码引发的句柄泄漏","slug":"handle_leak","date":"2015-08-05T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/08/06/handle_leak/","link":"","permalink":"http://blog.decbug.com/2015/08/06/handle_leak/","excerpt":"背景现象主进程不断调用7z.exe进行解压，当文件数量较小时，顺利运行。当文件数量达到几十万的时候，运行过程中7z报错，fatal error 2。网上很多同僚说这是由于系统资源不足造成的。观察此时的内存及磁盘使用情况，都很充裕，但为何还说资源不足呢？于是开启了蛋疼的定位之旅，至于为什么说很蛋疼呢，这是因为是一个低级错误导致的问题。 心急的朋友可以直接看原理:https://github.com/CodeJuan/HandleLeak 不着急的朋友可以慢慢看定位过程","text":"背景现象主进程不断调用7z.exe进行解压，当文件数量较小时，顺利运行。当文件数量达到几十万的时候，运行过程中7z报错，fatal error 2。网上很多同僚说这是由于系统资源不足造成的。观察此时的内存及磁盘使用情况，都很充裕，但为何还说资源不足呢？于是开启了蛋疼的定位之旅，至于为什么说很蛋疼呢，这是因为是一个低级错误导致的问题。 心急的朋友可以直接看原理:https://github.com/CodeJuan/HandleLeak 不着急的朋友可以慢慢看定位过程 过程句柄泄漏鉴于内存及硬盘都充足，那么猜测可能算句柄泄漏。先简单说下句柄泄漏的概念： 句柄，可以简单理解为某个资源的名字。 泄漏，跟内存泄漏一个泄漏，用了忘记释放，导致可用资源越来越少。 A handle leak is a type of software bug that occurs when a computer program asks for a handle to a resource but does not free the handle when it is no longer used. If this occurs frequently or repeatedly over an extended period of time, a large number of handles may be marked in-use and thus unavailable, causing performance problems or a crash. 验证泄漏把有问题的代码抠出来，写一个demo，循环跑。观察句柄情况。 1234567891011121314151617while(1)&#123; SHELLEXECUTEINFO ShExecInfo = &#123;0&#125;; ShExecInfo.cbSize = sizeof(SHELLEXECUTEINFO); ShExecInfo.fMask = SEE_MASK_NOCLOSEPROCESS; ShExecInfo.hwnd = NULL; ShExecInfo.lpVerb = _T(\"open\"); ShExecInfo.lpFile = _T(\"cmd\"); ShExecInfo.lpParameters = _T(\"/c echo 111\"); ShExecInfo.lpDirectory = NULL; ShExecInfo.nShow = SW_HIDE; ShExecInfo.hInstApp = NULL; ShellExecuteEx(&amp;ShExecInfo); WaitForSingleObject(ShExecInfo.hProcess,INFINITE); &#125; 查看任务管理器中性能页显示的总句柄数，果然是不停在上涨，说明猜测成立 7z泄漏？猜测可能算7z自身有泄漏，然而很快又否决了。就像内存泄漏一样，当进程结束的时候，所有资源都会被系统回收，不会继续作恶下去。 When the program terminates, all its open handles are closedYes, a “memory leak” is simply memory that a process no longer has a reference to, and thus can no longer free. The OS still keeps track of all the memory allocated to a process, and will free it when that process terminates. 说明只是我们自己的主进程有泄漏 查看主进程句柄通过任务管理器查看进程的句柄数，方法选项-查看列-选中句柄计数 句柄情况如图所示 运行一段时间后400+句柄 再过一段时间1000+句柄 接下来2000+句柄 看来真的是泄漏了 查看代码看一下SHELLEXECUTEINFOW的定义123456789101112131415161718192021222324typedef struct _SHELLEXECUTEINFOW&#123; DWORD cbSize; // in, required, sizeof of this structure ULONG fMask; // in, SEE_MASK_XXX values HWND hwnd; // in, optional LPCWSTR lpVerb; // in, optional when unspecified the default verb is choosen LPCWSTR lpFile; // in, either this value or lpIDList must be specified LPCWSTR lpParameters; // in, optional LPCWSTR lpDirectory; // in, optional int nShow; // in, required HINSTANCE hInstApp; // out when SEE_MASK_NOCLOSEPROCESS is specified void *lpIDList; // in, valid when SEE_MASK_IDLIST is specified, PCIDLIST_ABSOLUTE, for use with SEE_MASK_IDLIST &amp; SEE_MASK_INVOKEIDLIST LPCWSTR lpClass; // in, valid when SEE_MASK_CLASSNAME is specified HKEY hkeyClass; // in, valid when SEE_MASK_CLASSKEY is specified DWORD dwHotKey; // in, valid when SEE_MASK_HOTKEY is specified union &#123; HANDLE hIcon; // not used#if (NTDDI_VERSION &gt;= NTDDI_WIN2K) HANDLE hMonitor; // in, valid when SEE_MASK_HMONITOR specified#endif // (NTDDI_VERSION &gt;= NTDDI_WIN2K) &#125; DUMMYUNIONNAME; HANDLE hProcess; // out, valid when SEE_MASK_NOCLOSEPROCESS specified&#125; SHELLEXECUTEINFOW, *LPSHELLEXECUTEINFOW; 注意看HANDLE hProcess;// out, valid when SEE_MASK_NOCLOSEPROCESS specified 也就是说，如果指定了SEE_MASK_NOCLOSEPROCESS，hProcess就是返回的句柄。如果不关闭，就会造成句柄泄漏。 我们的代码为了等待进程结束，设置了SEE_MASK_NOCLOSEPROCESS，然后WaitForSingleObject(ShExecInfo.hProcess,INFINITE); 然后又没有关闭ShExecInfo.hProcess，导致句柄不断上涨 CloseHandle加上CloseHandle之后1CloseHandle(ShExecInfo.hProcess); 句柄始终保持在100左右 修改正式代码，运行50万次依旧稳定，问题解决。 结论询问组内同事，说这段代码是从CSDN上抄来的，没有深入了解代码的意思，没有注意到SEE_MASK_NOCLOSEPROCESS。 抄代码一定要小心谨慎，需要仔细阅读官方说明，把参数的意义都理解清楚 仅仅跑起来，凑合着用是不够的，需要做一做压力测试 这次看句柄的方式比较落伍，需要整理一下如何用windbg查句柄泄漏的方法，下一篇就写这个吧。 参考HandleLeakPushing the Limits of Windows: HandlesIs leaked memory freed up when the program exits? 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://blog.decbug.com/tags/C/"},{"name":"handle","slug":"handle","permalink":"http://blog.decbug.com/tags/handle/"},{"name":"leak","slug":"leak","permalink":"http://blog.decbug.com/tags/leak/"},{"name":"process","slug":"process","permalink":"http://blog.decbug.com/tags/process/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"自动生成软件中模块依赖图","slug":"pe_depen","date":"2015-07-25T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/07/26/pe_depen/","link":"","permalink":"http://blog.decbug.com/2015/07/26/pe_depen/","excerpt":"前言上回实现了自动生成sln中各project依赖图，可以分析一个VS solution里面每个project的依赖关系，但是这个太弱了。我需要exe、dll之间依赖图，所以只能继续想办法了。 思路 获取该软件目录下所有模块(exe和dll) 通过vs自带的dumpbin命令得到每个模块文件的依赖 画出graphviz的dot脚本 graphviz绘图","text":"前言上回实现了自动生成sln中各project依赖图，可以分析一个VS solution里面每个project的依赖关系，但是这个太弱了。我需要exe、dll之间依赖图，所以只能继续想办法了。 思路 获取该软件目录下所有模块(exe和dll) 通过vs自带的dumpbin命令得到每个模块文件的依赖 画出graphviz的dot脚本 graphviz绘图 使用方法代码已经写好，放在https://github.com/CodeJuan/pe_dependency先说怎么用 安装graphviz2.38http://www.graphviz.org/Download_windows.php到D盘program files 安装VS2010到到D盘program files1powershell .\\dependency.ps1 -sw_path &#34;&#36719;&#20214;&#30340;&#36335;&#24452;&#34; 比如说我要分析腾讯TM，那么powershell .\\dependency.ps1 -sw_path &quot;D:\\Program Files\\Tencent\\TM&quot;就OK啦 代码获取目录下所有PE12$get_pe_cmd = \"dir /S /B /a-d-h-s `\"$sw_path`\" | findstr /I `\".dll .exe`\" &gt; files.txt\"cmd /c \"$get_pe_cmd\" 其中findstr /I表示忽略大小写 拷贝mspdb100.dll由于无法直接调用vs2010 command prompt，所以没有设置环境变量，在使用dumpbin的时候会提示缺少mspdb100.dll，这就需要把mspdb100.dll拷贝到dumpbin.exe所在的vc_bin目录下12$vs_path=\"D:\\Program Files\\Microsoft Visual Studio 10.0\"copy-item \"$vs_path\\Common7\\IDE\\mspdb100.dll\" \"$vc_bin\" -Force 我的测试机是x86 32位，如果路径有变化，修改$vs_path即可 graphviz画图123$graph_dot=\"D:\\Program Files\\Graphviz2.38\\bin\\dot.exe\"$draw = \"`\"$graph_dot`\" -Tpng graph.txt &gt; graph.png\" cmd /c \"$draw\" 我的graphviz装在D盘，如果有变化，修改$graph_dot即可 通过dumpbin获取依赖12$dump_cmd = \"`\"$dumpbin`\" /dependents `\"$line`\" | findstr /I .dll | findstr /I /vi `\"dump of file`\" &gt; $deptxt\"cmd /c \"`\"$dump_cmd`\"\" 把依赖关系写入dot1234567append \"`\"$pename`\"[shape=box,fontname=consolas];\"append \"`\"$pename`\"-&gt;&#123;\"if ($bFound -eq 1)&#123; append \"`\"$depen`\";\"&#125;append \"&#125;;\" graphviz画图12345$draw = \"`\"$graph_dot`\" $graphtxt -Tpng &gt; dependency_graph.png\" write-host $drawcmd /c \"$draw\"` 效果图分析了一下腾讯TM 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"dependency","slug":"dependency","permalink":"http://blog.decbug.com/tags/dependency/"},{"name":"graphviz","slug":"graphviz","permalink":"http://blog.decbug.com/tags/graphviz/"},{"name":"module","slug":"module","permalink":"http://blog.decbug.com/tags/module/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"在家里玩分布式(1)install centos","slug":"install_centos","date":"2015-07-24T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/07/25/install_centos/","link":"","permalink":"http://blog.decbug.com/2015/07/25/install_centos/","excerpt":"扯淡自己在家玩，买了一堆二手配件，整了4个台式机，打算 - 弄个scrapy爬数据 - 存到分布式内存数据库(redis吧) - 再存到分布式文件系统(打算用fastdfs) - 同时用storm流计算，弄个什么东西挖掘一下 - 最后用PHP展示 也勉强算是跟大数据沾点边，几台机器都自动化起来，也get以下运维技能吧。","text":"扯淡自己在家玩，买了一堆二手配件，整了4个台式机，打算 - 弄个scrapy爬数据 - 存到分布式内存数据库(redis吧) - 再存到分布式文件系统(打算用fastdfs) - 同时用storm流计算，弄个什么东西挖掘一下 - 最后用PHP展示 也勉强算是跟大数据沾点边，几台机器都自动化起来，也get以下运维技能吧。 centos下载isohttp://www.centos.org/download/ minimal: The aim of this image is to install a very basic CentOS system, with the minimum of packages needed to have a functional system dvd: 一般选择这个下载x86_64 分区/、/boot、/home、swap 就够了 预装软件选择开发者模式，可以把python jdk都装上 设置自动登录1vi /etc/gdm/custom.conf 写上123[daemon]AutomaticLoginEnable=trueAutomaticLogin=你的用户名 启动网络12sudo ntsysv# TAB切换到OK 修改/etc/sysconfig/network-scripts/ifcfg-enp2s0,设置为onboot=yes 安装启动SSH1yum install ssh&#10;service sshd start&#10;chkconfig sshd on 路由器设置固定IP 查看每台机器的MAC ifconfig 进入路由器管理页面，DHCP - 静态地址分配 - 绑定MAC和IP 安装vim git1yum -y install vim&#10;yum -y install git 123git clone https://github.com/CodeJuan/config.gitcp config/.vimrc ~/cat config/.gitconfig &gt;&gt; ~/.gitconfig 装爬虫装pip1234wget --no-check-certificate https://github.com/pypa/pip/archive/7.1.0.tar.gztar zvxf 7.1.0.tar.gz #解压文件cd pip-7.1.0sudo python setup.py install 装scrapy1sudo pip install scrapy 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"system","slug":"system","permalink":"http://blog.decbug.com/tags/system/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"自动生成sln中各project依赖图","slug":"dependency_in_sln","date":"2015-07-05T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/07/06/dependency_in_sln/","link":"","permalink":"http://blog.decbug.com/2015/07/06/dependency_in_sln/","excerpt":"前言为了提高构建效率，需要分析sln中各project的依赖关系，将相互独立的project分配到不同机器并行构建。如果是一个个打开工程并查看dependency，然后画出依赖图，实在是太繁琐了。这就需要将这一些工作用脚本来实现。 写好的代码放在https://github.com/CodeJuan/dependency_in_sln，使用方法也很简单。","text":"前言为了提高构建效率，需要分析sln中各project的依赖关系，将相互独立的project分配到不同机器并行构建。如果是一个个打开工程并查看dependency，然后画出依赖图，实在是太繁琐了。这就需要将这一些工作用脚本来实现。 写好的代码放在https://github.com/CodeJuan/dependency_in_sln，使用方法也很简单。 思考采用的技术 Graphviz is open source graph visualization software. Graph visualization is a way of representing structural information as diagrams of abstract graphs and networks. It has important applications in networking, bioinformatics, software engineering, database and web design, machine learning, and in visual interfaces for other technical domains. DOT is a plain text graph description language. It is a simple way of describing graphs that both humans and computer programs can use. graphviz是画图神器，dot可以描述图，二者结合，就能画出各种神奇的图片 步骤 解析sln，得出各工程的依赖关系 依据第1步的依赖关系生成dot文件 graphviz调用第2步的dot文件，生成图片 实施sln规律先看一段例子123456Project(\"&#123;8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942&#125;\") = \"gtest_unittest\", \"gtest_unittest.vcxproj\", \"&#123;4D9FDFB5-986A-4139-823C-F4EE0ED481A1&#125;\" ProjectSection(ProjectDependencies) = postProject &#123;24848551-EF4F-47E8-9A9D-EA4D49BC3ECA&#125; = &#123;24848551-EF4F-47E8-9A9D-EA4D49BC3ECA&#125; &#123;C8F6C172-56F2-4E76-B5FA-C3B423B31BE7&#125; = &#123;C8F6C172-56F2-4E76-B5FA-C3B423B31BE7&#125; EndProjectSectionEndProject project的开头 1Project(\"&#123;8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942&#125;\") = \"gtest_unittest\", \"gtest_unittest.vcxproj\", \"&#123;4D9FDFB5-986A-4139-823C-F4EE0ED481A1&#125;\" # 格式是Project(\"&#123;sln guid&#125;\") = \"project name\", \"relative path\", \"&#123;project guid&#125;\" project的结尾 1EndProject 依赖关系 123ProjectSection(ProjectDependencies) = postProject # 依赖了哪些工程的开头&#123;24848551-EF4F-47E8-9A9D-EA4D49BC3ECA&#125; = &#123;24848551-EF4F-47E8-9A9D-EA4D49BC3ECA&#125; #依赖工程的guidEndProjectSection # 依赖描述结尾 发现这样的规律，就能够很方便的解析了 代码由于是在windows上面解析，有同事不会用shell，于是只好用powershell重写一遍 遍历sln的每一行，进行分析，并写入dot123456789if ($line -like \"Project(`\"&#123;*\") #如果匹配到了project开头&#123; $array = $line.split(\"`\"\"); $name = $array[3] $id = $array[7] $script:prj_name_list += $name $script:prj_id_list += $id append \"$name[shape=box,fontname=consolas];\" # 在dot写入这个project的描述&#125; 12345if ($line -like \"*ProjectSection(*\") &#123; $name = $script:prj_name_list[$script:prj_name_list.length - 1] append \"$name-&gt;&#123;\" # 匹配到依赖了哪些工程的开头，开始写入依赖关系 &#125; 1234if ($line -like \"*EndProjectSection*\") &#123; append \"&#125;;\" # 匹配到了依赖描述结尾，写入&#125;;，完成了这个project的依赖描述 &#125; 123456789101112131415if ($line -like \"*&#123;*&#125; = &#123;*&#125;*\") # 通过大括号识别是否是工程依赖&#123; $right = $line.lastindexof(\"&#125;\") $left = $line.lastindexof(\"&#123;\") $dep_id = $line.substring($left+1, $right-$left-1) for ($i = 0; $i -lt $script:prj_id_list_query.length; $i++) &#123; $cur_id = $script:prj_id_list_query[$i] if ( $dep_id -like \"$cur_id\") &#123; $dep_name = $script:prj_name_list_query[$i] append \"$dep_name;\" &#125; &#125;&#125; 生成的dot1digraph G &#123;&#10;rankdir=BT;&#10;gtest[shape=box,fontname=consolas];&#10;gtest_main[shape=box,fontname=consolas];&#10;gtest_unittest[shape=box,fontname=consolas];&#10;gtest_unittest-&#62;&#123;&#10;gtest_prod_test;&#10;gtest;&#10;&#125;;&#10;gtest_prod_test[shape=box,fontname=consolas];&#10;&#125; demo 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"dependency","slug":"dependency","permalink":"http://blog.decbug.com/tags/dependency/"},{"name":"dot","slug":"dot","permalink":"http://blog.decbug.com/tags/dot/"},{"name":"graphviz","slug":"graphviz","permalink":"http://blog.decbug.com/tags/graphviz/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"hexo and pelican","slug":"Pelican_hexo","date":"2015-06-21T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2015/06/22/Pelican_hexo/","link":"","permalink":"http://blog.decbug.com/2015/06/22/Pelican_hexo/","excerpt":"用pelican或hexo建一个漂亮的博客","text":"用pelican或hexo建一个漂亮的博客 installpython 2.7https://www.python.org/downloads/release/python-2710/ easy_installhttps://pypi.python.org/pypi/setuptoolshttps://bootstrap.pypa.io/ez_setup.py1E:\\Python27\\python.exe ez_setup.py pipeasy_install pip 提示找不到命令设置环境变量 E:\\Python27;E:\\Python27\\Scripts其实新版的python都自带了pip，无需安装 makehttp://pan.baidu.com/s/1hqzJBBe解压到python目录 pelicanpip install pelican markdown1pip install markdown quick-starthttps://en.wikipedia.org/wiki/List_of_tz_database_time_zonestimezone Asia/Shanghai run1pelican content&#10;cd ~/projects/yoursite/output&#10;python -m pelican.server themes下载themes1pelican theme -i &#34;&#20320;&#21916;&#27426;&#30340;&#20027;&#39064;&#34; hexoinstalldownload1npm install -g hexo&#10;mkdir blog&#10;cd blog&#10;hexo init&#10;npm install&#10;hexo generate&#10;hexo server themeclone theme to folder themes_config.yml theme: jacman 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://blog.decbug.com/tags/blog/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"身边的过早优化事件","slug":"Premature_Optimization","date":"2015-06-13T15:30:09.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2015/06/13/Premature_Optimization/","link":"","permalink":"http://blog.decbug.com/2015/06/13/Premature_Optimization/","excerpt":"背景组里小伙要对他们的代码进行优化，分析之后，觉得没有什么拖慢性能的代码，于是决定多开几个线程。我得知之后，与他进行了一番对话，终于说服了他在动手优化之前进行充分测量，找出瓶颈再有针对性的优化。","text":"背景组里小伙要对他们的代码进行优化，分析之后，觉得没有什么拖慢性能的代码，于是决定多开几个线程。我得知之后，与他进行了一番对话，终于说服了他在动手优化之前进行充分测量，找出瓶颈再有针对性的优化。 对话如下： 我：你测量过了嘛？ 他：什么是测量？ 我：测量就是对你现有的代码profile，因为经验也好，直觉也罢，都是不可靠的，我们需要证据。从我目前看到的情况来看，我觉得你的数据不足以支持你进行多线程改造。 他：我已经看了三遍代码，没有发现优化的地方。 我：细节里藏着魔鬼，有时候我们的肉眼，我们的直觉都不可靠。所以我希望你能够测量之后再优化。 他：相信我，我觉得多线程是目前最好的解决方案。 此时我想，看来光讲道理行不通，得换个方式了，于是说道：好的，假定多线程是最好的解决方案。那么我想知道，你完成你的方案需要多长时间？能跟上我们版本的节奏吗？ 他犹豫一下说道：大约需要5天吧，放心，我肯定不会拖后腿的。 我：好的，我相信你的能力，你肯定能把你的方案做好。但是，我有一个建议。如果我有一个简单的方案，只需要2～3个小时，就能得出结果。也许能解决你的问题，当然，也可能无法解决，你还得做你的多线程。但无论如何，这都算是一个投入非常少的方案，愿不愿意试一下？就算是无法解决，你也不算一无所获，至少掌握了profile的方法。 他：好的，试一下吧，如果不行，我还是要弄多线程的。你可要帮我检查一下我写的多线程代码。 然后我把使用文档给他，他照着文档用性能分析工具跑了一下代码，果然找到了瓶颈代码，在一个循环里用一个vector对另外一个vector赋值，如你所知，会产生NNNN多次的构造析构，不慢才怪。修改之后，性能瞬间提升1倍，达成了目标。 坦白说，这是一个很低级的错误，我曾在编码tips里提过多次，然而并没有什么卵用。周围的小伙子们依旧如故，有时候真的挺失望的，一定要通过领导来施压，他们才愿意遵守吗？其实我特别不想通过行政手段来实现目标，低效且低级的手段。当然，这是另一件事，这里就不吐槽了。 过早优化是万恶之源 Donald Knuth曾经曰过：Don’t Cut Yourself: Code Optimization as a Double-Edged Sword。 中文翻译：过早优化是万恶之源。 1 究竟要优化什么？ 2 选择一个正确的优化指标 3 优化在刀刃上 4 优化层次越高越好 5 不要过早优化 6 依赖性能分析，而不是直觉 7 优化不是万金油 大道理，我们都懂，然而却过不好这一生。这句话我们经常听到，但是在实际工作中却对自己过于自信。 总结我的优化流程： 先对当前代码profile，多采集几次，有足够的样本。 针对热点进行分析，尽量用小的改动，实现大的提升。 改一点，验证一点，并记录下优化后的数据。如此往复。 PS 一直以来，这个小伙都比较傲娇，都不怎么听周围的人的意见，也不怎么听我的（后来才知道，因为之前有人谣传我是91年的，而他是89年的，所以他觉得我比较菜。。。。。）自从这件事之后，他对我的态度明显好多了。码农圈子还是要用技术说话啊，吹的天花乱坠都没用。 和别人沟通（也许可以算是辩论）的时候，一定面带微笑，降低语速，摆事实讲道理表明自己的意见。越是意见不一致，就越需要控制语气。舒适的对话，是达成共识的基础。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"optimize","slug":"optimize","permalink":"http://blog.decbug.com/tags/optimize/"},{"name":"profiler","slug":"profiler","permalink":"http://blog.decbug.com/tags/profiler/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"读程序员职业规划书有感","slug":"career_of_programmer","date":"2015-06-11T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/06/11/career_of_programmer/","link":"","permalink":"http://blog.decbug.com/2015/06/11/career_of_programmer/","excerpt":"前言 最近被挖猎几次，虽说心动不已，但我年事已高，不复当年之热血，故对未来的职业规划愈发迷茫，愈发谨慎。恰巧得到@Easy兄惠赠的《程序员必读的职业规划书》，拜读之下有所收获。","text":"前言 最近被挖猎几次，虽说心动不已，但我年事已高，不复当年之热血，故对未来的职业规划愈发迷茫，愈发谨慎。恰巧得到@Easy兄惠赠的《程序员必读的职业规划书》，拜读之下有所收获。 跳槽 不要因为“现在很差”而跳槽，要为“未来更好”而跳槽 就我个人而言，每次跳槽都是一次很艰难的决定，因为有得必有失。有时候是为了更多的金钱放弃现在轻松不加班的工作；有时候是为了get新技能而放弃现在丰厚的薪水。但无论如何，我们的得到的都比失去的多，也就是我现在的决定让我的未来更好，也许这个好需要很长一段时间才能体现出来。 现在的工作各方面都挺好，可是对于我个人的技术能力提升的空间已经不大。作为想努力成为大牛的人，我期望能补齐我的短板，丰富我的技能树。也就是说想要一份更有挑战的工作，薪水不要比现在差就好。 秀出自己的肌肉虽然周围的朋友都决定我水平还行，可我还是觉得自己比较菜，越学习，就觉得自己越菜，我经常说自己还是菜鸟，要学的东西还很多 然而在求职的时候，却容不得半点谦虚，要把自己的能力都展现出来，才能让雇主给出合适的薪水。像我们猿类都比较低调，陌生人比较难发现我们的亮点。这时候就需要构建个人品牌，把自己的优势都展示出来。只是空口无凭，雇主如何才能相信你？这个时候就需要博客，博客是最好的简历，曾做过什么，解决过什么，玩过什么，学了什么，都可以通通记录下来。 自己可以常常回顾，温故知新； 可以把自己的能力，经验以及业余时间的研究都展示出来； 锻炼自己的写作沟通能力，程序员也要多写作； 晚上下班还愿意做总结的人，技术一般不会太差； 也许我的博客能帮到别人呢？我经常拜读大牛们博客，有时真的大有收获。虽然我水平离大牛很远，但我解决的问题可能别人也会遇到，看我的博客之后就能少走点弯路。 总结工作不是一件容易的事，跳槽则更难。每一个决定都可能影响未来几年的职业生涯，我们无法预见未来，我们只能把握当下，努力提升自己的能力，总归是不差的。 当你的能力足够强，必然会有一份满意的工作，区别只是在哪家公司干而已 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"career","slug":"career","permalink":"http://blog.decbug.com/tags/career/"},{"name":"programmer","slug":"programmer","permalink":"http://blog.decbug.com/tags/programmer/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"自动调用windbg分析dump","slug":"auto_analyze_dump","date":"2015-04-15T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/04/15/auto_analyze_dump/","link":"","permalink":"http://blog.decbug.com/2015/04/15/auto_analyze_dump/","excerpt":"前言最近开始整并发，项目组的年轻人对共享资源的控制不够熟悉，导致经常core dump。虽然我在文档里写了，用windbg打开dmp，然后输入!analyze -v就能看到挂在哪一行，但是经常有小朋友来问命令怎么用。 老夫一怒之下，就开始反思。是我的文档写的不够清晰？还是操作太繁琐了？其实都不是，说白了就是现在的年轻人都太懒了。 竟然都这么懒惰，那么我只好想出个更简便的方法来分析dump，一键式傻瓜操作，这样应该可以了吧。","text":"前言最近开始整并发，项目组的年轻人对共享资源的控制不够熟悉，导致经常core dump。虽然我在文档里写了，用windbg打开dmp，然后输入!analyze -v就能看到挂在哪一行，但是经常有小朋友来问命令怎么用。 老夫一怒之下，就开始反思。是我的文档写的不够清晰？还是操作太繁琐了？其实都不是，说白了就是现在的年轻人都太懒了。 竟然都这么懒惰，那么我只好想出个更简便的方法来分析dump，一键式傻瓜操作，这样应该可以了吧。 初稿通过powershell启动windbg，然后调用sendwait输入!analyze -v 1234[System.Reflection.Assembly]::LoadWithPartialName(\"'Microsoft.VisualBasic\")start-process windbg.exe -z \"dump file 路径\"# &#123;~&#125;表示ENTER [System.Windows.Forms.SendKeys]::SendWait(\"!analyze -v&#123;~&#125;\") 通过模拟键盘消息实现，在输入过程中必须保持焦点在windbg上，不允许动键盘鼠标，不够人性化。 还需要进一步完善 完善微软关于windbg命令行的说明https://msdn.microsoft.com/zh-cn/library/ff561306 initial command -c-c command可以给windbg设置启动后的初始命令。 Specifies the initial debugger command to run at start-up. Multiple commands can be separated with semicolons. 既然可以设置命令，那么就可以抛弃powershell发键盘消息的方式了，直接写个batch搞定。 脚本 1&#34;&#23433;&#35013;&#30446;&#24405;\\windbg.exe&#34; -z &#34;dump file &#36335;&#24452;&#34; -c &#34;!analyze -v&#34; logo有时候需要保存log，以前的做法是选中windbg的output，然后CTRL+C，CTRL+V到一个文本里。多次键盘鼠标操作，太麻烦，看看能否有命令行可以实现。 找到一个-log{o|a} LogFile Begins logging information to a log file. If the specified log file already exists, it will be overwritten if -logo is used. If loga is used, the output will be appended to the file. For more details, see Keeping a Log File. 脚本升级为 1&#34;&#23433;&#35013;&#30446;&#24405;\\windbg.exe&#34; -z &#34;dump file &#36335;&#24452;&#34; -c &#34;!analyze -v&#34; -logo &#34;dump file &#36335;&#24452;.log&#34; 效果每人每天分析3次dump，每次敲命令+拷贝log需要花1~3分钟的时间，团队里共有150个开发，一天就能节省150人3次2分钟=900分钟。 很可观的收益啊，不由得老怀大慰。 程序员就是要从机械繁琐的工作中超脱出来，投入到更有意义的事情上去。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"dump","slug":"dump","permalink":"http://blog.decbug.com/tags/dump/"},{"name":"powershell","slug":"powershell","permalink":"http://blog.decbug.com/tags/powershell/"},{"name":"windbg","slug":"windbg","permalink":"http://blog.decbug.com/tags/windbg/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"Linux C++性能调优笔记","slug":"gprof_sprof_perf","date":"2015-03-27T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/03/27/gprof_sprof_perf/","link":"","permalink":"http://blog.decbug.com/2015/03/27/gprof_sprof_perf/","excerpt":"前言上周领导在群里问谁会linux C开发，我曾在业余时间自己捣鼓过，于是回答略懂。这周就被派到别的项目组紧急支援开发。大体工作是开发一个so供前台调用，开发过程中对makefile、跨平台的理解越发深刻了。相比于自娱自乐，正规开发更能涨知识。 此后数据量较大，很快就出现性能问题，作为折腾砖家，我当仁不让地接下性能调优的活。 每当遇到难题，都是我比较开心的时候，因为又是一次get新技能的好机会。","text":"前言上周领导在群里问谁会linux C开发，我曾在业余时间自己捣鼓过，于是回答略懂。这周就被派到别的项目组紧急支援开发。大体工作是开发一个so供前台调用，开发过程中对makefile、跨平台的理解越发深刻了。相比于自娱自乐，正规开发更能涨知识。 此后数据量较大，很快就出现性能问题，作为折腾砖家，我当仁不让地接下性能调优的活。 每当遇到难题，都是我比较开心的时候，因为又是一次get新技能的好机会。 profiler当系统的性能不能满足要求的时候，便要对其进行调优。方法有千千万万种，但无论如何，我们都要想办法精确识别到瓶颈，然后有的放矢进行优化。如何精确识别呢？这个时候profiler就闪亮登场了。 尝试了很多profiler之后，最终还是决定使用google perf tools linux常用profilergprofile &amp; perf &amp; sprof gprofile老牌劲旅，长久不衰，很多人用，功能也比较强大，使用简单。 在编译时加入参数 -pg就可以打开GProfile的开关 运行你的可执行文件，结束后会生成一个gmon.out 分析结果：gprof -b ‘你的可执行文件名’ gmon.out 会按函数热度进行排序，百分比越大的函数就越热，可以针对TOPN函数进行分析。 但是由于我开发的是一个so，被其他进程调用。虽然在so的编译时加上了-pg，并且通过标志位将进程用exit退出，但是还是没有生成gmon.out，不知道怎么回事，姑且先放下，有机会再研究。 perfperf功能很强大，而且被收录到内核(2.6.31)，可以记录page fault， cache miss，看起来真的很不错。 可惜我们的目标机内核版本太老，2.6.17，stackoverflow上有人回答说无法安装， Q: Does the old linux kernel support perf. A: No, it does not. The performance counters subsystem has undergone significant recent changes, and you are exceedingly unlikely to get perf working on any kernel below 2.6.31. 只好就此作罢。以后有机会再尝试。 sprof继续搜索’Profiling shared library’，找到sprof。看了下简介，大概能满足需求，先拿来用用。 首先创建一个so，里边写一段比较耗时的代码 123456789101112131415161718192021#include \"lib.h\"#include &lt;unistd.h&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void A::work(void)&#123; int a = 0; int b = 0; vector&lt;int&gt; v; while(a &lt; 10) &#123; b += a; ++a; v.push_back(a); sleep(1); &#125; cout &lt;&lt; \"work\" &lt;&lt; endl; return;&#125; 12345678910111213ll : libso g++ -L ./ -Wall -o test main.cpp -lliblibso : libo g++ -shared -o liblib.so liblib.olibo : lib.cpp g++ -Wall -Werror -fpic -c lib.cpp -o liblib.oclean: rm -f test# export LD_LIBRARY_PATH=/home/username/foo:$LD_LIBRARY_PATH 1234567#set the environment variable LD_PROFILE to the name of the shared objexport LD_PROFILE=my_obj#run your applicationmy_app#this should create a file /var/tmp/my_sobj.profile#now run sprofsprof my_sobj my_sobj.profile 查了一下，sprof只能采集可执行文件的性能，无法采集so的，还是需要放弃。 gperf-tools内网的文章带不出来，只能简单回忆，记录一下。继续折腾之下，找到了google-perf-tools，功能很强大，可以采集so的性能，还能采集内存。 决定结合gtest，用采用单元测试来测性能内存。 为什么要用单元测试呢？ 以前的做法比较麻烦。需要运行服务，然后kill平台进程等一系列操作。 方便。项目已有单元测试框架，可以根据我们的需要自由组合场景，对外部环境依赖较小。 运行快，几分钟就能看到结果。及时反馈，人脑在不断反馈的刺激下，会更专注。 如果使用得当，可能做到自动化。 安装libunwind安装gperftools设置环境变量CPUPROFILE; exprot enable单元测试改makefile在单元测试可执行文件tester的makefile和我们so的makefile加上 1234CXXFLAGS += -gLIBRARY += profiler 然后make 写测试代码 增加一个TEST，执行需要测性能的代码 在setup里加上profilerStart 在teardown加上profilerstop 运行，然后分析结果用 pprof –text (PATH OF TESTER) (CPUPROFILER执行的log)，得到文本格式的分析，包括每个函数的时间占有比例 用 pprof –callgrind可以生成图形化，很炫目。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://blog.decbug.com/tags/C/"},{"name":"linux","slug":"linux","permalink":"http://blog.decbug.com/tags/linux/"},{"name":"optimization","slug":"optimization","permalink":"http://blog.decbug.com/tags/optimization/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"pandoc---markdown转换利器","slug":"mark2html","date":"2015-03-10T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/03/10/mark2html/","link":"","permalink":"http://blog.decbug.com/2015/03/10/mark2html/","excerpt":"背景项目要发布一堆开发文档，并支持快速更新。经过我的不断安利，领导同意用markdown（感觉好有成就感啊）。经过一番探索，决定采用pandoc，因为功能真的很强大，请看官网介绍 If you need to convert files from one markup format into another, pandoc is your swiss-army knife. Pandoc can convert documents in markdown, reStructuredText, textile, HTML, DocBook, LaTeX, MediaWiki markup, TWiki markup, OPML, Emacs Org-Mode, Txt2Tags, Microsoft Word docx, EPUB, or Haddock markup to - HTML formats: XHTML, HTML5, and HTML slide shows using Slidy, reveal.js, Slideous, S5, or DZSlides. - Word processor formats: Microsoft Word docx, OpenOffice/LibreOffice ODT, OpenDocument XML - Ebooks: EPUB version 2 or 3, FictionBook2 - Documentation formats: DocBook, GNU TexInfo, Groff man pages, Haddock markup - Page layout formats: InDesign ICML - Outline formats: OPML - TeX formats: LaTeX, ConTeXt, LaTeX Beamer slides - PDF via LaTeX - Lightweight markup formats: Markdown, reStructuredText, AsciiDoc, MediaWiki markup, DokuWiki markup, Emacs Org-Mode, Textile - Custom formats: custom writers can be written in lua.","text":"背景项目要发布一堆开发文档，并支持快速更新。经过我的不断安利，领导同意用markdown（感觉好有成就感啊）。经过一番探索，决定采用pandoc，因为功能真的很强大，请看官网介绍 If you need to convert files from one markup format into another, pandoc is your swiss-army knife. Pandoc can convert documents in markdown, reStructuredText, textile, HTML, DocBook, LaTeX, MediaWiki markup, TWiki markup, OPML, Emacs Org-Mode, Txt2Tags, Microsoft Word docx, EPUB, or Haddock markup to - HTML formats: XHTML, HTML5, and HTML slide shows using Slidy, reveal.js, Slideous, S5, or DZSlides. - Word processor formats: Microsoft Word docx, OpenOffice/LibreOffice ODT, OpenDocument XML - Ebooks: EPUB version 2 or 3, FictionBook2 - Documentation formats: DocBook, GNU TexInfo, Groff man pages, Haddock markup - Page layout formats: InDesign ICML - Outline formats: OPML - TeX formats: LaTeX, ConTeXt, LaTeX Beamer slides - PDF via LaTeX - Lightweight markup formats: Markdown, reStructuredText, AsciiDoc, MediaWiki markup, DokuWiki markup, Emacs Org-Mode, Textile - Custom formats: custom writers can be written in lua. 此后再折腾了一下，打算不转PDF，还是转换成html比较好。优势在于 html浏览起来很方便，不需要装其他软件。 转PDF要安装引擎MiKTeX。 转换速度快，即时反馈。 pandoc对中文的支持还是不够理想。 随时可以发布。 下载安装官网 release 当前最新版是1.13.2。 学习资料神器Pandoc的安装与使用tzengyuxio 转html写了一个脚本，封装了一下，另外加了点css，代码放在https://github.com/CodeJuan/pandoc下一步计划把slide也美化一下，以后就可以抛弃PPT了。 ::脚本内容 pandoc -s --self-contained -c style.css \"%1\" -o \"%2.html\" --toc --self-contained表示将图片嵌入到页面 -c 表示使用style.css，用的是 --toc表示生成目录(table of contents) 调用方法::脚本内容 html.bat &quot;input_file_name&quot; &quot;output_name&quot; 改css看下效果，感觉比较一般，打算再修改一下 修改前的效果 修改后的效果主要修改点 body字体，代码字体 body居中 图片居中 table加border ## 详情请查看css提交记录 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"html","slug":"html","permalink":"http://blog.decbug.com/tags/html/"},{"name":"pandoc","slug":"pandoc","permalink":"http://blog.decbug.com/tags/pandoc/"},{"name":"slide","slug":"slide","permalink":"http://blog.decbug.com/tags/slide/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学习R语言","slug":"learning_rlang","date":"2015-03-04T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/03/04/learning_rlang/","link":"","permalink":"http://blog.decbug.com/2015/03/04/learning_rlang/","excerpt":"安装 mirriors select China， bjtu resouce , current version is R-3.1.2","text":"安装 mirriors select China， bjtu resouce , current version is R-3.1.2 extract, sudo tar xf r-3.1.2.tar.gz -C extract/ view the build document,vim INSTALL ./configure, error: No F77 compiler found。学自这里http://laymantech.blogbus.com/logs/80761679.html 会产生错误：configure: error: No F77 compiler found R语言需要fortran compiler，也就是说， 在上面尝试寻找了若干种Fortran 编译器未果之后，提示你没有安装任何一种可以使用的fortran 77 编译器。随便装个gfortran就行了。 $ sudo apt-get install gfortran 再次运行./configure $ ./configure 会产生错误：configure: error: con–with-readline=yes (default) and headers/libs are not available 首先检查是否安装readline. $ sudo apt-get install readline-common $ ./configure –with-readline=no 会出现错误：configure: error: –with-x=yes (default) and X11 headers/libs are no t available $ ./configure –with-x=no –with-readline=no 配置通过，但是会产生如下warning： configure: WARNING: you cannot build DVI versions of the R manuals configure: WARNING: you cannot build DVI versions of all the help pages configure: WARNING: you cannot build info or HTML versions of the R manuals configure: WARNING: you cannot build PDF versions of the R manuals configure: WARNING: you cannot build PDF versions of all the help pages 这是缺少生成相应格式manuals的插件，如果有需要可以依次安装。 sudo make，安装完毕。 简单试用###cd 到bin，sudo ./R，进入R控制台按照http://developer.51cto.com/art/201305/393121.htm试用一下1install.packages('quantmod') # 安装quantmod包 ， 会提示选择哪个镜像，19号beijing离我最近，于是输入19 q()是退出 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"R","slug":"R","permalink":"http://blog.decbug.com/tags/R/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"万网免费主机搭博客","slug":"netcn_zblog","date":"2015-01-31T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/01/31/netcn_zblog/","link":"","permalink":"http://blog.decbug.com/2015/01/31/netcn_zblog/","excerpt":"最近万网搞活动，域名29，虚拟主机免费，有小朋友动了建博客的念头，于是申请好了域名、虚拟主机。但是不知道后续该如何处理，乐于助人的我自然是要帮他一把的。 选框架小朋友选的是windows主机，简单搜索了一下，zblog貌似不错，好吧，就选它了，官网链接http://www.zblogcn.com/，下载ASP版http://www.zblogcn.com/zblog/，当前最新版的Z-Blog 2.2 Prism Build 140101。 解压后会看到一个release文件夹，由于后续要将release文件夹里的文件放在主机根目录，所以还要再压缩一次，格式还必须是rar，如下图所示","text":"最近万网搞活动，域名29，虚拟主机免费，有小朋友动了建博客的念头，于是申请好了域名、虚拟主机。但是不知道后续该如何处理，乐于助人的我自然是要帮他一把的。 选框架小朋友选的是windows主机，简单搜索了一下，zblog貌似不错，好吧，就选它了，官网链接http://www.zblogcn.com/，下载ASP版http://www.zblogcn.com/zblog/，当前最新版的Z-Blog 2.2 Prism Build 140101。 解压后会看到一个release文件夹，由于后续要将release文件夹里的文件放在主机根目录，所以还要再压缩一次，格式还必须是rar，如下图所示 通过FTP上传安装包把刚才压缩的rar，上传到FTP根目录，上传方法http://help.www.net.cn/KnowledgeDetail.html?knowledgeId=5868398&amp;categoryId=8311136 解压到根目录 如果不解压到根目录，也是可以的，只是访问的时候不能直接输入域名了，将会是你的域名/你的目录 安装ZBLOG打开http://你的域名/zb_install/default.asp(`万网的免费主机要备案，如果不备案，此时的网址就输入临时域名即可，临时域名还是在站点信息查询`)。 效果图一路next，完成。效果如图 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"virtual","slug":"virtual","permalink":"http://blog.decbug.com/tags/virtual/"},{"name":"zblog","slug":"zblog","permalink":"http://blog.decbug.com/tags/zblog/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"DebugDiag使用指南","slug":"debugdiag","date":"2015-01-18T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/01/18/debugdiag/","link":"","permalink":"http://blog.decbug.com/2015/01/18/debugdiag/","excerpt":"DebugDiag使用指南Foreword一直都是用windbg进行调试，但是主要通过CLI操作，现在的小朋友被GUI带坏了，都说学不会用。为此，还得找个略微简单的工具。恰好找到了DebugDiag，据说很简单，微软原文如下： The right debugging tool can dramatically simplify the isolation of these problem s and the provision of solutions. There are several types of these issues for which the Debug Diagnostic Tool is a better choice than other debugging tools Using the Windows core debuggers (Windbg.exe or Cdb.exe) for post-mortem analysis is a time consuming process and requires many debugging skills. 试用之后，果然比较简单，功能也很强大。这么个挺好用的工具，还是值得安利一下的。鉴于帮助文档大多是英文版，我就顺手把How to Use the Debug Diagnostic Tool (DebugDiag) to Debug User Mode Processes翻译一下。","text":"DebugDiag使用指南Foreword一直都是用windbg进行调试，但是主要通过CLI操作，现在的小朋友被GUI带坏了，都说学不会用。为此，还得找个略微简单的工具。恰好找到了DebugDiag，据说很简单，微软原文如下： The right debugging tool can dramatically simplify the isolation of these problem s and the provision of solutions. There are several types of these issues for which the Debug Diagnostic Tool is a better choice than other debugging tools Using the Windows core debuggers (Windbg.exe or Cdb.exe) for post-mortem analysis is a time consuming process and requires many debugging skills. 试用之后，果然比较简单，功能也很强大。这么个挺好用的工具，还是值得安利一下的。鉴于帮助文档大多是英文版，我就顺手把How to Use the Debug Diagnostic Tool (DebugDiag) to Debug User Mode Processes翻译一下。 原文链接:http://msdn.microsoft.com/en-us/library/ff420662.aspx 以上。 简介当用户面临程序稳定性及性能问题（如崩溃、挂死、不明觉厉的高内存占用）时，最佳补救措施就是在第一时间分析此程序的进程。不过，某些应用服务（如 IIS、Exchange、SQL Server、COM+、Biztalk）在运行出错和重启时，并没有提供UI信息，这样就增加了troubleshooting的难度。 123456789101112131415161718192021#include \"lib.h\"#include &lt;unistd.h&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void A::work(void)&#123; int a = 0; int b = 0; vector&lt;int&gt; v; while(a &lt; 10) &#123; b += a; ++a; v.push_back(a); sleep(1); &#125; cout &lt;&lt; \"work\" &lt;&lt; endl; return;&#125; 12345678910111213ll : libso g++ -L ./ -Wall -o test main.cpp -lliblibso : libo g++ -shared -o liblib.so liblib.olibo : lib.cpp g++ -Wall -Werror -fpic -c lib.cpp -o liblib.oclean: rm -f test# export LD_LIBRARY_PATH=/home/username/foo:$LD_LIBRARY_PATH 1234567#set the environment variable LD_PROFILE to the name of the shared objexport LD_PROFILE=my_obj#run your applicationmy_app#this should create a file /var/tmp/my_sobj.profile#now run sprofsprof my_sobj my_sobj.profile 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"debug","slug":"debug","permalink":"http://blog.decbug.com/tags/debug/"},{"name":"debugdiag","slug":"debugdiag","permalink":"http://blog.decbug.com/tags/debugdiag/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"真的是内存碎片吗","slug":"fragment","date":"2015-01-15T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/01/15/fragment/","link":"","permalink":"http://blog.decbug.com/2015/01/15/fragment/","excerpt":"背景 配置 参数 系统 win32 CPU E5505 内存 4G 某程序在运行过程中峰值达到1.8G，此后在申请小块内存时出现异常，此时进程只使用了900M内存。如你所知，windows 32bit的每个进程可用虚拟内存是4G，其中内核态2G，用户态2G（打开3G开关后就会是3G，但是不建议打开）。异常时，进程尚有近1G的内存可用，但为什么会抛出异常呢？真的是内存碎片造成的吗？","text":"背景 配置 参数 系统 win32 CPU E5505 内存 4G 某程序在运行过程中峰值达到1.8G，此后在申请小块内存时出现异常，此时进程只使用了900M内存。如你所知，windows 32bit的每个进程可用虚拟内存是4G，其中内核态2G，用户态2G（打开3G开关后就会是3G，但是不建议打开）。异常时，进程尚有近1G的内存可用，但为什么会抛出异常呢？真的是内存碎片造成的吗？ 调查运行两次，在不同的地方crash，抓到两个dump，用windbg简单分析一下。 Crash 1 : vector.push_back异常链: push_back -&gt; allovator -&gt; new -&gt; MemoryException。说明是在push_back申请内存时抛出的内存异常。简单回忆一下vector的内存分配机制，vector是连续存储的容器，它在新插入一个元素的时候，如果发现当前持有的内存放不下，那么就会再申请一块更大的内存（内存分配策略有差异，可以简单视为两倍），然后将旧内存中的元素复制到新内存中，并释放旧内存中的元素，再插入新的元素。由此猜测，push_back时vector里是不是有很多元素，使得此次会申请很大的一块连续内存，而系统没有合适的内存空间，然后申请失败抛出异常呢？查看代码，并询问开发小伙，得知crash时vector中元素个数不多，push_back时申请的不会是一块很大的连续内存，难道是真的是传说中的碎片？ Crash 12: CString.AppendFormat异常链: AppendFormat -&gt; PrepareWrite -&gt; Reallocate -&gt; MemoryException。有allocate的字样，看起来又像是在申请内存。查看一下微软CString的源码，在preparewrite函数中实现了这么一个内存算法： 1234567891011121314//凭印象写的，领会精神PrepareWrite()&#123; if (current_len &lt; 1G) &#123; //小于1G，每次都是申请1.5倍 new_len = current_len * 1.5; &#125; else &#123; //大于1G，每次加1M new_len = current_len + 1M; &#125;&#125; 12345678910111213PrepareWrite()&#123; if (current_len &lt; 1G) &#123; //小于1G，每次都是申请1.5倍 new_len = current_len * 1.5; &#125; else &#123; //大于1G，每次加1M new_len = current_len + 1M; &#125;&#125; 查看了当前string的长度，几百几千个字符而已，也就只申请几K内存。只是申请这么小的内存，怎么也申请失败了？ 简单分析查了下微软的一些文档 .Net application, 32-bit process, 32-bit OS, 800-1200 MB 微软说32位.Net程序内存在800M-1200M的时候，可能会出现out of memory的异常。 High memory usage or memory leak can cause virtual memory usage in a process to keep growing over time and prevent it from ever returning to normal usage levels. The process can then run out of memory and this can cause it to terminate unexpectedly. During these out-of-memory instances, the virtual memory may fall below 1 Gb, instead of the 2 Gb allowed to Win 32 processes. This problem is sometimes caused by high memory fragmentation. 微软建议虽然win32进程可以用2G，但最好是低于1G，否则可能会许多奇怪问题，有时就是内存碎片引起的。 如此，可能真的是碎片引起的。 初步解决方法将前面的内存降下去，就能顺利申请到内存，正常运行。但还是不能确定真的是内存碎片引起的。As a modern OS, the strategy of memory allocation so sucks? I don’t think so. The failure of memory allocattion caused by fragment. And The fragment should be caused by memory leak.. 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"fragment","slug":"fragment","permalink":"http://blog.decbug.com/tags/fragment/"},{"name":"memory","slug":"memory","permalink":"http://blog.decbug.com/tags/memory/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"用jenkins监控程序内存CPU","slug":"jenkins","date":"2015-01-12T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2015/01/12/jenkins/","link":"","permalink":"http://blog.decbug.com/2015/01/12/jenkins/","excerpt":"背景组里有许多初学C++的小朋友，对于STL及算法的时间/空间复杂度的敏感性不强，写出来的代码虽然完成了功能，但是运行时间过长，占用内存都过大。 老夫虽给小朋友们科普过几次，但效果还不是特别理想，有道是不掉坑，不长记性，古人诚不欺我。可势必不能把性能问题流到后端，老夫不得不在持续集成上增加一道小菜——检测运行时间、内存峰值及均值。 大概原理：写个脚本 取得构建包列表。下载没有测试过的最新的包。 读配置文件，获取测试用例，期望运行时间，期望内存峰值及均值。 自动运行程序，每1s采样一次进程内存大小，记录在日志里。 当程序结束时，计算运行时间间隔，与期望值比较，如果超出，则红。 分析之前记录的内存日志，求出峰值和均值，如果超出期望，也红。","text":"背景组里有许多初学C++的小朋友，对于STL及算法的时间/空间复杂度的敏感性不强，写出来的代码虽然完成了功能，但是运行时间过长，占用内存都过大。 老夫虽给小朋友们科普过几次，但效果还不是特别理想，有道是不掉坑，不长记性，古人诚不欺我。可势必不能把性能问题流到后端，老夫不得不在持续集成上增加一道小菜——检测运行时间、内存峰值及均值。 大概原理：写个脚本 取得构建包列表。下载没有测试过的最新的包。 读配置文件，获取测试用例，期望运行时间，期望内存峰值及均值。 自动运行程序，每1s采样一次进程内存大小，记录在日志里。 当程序结束时，计算运行时间间隔，与期望值比较，如果超出，则红。 分析之前记录的内存日志，求出峰值和均值，如果超出期望，也红。 安装windows此项目是开发windows应用程序，正好在华军有1.575的安装版，安装后就能用，省去不少事，访问http://你的IP:8080/就能看到jenkins的dashboard。 ubuntu家里木有windows，只能在ubuntu上安装一份，用于截图了。 JAVA，TOMCAT自然是少不了的。 在官网下载Jenkins.war，然后拷贝到你的tomcat的webapps下。 启动tomcat，运行tomcat/bin下destartup，命令： sudo sh startup.sh。 进入http://localhost:8080/jenkins/，熟悉的dashboard又出现了。 开工下载插件由于公司坑爹的网络设置，无法直接在线更新，只能采用手动下载。以Build Pipeline Plugin为例示范一下 进入 plugin manager，找到并点击Build Pipeline Plugin 在表格左上角找到Lastest Release，点击archives，下载你喜欢的版本即可。 未完待续 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://blog.decbug.com/tags/CPU/"},{"name":"jenkins","slug":"jenkins","permalink":"http://blog.decbug.com/tags/jenkins/"},{"name":"memory","slug":"memory","permalink":"http://blog.decbug.com/tags/memory/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"understand your code","slug":"understand_code","date":"2014-12-27T15:30:09.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2014/12/27/understand_code/","link":"","permalink":"http://blog.decbug.com/2014/12/27/understand_code/","excerpt":"","text":"代码可视化understand，一款很强大的软件，支持C++/JAVA/VHDL等等十几种语言，可以生成依赖图，类图，调用图，控制流图。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"scitools","slug":"scitools","permalink":"http://blog.decbug.com/tags/scitools/"},{"name":"understand","slug":"understand","permalink":"http://blog.decbug.com/tags/understand/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"一键式给VC工程创建UT工程","slug":"CreateUTproject","date":"2014-12-24T15:30:09.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2014/12/24/CreateUTproject/","link":"","permalink":"http://blog.decbug.com/2014/12/24/CreateUTproject/","excerpt":"前言项目组要求给已有的几十个VC工程添加配套的UT工程，需要覆盖到每个类(即每个CPP都要有对应的TEST)。简单观察了一下，还是选用add existing item to project添加.cpp.h的方法最为简单。 人肉创建验证此方法是否可行 把某工程的vcxproj及filter拷贝到UT目录 替换掉vcxproj里的CIinclude, resourceInclude的路径为相对路径 additional path加入gtest和gmock的头文件及lib def也要改成相对路径 additional Include path 要加上原有工程的路径 application type 改为 exe link-system-subsystem改为console gtest gmock的runtime lib都改为/mdd","text":"前言项目组要求给已有的几十个VC工程添加配套的UT工程，需要覆盖到每个类(即每个CPP都要有对应的TEST)。简单观察了一下，还是选用add existing item to project添加.cpp.h的方法最为简单。 人肉创建验证此方法是否可行 把某工程的vcxproj及filter拷贝到UT目录 替换掉vcxproj里的CIinclude, resourceInclude的路径为相对路径 additional path加入gtest和gmock的头文件及lib def也要改成相对路径 additional Include path 要加上原有工程的路径 application type 改为 exe link-system-subsystem改为console gtest gmock的runtime lib都改为/mdd 果然可以效果如图 powershell 脚本说白了就是用脚本处理vcxproj(其实就xml)，把上文提到的几个步骤都用脚本实现。 $path= gi .\\abc.xml $xmldata = [xml](Get-Content $path) $xmldata.rss.channel.title $xmldata.rss.channel.title=\"abc\" $xmldata.save($path.fullname) conclusion花了半天的时间把创建方法及脚本写好，省去N个人的重复劳动。通过脚本实现，还不容易出错。YEAH!! 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"UT","slug":"UT","permalink":"http://blog.decbug.com/tags/UT/"},{"name":"automation","slug":"automation","permalink":"http://blog.decbug.com/tags/automation/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"VLD集成到CI自动化检测内存泄露","slug":"Vld2CI","date":"2014-11-30T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2014/12/01/Vld2CI/","link":"","permalink":"http://blog.decbug.com/2014/12/01/Vld2CI/","excerpt":"VLD简介 Visual Leak Detector is a free, robust, open-source memory leak detection system for Visual C++. windows下VC常用开源内存泄露检测工具，代码在codeplex 原理代码中include了vld.h，在开始运行时构建一个VisualLeakDetector g_vld的全局变量，接管申请内存和释放内存的操作。此后会记录每次申请内存，并将地址及call stack存到一个set；释放内存时会删除set中与之相匹配的内存申请记录。在程序结束时，vld会遍历此set，如果set不为空，说明有内存泄露，会将泄露地址及call stack输出到report中。","text":"VLD简介 Visual Leak Detector is a free, robust, open-source memory leak detection system for Visual C++. windows下VC常用开源内存泄露检测工具，代码在codeplex 原理代码中include了vld.h，在开始运行时构建一个VisualLeakDetector g_vld的全局变量，接管申请内存和释放内存的操作。此后会记录每次申请内存，并将地址及call stack存到一个set；释放内存时会删除set中与之相匹配的内存申请记录。在程序结束时，vld会遍历此set，如果set不为空，说明有内存泄露，会将泄露地址及call stack输出到report中。 简单用法 下载及安装，假设安装在VldPath 配置VC的include路径：右键-属性-directory-include directory，增加VldPath\\include 配置lib路径：右键-属性-directory-lib directory，，增加VldPath\\lib\\win32，如果是x64的系统，那么选择win64即可。 根据需要配置vld.ini 声明 12#define VLD_FORCE_ENABLE //2.3版本之后，支持release下检测内存泄露#include \"vld.h\" 构建，运行，就会生成report。 集成到CI其实就是用脚本来实现上面的步骤，由于项目暂时不允许上传lib和dll到svn，只能通过迂回的方法来实现。 vld.h项目中有一个专门的目录存放开源代码的头文件，此时正好派上用场 copy /y vld.h %CODE_HOME%\\opensrc\\include\\ :: /y表示默认覆盖同名文件 copy /y vld_def.h %CODE_HOME%\\opensrc\\include\\ vld.lib同样也有个存放开源代码lib的目录 copy /y vld.lib %CODE_HOME%\\opensrc\\lib\\ dll将vld_x86.dll拷贝到bin目录 copy /y vld_x86.dll %CODE_HOME%\\bin\\ vld.ini将AggregateDuplicates设置为yes，表示将引起泄露同一行代码合并到一块。将ReportFile设置为.\\leak_report.txt，表示将结果输出到leak_report.txt中再将ini拷贝到bin copy /y vld.ini %CODE_HOME%\\bin\\ 更新代码svn revert -R .svn update . 修改stdafx.h由于stdafx.h会被预编译，只要在其包含vld.h，那么整个工程都会处于vld的监控之下。 :: 家里没有windows的系统，凭记忆写的，可能会有点小纰漏 FOR /F \"delims=\" %%i IN('dir /b /s stdafx.h') DO( echo //&gt;&gt;\"%%i\" echo #define VLD_FORCE_ENABLE&gt;&gt;\"%%i\" echo #include \"vld.h\"&gt;&gt;\"%%i\" ) buildFOR /F \"delims=\" %%i IN('dir /b /s *.sln') DO( msbuild.exe \"%%i\" /p:Configuration=Release /t:rebuild ) 运行提示0xC0150002，无法正确启动程序，这是因为缺少manifest，还需要把vld目录下的microsoft.dtfw.dhl.manifest拷贝到bin目录 copy /y microsoft.dtfw.dhl.manifest %CODE_HOME%\\bin\\ 在运行目录生成了一个leak_report.txt，如果有泄露，则会有一行提示WARNING:Visual Leak Detector detected memory leaks!，并指出引起内存泄露的代码。只要检测report就能知道是否有泄露。 加入到自动化测试套餐将脚本调试好，自动构建出检测内存泄露的版本，然后运行自动化测试，最后检测leak_report的内容，如有泄露则告警。 PS家里没有windows系统，有些命令记不清了，不知有没有写错。领会精神，不要在意这些细节。囧rz 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"ContinuousIntegration","slug":"ContinuousIntegration","permalink":"http://blog.decbug.com/tags/ContinuousIntegration/"},{"name":"MemoryLeak","slug":"MemoryLeak","permalink":"http://blog.decbug.com/tags/MemoryLeak/"},{"name":"VLD","slug":"VLD","permalink":"http://blog.decbug.com/tags/VLD/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学习gtest&gmock","slug":"gtest_gmock","date":"2014-11-28T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2014/11/29/gtest_gmock/","link":"","permalink":"http://blog.decbug.com/2014/11/29/gtest_gmock/","excerpt":"UT单元测试是代码的第一道防线，尽量将问题在前期暴露出来，发现越早，解决的成本就越低。 所以，作为码农，必须掌握单元测试的方法，并将UT集成到本地构建及CI服务器上，这样无论是新开发，还是维护重构等等，都能对我们的改动进行检测，及时反馈。 以前用过JUnit和CppUnit，已不太适合当前开发。很多同僚都推荐gtest，我自然不能错过。","text":"UT单元测试是代码的第一道防线，尽量将问题在前期暴露出来，发现越早，解决的成本就越低。 所以，作为码农，必须掌握单元测试的方法，并将UT集成到本地构建及CI服务器上，这样无论是新开发，还是维护重构等等，都能对我们的改动进行检测，及时反馈。 以前用过JUnit和CppUnit，已不太适合当前开发。很多同僚都推荐gtest，我自然不能错过。 下载 csdn下载，有好人一生平安，不用积分。 googlecode make有帖子说1.5之后的版本无法用make构建，其实并不是这样。 1.7版本还是支持make的，cd到make文件夹，然后make即可。 以gtest为例，会在make目录生成一个库文件，以及一个测试可执行文件sample1_unittest。 执行sample1_unittest 1234567891011Running main() from gtest_main.cc[==========] Running 6 tests from 2 test cases.[----------] Global test environment set-up.[----------] 3 tests from FactorialTest[ RUN ] FactorialTest.Negative[ OK ] FactorialTest.Negative (0 ms)[ RUN ] FactorialTest.Zero[ OK ] FactorialTest.Zero (0 ms)[ RUN ] FactorialTest.Positive[ OK ] FactorialTest.Positive (0 ms)[----------] 3 tests from FactorialTest (0 ms total) 接下来就是怎么链接到我们的工程，makefile如下: 123456789101112PPFLAGS += -isystem $(GTEST_DIR)/include CXXFLAGS += -g -Wall -Wextra -pthread TESTS = test #将gtest加入到includeGTEST_HEADERS = ../include#引入静态库LIB_DIR = ../lib/gtest_main.atest : g++ $(CPPFLAGS) $(CXXFLAGS) -lpthread -I $(GTEST_HEADERS) $(LIB_DIR) test.cpp -o test clean : rm -f test 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"GMOCK","slug":"GMOCK","permalink":"http://blog.decbug.com/tags/GMOCK/"},{"name":"GTEST","slug":"GTEST","permalink":"http://blog.decbug.com/tags/GTEST/"},{"name":"UT","slug":"UT","permalink":"http://blog.decbug.com/tags/UT/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"学习GCC & GDB","slug":"test_gcc_gdb","date":"2014-11-25T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2014/11/26/test_gcc_gdb/","link":"","permalink":"http://blog.decbug.com/2014/11/26/test_gcc_gdb/","excerpt":"前言工作是在windows下开发，业余时间才能玩自己喜欢的东东，一段时间不用就会生疏。随便写两段，加深记忆。 GCC从代码到可执行文件，会经历四个阶段，对应的命令是 gcc -E test.c -o test.i 中间文件gcc -S test.i -o test.s ASMgcc -c test.s -o test.o OBJgcc test.o -o test 可执行文件","text":"前言工作是在windows下开发，业余时间才能玩自己喜欢的东东，一段时间不用就会生疏。随便写两段，加深记忆。 GCC从代码到可执行文件，会经历四个阶段，对应的命令是 gcc -E test.c -o test.i 中间文件gcc -S test.i -o test.s ASMgcc -c test.s -o test.o OBJgcc test.o -o test 可执行文件 当然，可以用一行命令搞定 gcc -o test test.c GDB回忆一下GDB的常用命令吧l, b, r, watch, bt, n, step从陈皓巨巨那A了段教程1234567891011121314151617181920212223#include &lt;stdio.h&gt; int func(int n)&#123; int sum=0,i; for(i=0; i&lt;n; i++) &#123; sum+=i; &#125; return sum;&#125;main()&#123; int i; long result = 0; for(i=1; i&lt;=100; i++) &#123; result += i; &#125; printf(\"result[1-100] = %d /n\", result ); printf(\"result[1-250] = %d /n\", func(250) );&#125; 123456789101112131415gcc -g -o test test.c #-g表示gdbgdb ./test #用gdb打开l #显示代码b linenum #给指定行号价断点 bpb function_name #给函数加断点i b #info breakpoint显示断点，类似于windbg的blr #runn #nextp var_name #显示变量的值step #下一行info locals #显示localwatch i #watch某变量d 1 #delete breakpoint 1c #continueq #quit conclusion还是要得写几段代码玩呃，拳不离手，曲不离口。。。。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"GCC","slug":"GCC","permalink":"http://blog.decbug.com/tags/GCC/"},{"name":"GDB","slug":"GDB","permalink":"http://blog.decbug.com/tags/GDB/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"比较WinPE文件(忽略时间戳)","slug":"CompareWinPE","date":"2014-11-18T16:00:00.000Z","updated":"2016-10-10T13:05:25.396Z","comments":true,"path":"2014/11/19/CompareWinPE/","link":"","permalink":"http://blog.decbug.com/2014/11/19/CompareWinPE/","excerpt":"背景项目组出现过比较有意思的情况：在同一台持续集成服务器，从同一个SVN上取指定版本的代码进行打包，但生成的两个版本有差异，即有DLL不相同导致运行结果不正确。经过定位，推测可能是update代码的过程中出现了异常，没有获取到期望的代码。因此，CI工程师需要一种方法能够对DLL，EXE等二进制文件进行比对，以验证其正确性。但是即使用普通二进制比较工具（BeyondCompare）进行比较，发现总是有几个字节不相同。于是向我求助。 过程我曾看过windows的PE文件结构，依稀记得里边会有几个字节存放TimeStamp和CheckSum，所以会有这么几个字节的差异。为避免误人子弟，特找来微软的定义看看： 12345typedef struct _IMAGE_NT_HEADERS &#123; DWORD Signature; IMAGE_FILE_HEADER FileHeader; IMAGE_OPTIONAL_HEADER32 OptionalHeader; &#125; IMAGE_NT_HEADERS32, *PIMAGE_NT_HEADERS32;","text":"背景项目组出现过比较有意思的情况：在同一台持续集成服务器，从同一个SVN上取指定版本的代码进行打包，但生成的两个版本有差异，即有DLL不相同导致运行结果不正确。经过定位，推测可能是update代码的过程中出现了异常，没有获取到期望的代码。因此，CI工程师需要一种方法能够对DLL，EXE等二进制文件进行比对，以验证其正确性。但是即使用普通二进制比较工具（BeyondCompare）进行比较，发现总是有几个字节不相同。于是向我求助。 过程我曾看过windows的PE文件结构，依稀记得里边会有几个字节存放TimeStamp和CheckSum，所以会有这么几个字节的差异。为避免误人子弟，特找来微软的定义看看： 12345typedef struct _IMAGE_NT_HEADERS &#123; DWORD Signature; IMAGE_FILE_HEADER FileHeader; IMAGE_OPTIONAL_HEADER32 OptionalHeader; &#125; IMAGE_NT_HEADERS32, *PIMAGE_NT_HEADERS32; 其中FileHeader的定义是，第三个变量就是时间戳，表示文件的创建时间。 123456789typedef struct _IMAGE_FILE_HEADER &#123; WORD Machine; WORD NumberOfSections; DWORD timeDateStamp; //timeDateStamp DWORD PointerToSymbolTable; DWORD NumberOfSymbols; WORD SizeOfOptionalHeader; WORD Characteristics; &#125; IMAGE_FILE_HEADER, *PIMAGE_FILE_HEADER; 再来看看所谓的可选头OptionalHeader，其实一点都不可选，里边藏了好多东西，其中的CheckSum也会导致DLL差异。 1234567typedef struct _IMAGE_OPTIONAL_HEADER &#123; WORD Magic; //... DWORD CheckSum; //CheckSum //... IMAGE_DATA_DIRECTORY DataDirectory[IMAGE_NUMBEROF_DIRECTORY_ENTRIES]; &#125; IMAGE_OPTIONAL_HEADER32, *PIMAGE_OPTIONAL_HEADER32; 去除TimeStamp既然时间戳确实存在，那么只能想办法在比较的时候忽略时间戳，或是在比较之前去除之。秉承一贯不重复造轮子的作风，先google一下是否有解决方案。 BinDiff微软大力推荐的BinDiff，可惜找了一大圈都没找到下载源，网上另有说法是BinDiff属于商用软件，license很贵。只能放弃，另寻他法。 dumpbin /rawdataVS2010自带了将PE文件导出的工具Dumpbin，据说可以将PE文件导出来。需要注意的是，不能直接在CMD里输入dumpbin，会提示找不到某个DLL，必须在开始菜单-VS2010-Tools-prompt里打开。区别在于tools里会先调用一个bat环境变量。用法 12dumpbin /rawdata 1.dll 1.txtdumpbin /rawdata 2.dll 2.txt 用BeyondCompare比较1.txt和2.txt，发现差异还是在TimeStamp处，看来此法不通。 dumpbin /disasm查看dumpbin命令 /ALL /ARCHIVEMEMBERS /CLRHEADER /DEPENDENTS /DIRECTIVES /DISASM[:{BYTES|NOBYTES}] /ERRORREPORT:{NONE|PROMPT|QUEUE|SEND} /EXPORTS /FPO /HEADERS /IMPORTS[:文件名] /LINENUMBERS /LINKERMEMBER[:{1|2}] /LOADCONFIG /OUT:文件名 /PDATA /PDBPATH[:VERBOSE] /RANGE:vaMin[,vaMax] /RAWDATA[:{NONE|1|2|4|8}[,#]] /RELOCATIONS /SECTION:名称 /SUMMARY /SYMBOLS /TLS /UNWINDINFO 其中有个disasm，看着像反汇编。如果能把PE反汇编出来，应该就能把TimeStamp去掉。 12dumpbin /disasm 1.dll 1.txtdumpbin /disasm 2.dll 2.txt 比较1.txt和2.txt果然一致。 后续需要写一个bat，输入参数为两个文件夹的路径，将这两个文件夹内的PE文件都反汇编出来，然后一一进行比较，输出有差异的文件名。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"WinPE","slug":"WinPE","permalink":"http://blog.decbug.com/tags/WinPE/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"优化草稿","slug":"optimize","date":"2014-05-05T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2014/05/06/optimize/","link":"","permalink":"http://blog.decbug.com/2014/05/06/optimize/","excerpt":"背景用于大数据分析，追求速度，将所有数据都放于内存处理。分为：业务模块层，框架层，表现层。 流程 用户点击运行。 框架层从文件中读入数据，进行预处理，放入内存，传递给业务层。 业务层从内存中获取数据，进行二次处理，生成结果。 循环2与3，直至处理完全部文件。","text":"背景用于大数据分析，追求速度，将所有数据都放于内存处理。分为：业务模块层，框架层，表现层。 流程 用户点击运行。 框架层从文件中读入数据，进行预处理，放入内存，传递给业务层。 业务层从内存中获取数据，进行二次处理，生成结果。 循环2与3，直至处理完全部文件。 随手画下流程图，家里电脑没有合适的工具，将就着画吧。 现状如前文所示，业务模块是串行处理，CPU利用率25%，偶尔在会到80% 以上，利用不够充分。由于windows32位单个进程只能用4G内存，其中内核2G，用户只能使用2G。目前已出现内存不足的情况（new申请内存失败），当数据继续膨胀，2G内存必然远不够用。业务模块的代码不够规范，内存泄漏比较多，影响到整体运行。 想点办法由单进程改为多进程 并发以压榨CPU，根本闲不下来。 每个业务件都是一个进程，都可用2G内存，可以容纳更大的数据，并且不会互相干扰。 增加一个数据层，将框架层与业务层隔离。 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"optimize","slug":"optimize","permalink":"http://blog.decbug.com/tags/optimize/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"内存基础知识","slug":"memory","date":"2014-04-05T16:00:00.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2014/04/06/memory/","link":"","permalink":"http://blog.decbug.com/2014/04/06/memory/","excerpt":"当前问题目前有一个日志分析程序，随着数据的膨胀，工具的运行性能越来越差，甚至运行过程中出现申请不到内存的情况。在任务管理器里可以看到，还有足够的内存，可是却申请不到。由于程序在运行过程中，有许多次new/delete的操作，据此推测是有太多的内存碎片，导致无法申请到足够大的连续内存。 基础知识new/delete做了什么？有哪些开销slab锁-查找空闲-找到合适大小连续的-分配-解锁。delete相反","text":"当前问题目前有一个日志分析程序，随着数据的膨胀，工具的运行性能越来越差，甚至运行过程中出现申请不到内存的情况。在任务管理器里可以看到，还有足够的内存，可是却申请不到。由于程序在运行过程中，有许多次new/delete的操作，据此推测是有太多的内存碎片，导致无法申请到足够大的连续内存。 基础知识new/delete做了什么？有哪些开销slab锁-查找空闲-找到合适大小连续的-分配-解锁。delete相反 内存碎片Imagine that you have a “large” (32 bytes) expanse of free memory: |_| Now, allocate some of it (5 allocations): |aaaabbccccccddeeee__| Now, free the first four allocations but not the fifth: |__eeee___| Now, try to allocate 16 bytes. Oops, I can’t, even though there’s nearly double that much free.On systems with virtual memory, fragmentation is less of a problem than you might think, because large allocations only need to be contiguous in virtual address space, not in physical address space. So in my example, if I had virtual memory with a page size of 2 bytes then I could make my 16 byte allocation with no problem. Physical memory would look like this: |ffffffffffffffeeeeff__| whereas virtual memory (being much bigger) could look like this:__…|_eeeeffffffffffffffff__… The classic symptom of memory fragmentation is that you try to allocate a large block and you can’t, even though you appear to have enough memory free. Another possible consequence is the inability of the process to release memory back to the OS (because there’s some object still in use in all the blocks it has allocated from the OS, even though those blocks are now mostly unused). Tactics to prevent memory fragmentation in C++ work by allocating objects from different areas according to their size and/or their expected lifetime. So if you’re going to create a lot of objects and destroy them all together later, allocate them from a memory pool. Any other allocations you do in between them won’t be from the pool, hence won’t be located in between them in memory, so memory will not be fragmented as a result. Generally you don’t need to worry about it much, unless your program is long-running and does a lot of allocation and freeing. It’s when you have mixtures of short-lived and long-lived objects that you’re most at risk, but even then malloc will do its best to help. Basically, ignore it until your program has allocation failures or unexpectedly causes the system to run low on memory (catch this in testing, for preference!). The standard libraries are no worse than anything else that allocates memory, and standard containers all have an Alloc template parameter which you could use to fine-tune their allocation strategy if absolutely necessary. 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"科普","slug":"科普","permalink":"http://blog.decbug.com/tags/科普/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]},{"title":"不完整的简历","slug":"x_resume","date":"2013-12-31T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2014/01/01/x_resume/","link":"","permalink":"http://blog.decbug.com/2014/01/01/x_resume/","excerpt":"个人资料","text":"个人资料 标题 内容 mail xh@decbug.com github codejuan stackoverflow codejuan blog blog.decbug.com 毕业学校 南昌大学 20xx年～20xx年 本科 手机号 xxxxxxxxxxxx个人隐私不公开可以发邮件索取 技能 全栈，需求、设计、编码、持续集成、测试、部署、运维 人员培养、性能优化、敏捷、效率提升。 技术 项目 评分 短评 C/C++ 熟悉 虽用的比较多，但实在不敢说精通 JAVA/Python/Go/PowerShell/C# 一般 lua/Shell 了解 英语 熟悉 读：谷歌，看英文资料；听：不错；写说：一般 windows 熟悉 对windows的消息，线程，进程，异常，windbg都比较熟悉 linux 熟悉 看过内核的书，知道MMU，进程，锁，调度，中断，文件系统，IO等等 工作经历华为 2014年～至今 云计算 Docker，企业私有镜像仓库及加速器，nginx+registry v2+自研DFS，目标是做一个DaoCloud OpenStack性能模拟器，测试各组件的性能。基于开源RabbitMQ客户端的C语言版本和lua实现，采用异步+状态机+责任链，仿真效果达到百万台虚拟机的水平 在一个数据挖掘的150人团队担任技术砖家 业务代码C++，UI用C#，分析基站的通信log 持续集成，将整个系统的构建时间由2小时缩短到0.5小时；搭建单元测试(关键代码全覆盖)，自动化测试框架，内存泄漏检测 负责性能优化，总结出常见低性能C++代码案例，以及google perf tool+vs performance analyse使用方法 采用STXXL+BOOST序列化，将非热点数据缓存至硬盘，在基本不需要改动代码的前提下，使得工具的数据处理能力由GB级别跃升至TB级别。没有用redis的原因是，对已有代码冲击太大。 指导组内同事开发，解决各种疑难杂症，如CoreD，性能慢等 招聘，负责技术面试；培训，STL用法，单元测试gtest用法等等 Samsung 2013年～2014年 接触前端/数据库等等，丰富技能树 软件生命周期管理系统，C#+SilverLight，Redmine/Jira做二次开发 JAVA + SSH做了个xxx管理系统 中兴 2011年～2013年 开发手机检测系统。Windows应用程序，C/S架构，C++，用到socket、USB等等 有点手机/无线路由的硬件经验，了解高通调测指令及方法，了解Atheros,Broadcom的路由方案。 Giesecke&amp;Devrient 20xx年～20xx年 由维修工转职为程序员，用过VB，C++，C#，奠定了啥都会一点的基础 基于VB实现一套标签打印系统，并针对业务需求优化，效果胜于某商用标签打印软件 基于VC，通过串口及并口操作设备，将生产过程自动化 兼职过IT，会组装电脑，维修电脑，搭建局域网","categories":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}],"tags":[{"name":"resume","slug":"resume","permalink":"http://blog.decbug.com/tags/resume/"}],"keywords":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}]},{"title":"一页简历","slug":"x_simple_resume","date":"2013-12-31T16:00:00.000Z","updated":"2016-10-10T13:05:25.404Z","comments":true,"path":"2014/01/01/x_simple_resume/","link":"","permalink":"http://blog.decbug.com/2014/01/01/x_simple_resume/","excerpt":"项目 内容 mail xh@decbug.com 技术 github 、 blog 、 stackoverflow 毕业学校 南昌大学 自动化 20xx年～20xx年 本科 手机号 个人隐私","text":"项目 内容 mail xh@decbug.com 技术 github 、 blog 、 stackoverflow 毕业学校 南昌大学 自动化 20xx年～20xx年 本科 手机号 个人隐私 技能全栈(全不能-_-!)，设计、编码、持续集成、测试、部署、运维；性能优化、敏捷、研发效率提升、人员培养技术控，对代码略有洁癖，爱好折腾，善于解决各种疑难问题，尝试新技术 项目 评分 短评 C/C++ 熟悉 虽用的比较多，但实在不敢说精通 JAVA/Python/Go/PowerShell/C# 一般 lua/Shell/Node 了解 英语 熟悉 读：只谷歌，看英文资料毫无压力；听：不错；写说：一般 windows 熟悉 对windows的消息，线程，进程，异常，windbg都比较熟悉 linux 熟悉 看过内核的书，MMU，进程，锁，调度，中断，文件系统，IO等 工作经历华为 2014年～至今 云计算 Docker，企业私有镜像仓库及加速器，nginx+registry+自研DFS Docker镜像构建服务：基于Go gorilla/mux、MySQL、微服务、Restful，从开发测试部署都是Docker化模式 OpenStack性能模拟器，测试各组件的性能。基于RabbitMQ-C语言实现AMQP协议，lua实现业务 数据挖掘 业务代码C++，UI用C#，分析基站产生的海量通信log 作为技术专家，负责整体技术架构，性能优化、难点攻关、技术指导、CodeReviewa、重构、开发效率提升 持续集成，将整个系统的构建时间由2小时缩短到0.5小时；搭建单元测试、自动化测试，覆盖到关键业务代码 总结出常见低性能C++代码案例，以及google perf tool+vs performance analyse使用方法 采用STXXL+BOOST序列化，将非热点数据存硬盘，仅需改动一点代码，使数据处理能力GB提升TB 指导组内同事开发，解决各种疑难杂症，如CoreDump，性能慢等；招聘，负责技术面试；培训，STL用法，单元测试gtest用法等等 Samsung 2013年～2014年 接触前端/数据库等等，丰富技能树 开发软件生命周期管理系统，C#+SilverLight，Redmine/Jira做二次开发；JAVA + SSH做了个xxx管理系统 中兴 2011年～2013年 开发手机检测系统。Windows应用程序，C/S架构，C++，用到socket、USB等等 有手机/无线路由的硬件经验，了解高通调测指令及方法，了解Atheros,Broadcom的路由方案。 Giesecke&amp;Devrient 20xx年～2011年 由维修工转职为程序员，兼职过IT，组装电脑，维修电脑，用过VB，C++，C#，奠定了啥都会一点的基础 基于VB实现一套标签打印系统，并针对业务需求优化，效果胜于某商用标签打印软件；基于VC，通过串口及并口操作设备，将生产过程自动化","categories":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}],"tags":[{"name":"resume","slug":"resume","permalink":"http://blog.decbug.com/tags/resume/"}],"keywords":[{"name":"mumble","slug":"mumble","permalink":"http://blog.decbug.com/categories/mumble/"}]},{"title":"Hello World","slug":"hello-world","date":"2013-12-24T15:30:09.000Z","updated":"2016-10-10T13:05:25.400Z","comments":true,"path":"2013/12/24/hello-world/","link":"","permalink":"http://blog.decbug.com/2013/12/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 本博客欢迎转发,但请保留原作者信息github:codejuan博客地址:http://blog.decbug.com/","categories":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}],"tags":[{"name":"hello","slug":"hello","permalink":"http://blog.decbug.com/tags/hello/"}],"keywords":[{"name":"code","slug":"code","permalink":"http://blog.decbug.com/categories/code/"}]}]}